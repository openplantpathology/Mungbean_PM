---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# Grain yield meta-analysis

Let's get started with the analysis by first finding the best fitting model which answers our research question.

> When, in relation to PM establishment in the crop, should farmers begin spraying mungbean to mitigate yield loss: before PM establishing, immediately after first sign of PM establishing, or after PM has become established in the crop. 

A secondary question to this aim is: given the time at which the first spray occurred does a second spray provide worthwhile yield protection.

To do this, the model will use the main variables:

   - *Grain yield* the response variable (t / ha)

   - *Trial*, which resolves combinations of categorical random variables: 
      i) year  
      ii) location  
      iii) row spacing  
      iv) cultivar  
      
   - *spray_management* a moderator to evaluate the difference in effect size attributed to fungicide application timing.  
   
   - *id* random variable indicating each treatment is independent
   
   
```{r Yield_ME_libraries, echo=TRUE,results='hide'}
# load R packages
if (!require("pacman"))
   install.packages("pacman")
pacman::p_load(
   tidyverse,
   kableExtra,
   bomrang,
   RColorBrewer,
   metafor,
   here,
   netmeta,
   multcomp,
   flextable
)

if (!require("theme.usq"))
   remotes::install_github("adamhsparks/theme.usq")
library(theme.usq)
theme_set(theme_usq())
source(here("R/reportP.R"))

# Data
PM_dat_Y <-
   read.csv("cache/PM_yield_clean_data.csv", stringsAsFactors = FALSE
   )
```



### Define Trial
```{r Yield_define_trial}
PM_dat_Y <-
   PM_dat_Y %>%
   mutate(trial = paste(trial_ref,
                        year,
                        location,
                        host_genotype,
                        row_spacing,
                        sep = "_")) 
```


<br>  
<br>  
<br>  

## Spray schedule meta-analysis  

The `spray_management` moderator will be evaluated in the first model. 
Then this model will be tested against other models incorporating, time of disease onset, disease pressure and other variance-covariance matrix structures.  

### Spray schedule moderator

This *grain yield* meta-analysis is a multi-variate meta-analysis, using the `metafor` package function `rma.mv()` [@Viechtbauer2010].

We are using the `spray_management` variable as a moderator and an interactive random term with the `trial` random variable. The variance-covariance matrix is specified as unstructured (UN) to allow correlations between and within trials.  

```{r Yield_Metafor-analysis}
PM_mv <- rma.mv(
   yi = grain_yield.t.ha.,
   V = vi,
   mods = ~ spray_management,
   method = "ML",
   random = list( ~ spray_management | trial, ~ 1 | id),
   struct = "UN",
   control = list(optimizer = "optim"),
   data = PM_dat_Y
)
```

<br>  
<br>  
<br>  

*****

### Disease onset interaction with spray schedule  

To determine if the time at which disease occurs in the cropping season influences the efficacy at which fungicide applications protect yield we will create a categorical variable defining `early` or `late` disease onset.

`early` and `late` categories should be divided by a number close to the median days after sowing when signs of the disease were first observed to ensure roughly even numbers in each category.
```{r median onset}
PM_dat_Y %>%
   mutate(first_sign_days = lubridate::ymd(first_sign_disease) -
             lubridate::ymd(planting_date)) %>%
   pull(first_sign_days) %>%
   median()
```

We will choose 42 days as this is the average days to flowering in mungbean. 
In addition, Kelly et. al. [-@Kelly2017a] noted that yield losses are higher in cultivar Berken when disease establishes before flowering.

Now let's define a continuous variable`first_sign_days` and a categorical variable `onset`.

```{r define_onset}
PM_dat_Y <- PM_dat_Y %>%
   mutate(first_sign_days = lubridate::ymd(first_sign_disease) -
             lubridate::ymd(planting_date)) %>%
   mutate(onset = case_when(
      first_sign_days <= 42 ~ "early_onset",
      first_sign_days > 42 ~ "late_onset"
   ))
```

Inspect a histogram of when first sign occurred in the crop.

```{r hist_onset}
PM_dat_Y %>%
   ggplot(aes(x = as.integer(first_sign_days))) +
   geom_histogram(binwidth = 1) +
   geom_vline(xintercept = 42)
```

`early_onset` contains `r nrow(PM_dat_Y[PM_dat_Y$onset == "early_onset",])` treatments and,  
`late_onset` contains `r nrow(PM_dat_Y[PM_dat_Y$onset == "late_onset",])` treatments.  

<br>  
<br>  

******

#### metafor onset analysis

We are adding the `onset` variable as a moderator to test and interaction with the `spray_management` variable as a moderator and an interactive term to the `trial` random variable.

```{r onset_Metafor-analysis}
PM_mv_onset <- rma.mv(
   yi = grain_yield.t.ha.,
   V = vi,
   mods = ~ spray_management * onset,
   method = "ML",
   random = list( ~ spray_management | trial, ~ 1 | id),
   struct = "UN",
   control = list(optimizer = "optim"),
   data = PM_dat_Y
)
```

```{r}
anova(PM_mv, PM_mv_onset)
```

This comparison tells us the meta-analysis including `onset` explained more residual heterogeneity, as shown by the lower QE value, and has a better fit, indicated by the higher log-likelihood with the additional `onset` parameters.
However the higher AIC indicates in the model with the additional `onset` parameters does not sufficiently improve the model fit to warrant including these parameters and therefore the 'reduced' model is a better option.
This inference is also reflected by the the chi-squared test, which is uncertain that the `onset` model is significantly better as indicated by the ANOVA `pval` `r round(anova(PM_mv, PM_mv_onset)$pval,3)`.

<br>  
<br>  
<br>  

******  

### Disease pressure interaction with spray schedule

To determine if the seasonal disease pressure influences the efficacy at which fungicide applications protect yield a categorical variable defining `high_pressure` or `low_pressure` can be defined.

`high_pressure` and `low_pressure` will be divided by the median disease severity in the no spray control treatments at the end of the season.

```{r median_pressure}
PM_dat_Y %>%
   filter(fungicide_ai == "control") %>%
   pull(PM_final_severity) %>%
   median()
```

Now to define these two new variables, `low_pressure` and `high_pressure` in the data.

```{r define_disease_pressure}
PM_dat_Y <- PM_dat_Y %>%
   mutate(
      d_pressure = case_when(
         PM_final_severity < 8 ~ "low_pressure",
         PM_final_severity >= 8 ~ "high_pressure"
      )
   )
```

Inspect a histogram of the final severity values in the crop.

```{r hist_pressure}
PM_dat_Y %>%
   ggplot(aes(x = PM_final_severity)) +
   geom_histogram(binwidth = 1) +
   geom_vline(xintercept = 8)
```

<br>  
<br>  
<br>  

******  


#### metafor disease pressure interaction

Test `d_pressure` variable addition as a moderator to evaluate it's interaction with the `spray_management` to influence the grain yield effect size.

```{r Dpressure_Metafor-analysis}
PM_mv_dp <- rma.mv(
   yi = grain_yield.t.ha.,
   V = vi,
   mods = ~ spray_management * d_pressure,
   method = "ML",
   random = list( ~ spray_management | trial, ~ 1 | id),
   struct = "UN",
   control = list(optimizer = "optim"),
   data = PM_dat_Y
)
```

```{r}
anova(PM_mv, PM_mv_dp)
```
This comparison tells us the meta-analysis including `d_pressure` explained more residual heterogeneity, as shown by the lower QE value, and has a better fit, indicated by the higher log-likelihood with the additional `d_pressure` parameter.
However the lower AIC in the 'Full' model indicates that retaining the model including the additional `d_pressure` variables could be a reasonable decision.
In addition the chi-squared test indicates that the `d_pressure` model is better as indicated by the `pval` 0.0468.  

However it is worth noting that there were no Late plus schedules that experienced low disease pressure. 
Even though the disease pressure interaction on the moderators could be deemed significant (P = 0.0468), the division of schedules due to disease pressure (reducing k) makes drawing conclusions risky. More data is needed to explore this possible effect.


```{r}
# show the division of spray schedules by the d_pressure moderator
PM_dat_Y %>%
   group_by(spray_management, d_pressure) %>%
   summarise(n()) %>%
   flextable()
```


```{r}
summary(PM_mv_dp)
```

<br>  
<br>  
<br>  

******  

### Test variance-covavriance matrix structure

Test a model with an implied simpler variance-covariance matrix, "compound symmetry" (CS), to examine if unstructured matrix is suitable.

```{r}
PM_mv_cs <- rma.mv(
   yi = grain_yield.t.ha.,
   V = vi,
   mods = ~ spray_management,
   method = "ML",
   random = list( ~ spray_management | trial, ~ 1 | id),
   struct = "CS",
   control = list(optimizer = "optim"),
   data = PM_dat_Y
)

anova(PM_mv, PM_mv_cs)
```

Again `PM_mv` (Full) prevails as the better model (p = 0.0014; AIC = -45.4359) and therefore we should keep the unstructured variance-covariance matrix.

 > Therefore the model `PM_mv`, is the preffered model with this data.


## Summarise PM_mv model

```{r PM_mv_summary}
summary(PM_mv)
```


The first table in the `PM_mv` output shows the tau^2 (between trial variance) for each random effect intercept (spray_management) to trial and the number of occurrences for each treatment in the analysis.
This effectively shows the heterogeneity between trials for these particular treatments.

This table shows `Recommended_plus` showed the highest heterogeneity between trials followed by `Late_plus`, `Late` then `Recommended`, with `Early` and the no-spray `control` showing the least heterogeneity.

The second table is in two parts (left and right). 
The left part, rho, is the correlation of variation between the specified treatments.
All comparisons were acceptable except for a comparison between `Early` and `Late_plus`, indicating `0.000` rho.
`Early` and `Late_plus` treatments never occurred within the same trial, which is indicated by the right side of the table (hence earlier warnings). 
This is not a concern for this type of network meta-analysis because the differences between these treatments can be inferred by their differences with other treatments [@Madden2016].

In this result we can see that the `Early` treatment is not significantly different to the intercept, which in this case is the mean of the no spray `control`.
However the other treatments are significantly different from the no-spray control (intercept).
The $Q_M$ [omnibus test](http://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept?s[]=anova) of moderators, shows the moderators significantly influence the model ($Q_M =$ `r PM_mv$QM` $,df =$ `r PM_mv$m`, `r reportP(PM_mv$QMp)`) and we can reject the null hypothesis ($H_0 : \beta_1 = \beta_2 = \beta_3 =\beta_4 = 0$) that there is no difference between the moderators [@Viechtbauer2010].
The analysis shows there is still a significant amount of residual heterogeneity ($Q_E =$ `r PM_mv$QE` $,df=$ `r PM_mv$k - PM_mv$m`, `r reportP(PM_mv$QEp)` ) not captured by the spray management moderator indicating other possible moderators which might influence grain yield.  

<br>
<br>
<br>

******

## Meta-analysis results summary

### Moderator estimates table

Let's present the meta-analysis results for the moderator variables in a table of estimates.

```{r metafor_results_table_yield}
# obtain number of treatments included in each moderator variable
k5 <-
   as.data.frame(table(PM_dat_Y$trial, PM_dat_Y$spray_management)) %>%
   filter(Freq != 0) %>%
   group_by(Var2) %>%
   summarise(n()) %>%
   pull()

# create data.frame
results_mv <- data.frame(
   Moderator = c(
      "Intercept / No Spray control",
      "Early",
      "Late",
      "Late+",
      "Recommended",
      "Recommended+"
   ),
   N = PM_mv$g.levels.k,
   k = k5,
   Effect = round(PM_mv$b, 4),
   se = round(PM_mv$se, 4),
   CI_lower = round(PM_mv$ci.lb, 4),
   CI_upper = round(PM_mv$ci.ub, 4),
   z_val = round(PM_mv$zval, 4),
   p_val = reportP(PM_mv$pval, AsNumeric = FALSE, P_prefix = FALSE)
)

# rename colnames to give table headings
colnames(results_mv)[c(2:5, 7:10)] <-
   c("Treatment",
     "N",
     "k",
     "mu",
     "CI_{L}",
     "CI_{U}",
     "Z",
     "P")

yield_estimates_table <-
   flextable(results_mv[c(2, 5, 6, 3, 4), c(1, 3:8, 10)]) %>%
   align(j = 3:8, align = "center", part = "all") %>%
   fontsize(size = 8, part = "body") %>%
   fontsize(size = 10, part = "header") %>%
   italic(italic = TRUE, part = "header") %>%
   set_caption(
      "Table 2: Estimated mungbean yield mean difference to the no spray control (intercept) for each spray schedule treatment. Yield estimates (u) were calculated from a network meta-analysis of data obtained from grey literature reports of 'k' field trials undertaken in Eastern Australia. P values indicate statistical significance in comparison to the intercept."
   ) %>%
   autofit() %>%
   footnote(
      i = 1,
      j = c(2:4, 6:8),
      value = as_paragraph(
         c(
            "number of treatment means categorised to each spray schedule",
            "number of trials with the respective spray schedule",
            "estimated mean yield determined by the meta-analysis",
            "Lower range of the 95% confidence interval",
            "Upper range of the 95% confidence interval",
            "indicates the significance between each respective spray schedule and the no spray control (intercept)"
         )
      ),
      ref_symbols = letters[1:6],
      part = "header",
      inline = TRUE
   )

yield_estimates_table
```


```{r eval=FALSE, include=FALSE}
# Save table as a word document
doc <- officer::read_docx()
doc <- body_add_flextable(doc, value = yield_estimates_table)
print(doc, target = "paper/figures/Table2_yield_estimates.docx")
```

<br>  
<br>  

### Moderator estimates plot  

View the moderator comparisons in a plot.

```{r metafor_plot_yied}
results_mv %>%
   filter(Treatment != "control") %>%
   mutate(Treatment = factor(Treatment, levels = rev(
      c(
         "Early",
         "Recommended",
         "Recommended_plus",
         "Late",
         "Late_plus"
      )
   ))) %>%
   ggplot(aes(Treatment, mu)) +
   geom_hline(
      yintercept = seq(-0.05, 0.3, by = 0.05),
      color = usq_cols("usq charcoal"),
      linetype = 3
   ) +
   geom_point(aes(size = 1 / se), shape = 15) +
   geom_linerange(aes(ymin = `CI_{L}`, ymax = `CI_{U}`)) +
   coord_flip() +
   labs(caption = "Bars indicate 95% confidence intervals")+
   ylab(expression(paste(
      "Mean yield difference to control (t ha" ^ -1, ")", sep = ""
   ))) +
   scale_x_discrete(
      "Moderator variable",
      labels = c(
         expression("Late"["plus"]),
         expression("Late"["single"]),
         expression("Recommended"["plus"]),
         expression("Recommended"["single"]),
         expression("Early"["single"])
      )
   )
ggsave("paper/figures/Fig2_means_difference.png",
       height = 3,
       dpi = 500)
```

<br>  
<br>  

### Moderator contrasts

Calculate treatment contrasts

```{r PM_Mv_Contrast_yield}
source("R/simple_summary.R") #function to provide a table that includes the treatment names in the contrasts
summary(glht(PM_mv, linfct = cbind(contrMat(rep(
   1, 6
), type = "Tukey"))), test = adjusted("none"))
contrast_Ssum <-
   simple_summary(summary(glht(PM_mv, linfct = cbind(
      contrMat(rep(1, 6), type = "Tukey")
   )), test = adjusted("none")))
contrast_Ssum %>%
   flextable()%>%
   autofit()

```

These contrasts can be viewed in a plot.

```{r plotContrasts_yield}
par(mar = c(5, 13, 4, 2) + 0.1)
plot(glht(PM_mv, linfct = cbind(contrMat(rep(
   1, 6
), type = "Tukey"))), yaxt = 'n')
axis(
   2,
   at = seq_along(contrast_Ssum$contrast),
   labels = rev(contrast_Ssum$contrast),
   las = 2,
   cex.axis = 0.8
)
```



### Profile plots

An inspection of the profile plots to ensure the model is not over-fitted can be undertaken.
We expect to see the estimate align with the peak of the curve.
Also that the shape of the line is a curve.
As these plots take a long time to generate they will not be evaluated.

```{r profile_plots, eval=FALSE, echo=TRUE, results="hide"}
profile(PM_mv, tau2 = 1)
profile(PM_mv, tau2 = 2)
profile(PM_mv, tau2 = 3)
profile(PM_mv, tau2 = 4)
profile(PM_mv, tau2 = 5)
profile(PM_mv, tau2 = 6)
```


<br>  
<br>  
<br>  

******  


## netmeta analysis

The `netmeta` package can provide a graphical representation of the pairwise comparisons.

The `netmeta` package uses a frequentist approach focusing on the pairwise comparisons between treatments. 
These results can be used to evaluate if our outcome with the `metafor` package was robust.

```{r netmeta-analysis}
datPM3 <- PM_dat_Y %>%
   group_by(trial, spray_management, replicates) %>%
   summarize(yi_mean = mean(grain_yield.t.ha.),
             vi_mean = mean(vi)) %>%
   ungroup()

PM_con <- pairwise(
   treat = spray_management,
   n = replicates,
   mean = yi_mean,
   sd = sqrt(vi_mean),
   studlab = trial,
   data = datPM3,
   sm = "MD"
)

net_con <- netmeta(TE,
                   seTE,
                   treat1,
                   treat2,
                   studlab,
                   data = PM_con,
                   sm = "MD")

summary(net_con)
```

<br>  
<br>  


### netmeta estimates plot
Visualise netmeta results as a forest plot.

```{r netmeta-forest}
forest(
   net_con,
   reference.group = 1,
   rightcols = c("effect", "ci", "Pscore"),
   rightlabs = "P-Score",
   small.values = "bad"
)
```
<br>  
<br>  
<br>  

******  

### Moderator netgraph

The `netmeta` analysis suggests the spray schedule commencing early are no different to any other treatment including the no spray `control`.
It estimates the mean is very similar to the recommended treatments.
The `Recommended_plus` and `Late_plus` treatments show higher mean estimates, however are not significantly different from the `Early` estimate.

```{r netgraphGW}
netgraph(
   net_con,
   plastic = FALSE,
   col = usq_cols("support orange"),
   thickness =  "number.of.studies",
   points = FALSE,
   col.points = usq_cols("usq charcoal"),
   cex.points = 1,
   number.of.studies = TRUE,
   cex.number.of.studies = 1,
   col.number.of.studies = "black",
   bg.number.of.studies = usq_cols("support orange"),
   multiarm = FALSE,
   col.multiarm = usq_cols("support turquiose"),
   pos.number.of.studies = 0.4
)
```

<br>  
<br>  
<br>  

******  

```{r}
netleague(net_con)

decomp.design(net_con)

netsplit(net_con)

nm1 <- netmeasures(net_con)

plot(
   nm1$meanpath,
   nm1$minpar,
   pch = "",
   xlab = "Mean path length",
   ylab = "Minimal parallelism"
)
text(nm1$meanpath, nm1$minpar, names(nm1$meanpath), cex = 0.8)
```



```{r Save_meta_data, eval=FALSE}
save(PM_dat_Y,
     PM_mv,
     contrast_Ssum,
     file = here("cache/Meta-analysisData.Rdata"))
```


