[
["meta-analysis.html", "5 Meta-analysis 5.1 Grain yield meta-analysis 5.2 Meta-analysis", " 5 Meta-analysis 5.1 Grain yield meta-analysis Let’s get started with the analysis by first finding the best model fit that answers our research question. Which spray management scenario provides the greatest yield protection from powdery mildew. Grain yield is our response variable. Trial, which resolves combinations of categorical variables: year, location, row spacing and cultivar; is set as a random intercept. We will test spray management (our treatment) as a fixed effect and random slope to trial. m8 &lt;- lmer(grain_yield.t.ha * 1000 ~ factor(spray_management) + (factor(spray_management) | trial_ref), data = slimmer_PM_dat) ## boundary (singular) fit: see ?isSingular m9 &lt;- lmer(log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (factor(spray_management) | trial_ref), data = slimmer_PM_dat) ## boundary (singular) fit: see ?isSingular m10 &lt;- lmer(log(grain_yield.t.ha * 1000) ~ (factor(spray_management) | trial_ref), data = slimmer_PM_dat) ## boundary (singular) fit: see ?isSingular m11 &lt;- lmer(log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (1 | trial_ref), data = slimmer_PM_dat) anova(m8, m9) # m9 is significantly better model ## refitting model(s) with ML (instead of REML) ## Data: slimmer_PM_dat ## Models: ## m8: grain_yield.t.ha * 1000 ~ factor(spray_management) + (factor(spray_management) | ## m8: trial_ref) ## m9: log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (factor(spray_management) | ## m9: trial_ref) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m8 21 2096.44 2159.80 -1027.22 2054.44 ## m9 21 -29.36 34.01 35.68 -71.36 2125.8 0 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(m9, m10) # m9 is significantly better model ## refitting model(s) with ML (instead of REML) ## Data: slimmer_PM_dat ## Models: ## m10: log(grain_yield.t.ha * 1000) ~ (factor(spray_management) | trial_ref) ## m9: log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (factor(spray_management) | ## m9: trial_ref) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m10 17 -25.584 25.710 29.792 -59.584 ## m9 21 -29.357 34.006 35.678 -71.357 11.773 4 0.01912 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(m9, m11) # m11 is a simpler model which is no different to m9 ## refitting model(s) with ML (instead of REML) ## Data: slimmer_PM_dat ## Models: ## m11: log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (1 | ## m11: trial_ref) ## m9: log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (factor(spray_management) | ## m9: trial_ref) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m11 7 -48.130 -27.009 31.065 -62.130 ## m9 21 -29.357 34.006 35.678 -71.357 9.2264 14 0.8163 The best model from the four above is m9 with the lower AIC of -29.357. summary(m9) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## log(grain_yield.t.ha * 1000) ~ factor(spray_management) + (factor(spray_management) | ## trial_ref) ## Data: slimmer_PM_dat ## ## REML criterion at convergence: -50.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.58718 -0.51727 0.04068 0.58676 1.96151 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## trial_ref (Intercept) 2.442e-01 0.494173 ## factor(spray_management)Early 9.264e-04 0.030436 -1.00 ## factor(spray_management)Late_plus 4.281e-03 0.065426 1.00 ## factor(spray_management)Recommended 6.291e-05 0.007931 1.00 ## factor(spray_management)Recommended_plus 5.864e-03 0.076575 1.00 ## Residual 2.323e-02 0.152403 ## ## ## ## -1.00 ## -1.00 1.00 ## -1.00 1.00 1.00 ## ## Number of obs: 151, groups: trial_ref, 17 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 6.80091 0.12274 55.411 ## factor(spray_management)Early 0.04659 0.05136 0.907 ## factor(spray_management)Late_plus 0.13618 0.05726 2.378 ## factor(spray_management)Recommended 0.10907 0.03753 2.906 ## factor(spray_management)Recommended_plus 0.14151 0.03954 3.579 ## ## Correlation of Fixed Effects: ## (Intr) fc(_)E f(_)L_ fc(_)R ## fctr(spr_)E -0.224 ## fctr(sp_)L_ 0.194 0.044 ## fctr(spr_)R -0.086 0.297 0.185 ## fctr(sp_)R_ 0.338 0.256 0.269 0.472 ## convergence code: 0 ## boundary (singular) fit: see ?isSingular This linear mixed effect model shows indicates: A single early spray before first sign of powdery mildew is not likely to increase yields. A single or single spray with one or more follow sprays starting at the recommended first spray , within 3 days of powdery mildew first sign are likely to produce significantly higher grain yields compared to the no spray control. The recommended_plus spray which has one or more follow-up sprays after first sign are likely to increase the mean grain yield. Late_plus spray treatments showed the highest mean grain yield, and was significantly higher than the no spray control. However showed no difference to either of the recommended treatments. 5.1.1 Imputing sample variances We need to impute the variances which are missing for a few of the trials. These trials mung1112/01, mung1516/03 were analysed and reported that there was no significant difference between the treatments in each trial. So therefore we need the imputed variances not to show a significant difference. There are 14 treatments without yield error in our data, and 137 where yield error was recorded. Plotting a histogram of the variances show that the yield is not normally distributed. A log transformation, however, shows a normal distribution. We can use the mean and standard deviation of the log(V) to sample variances for the treatments where V is missing. hist_usq(slimmer_PM_dat$yield_error) # yield error is not normally distributed hist_usq(log(slimmer_PM_dat$yield_error)) # a log transformation shows it is normally distributed We will evaluate whether the imputed variances confer a significant difference to the recorded means. I created a distance matrix of two standard errors above the mean against two standard errors below the mean. If any errors don’t overlap, inferring significant difference, the imputed variances are discarded and re-sampled until all treatment variances show no significant differences. # generate yield error values for (i in 0:500) { # Imputing missing log variances log_Yerror &lt;- rnorm( n = sum(is.na(slimmer_PM_dat$yield_error)), mean = mean(log(slimmer_PM_dat$yield_error), na.rm = TRUE), sd = sd(log(slimmer_PM_dat$yield_error), na.rm = TRUE) ) # First let&#39;s convert Variance to standard error for all the variables that have variance recorded slimmer_PM_dat$yield_SE &lt;- sqrt(slimmer_PM_dat$yield_error) / sqrt(slimmer_PM_dat$n) # Second; adding the imputed standard errors slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;yield_SE&quot;] &lt;- sqrt(exp(log_Yerror)) / sqrt(slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;n&quot;]) # all errorbars should overlap so they are consistant with the meta-data describing no significant difference bettween treatments # let&#39;s test to make sure if (max(outer( X = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;grain_yield.t.ha&quot;] - (2 * slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;yield_SE&quot;]), Y = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;grain_yield.t.ha&quot;] + (2 * slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;yield_SE&quot;]), FUN = &quot;-&quot; )) &gt; 0) { message( paste( &quot;\\nWarning!!: Imputed yield errors show significant differences when they should not, imputation will automatically rerun - iteration&quot;, &quot;i =&quot;, i ) ) next() } else{ message( paste( i, &quot;iterations: &quot;, &quot;imputed variances now show no significant distances :)\\n Now adding variances to data &quot; ) ) # Plot the imputed errors for each trial Vplot &lt;- slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),] %&gt;% ggplot(aes(y = grain_yield.t.ha, trial)) + #geom_point()+ geom_pointrange( ymin = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;grain_yield.t.ha&quot;] - (1.95 * slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;yield_SE&quot;]), ymax = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;grain_yield.t.ha&quot;] + (1.95 * slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;yield_SE&quot;]), position = &quot;jitter&quot; ) + ylim(0.2, 1.5) slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), &quot;yield_error&quot;] &lt;- exp(log_Yerror) print(Vplot) break() } } ## ## Warning!!: Imputed yield errors show significant differences when they should not, imputation will automatically rerun - iteration i = 0 ## ## Warning!!: Imputed yield errors show significant differences when they should not, imputation will automatically rerun - iteration i = 1 ## ## Warning!!: Imputed yield errors show significant differences when they should not, imputation will automatically rerun - iteration i = 2 ## ## Warning!!: Imputed yield errors show significant differences when they should not, imputation will automatically rerun - iteration i = 3 ## 4 iterations: imputed variances now show no significant distances :) ## Now adding variances to data The imputed variances calculated above don’t show the expected positive correlation between grain yield and variance. This is unexpected and reflects the inherent variability of the data. Therefore we will calculate the trial mean squares and use this to calculate the variance for each sample. 5.1.1.1 Imputing sample variances from Mean squares slimmer_PM_dat &lt;- read.csv(&quot;cache/slimmer_PM_clusterdat.csv&quot;) hist_usq(unique(slimmer_PM_dat$Y_Msquare)) hist_usq(log(unique(slimmer_PM_dat$Y_Msquare))) # log mean square has a more normal distribution Imputing using a log transformation of the data is required. Which trials need variance imputation? TrialMSQ &lt;- slimmer_PM_dat %&gt;% group_by(trial_ref)%&gt;% summarise(unique(Y_Msquare)) TrialMSQ[is.na(TrialMSQ$`unique(Y_Msquare)`), &quot;trial_ref&quot;] ## # A tibble: 3 x 1 ## trial_ref ## &lt;fct&gt; ## 1 mung1112/01 ## 2 mung1112/02 ## 3 mung1516/03 for (i in TrialMSQ[is.na(TrialMSQ$`unique(Y_Msquare)`),]$trial_ref) { slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, &quot;Y_Msquare&quot;] &lt;- exp(rnorm( n = 1, mean = mean(log(TrialMSQ$`unique(Y_Msquare)`), na.rm = TRUE), sd(log(TrialMSQ$`unique(Y_Msquare)`), na.rm = TRUE) )) } Before analysis let’s have a look at the trimmed down modified data. slimmer_PM_dat$spray_management &lt;- factor(slimmer_PM_dat$spray_management, levels(slimmer_PM_dat$spray_management)[rev(c(1, 2, 4, 5, 3))]) slimmer_PM_dat %&gt;% ggplot(aes(y = grain_yield.t.ha, x = spray_management)) + geom_boxplot() + #geom_point(position = &quot;jitter&quot;, alpha = 1/5)+ geom_jitter(width = 0.1, alpha = 1 / 5) + labs(x = &quot;Spray management variable&quot;, y = &quot;Grain yield (t/Ha)&quot;, title = &quot;Mean grain yield from each treatment \\n categorised by spray management scenario&quot;) + theme(plot.title = element_text(hjust = 0.5)) + geom_hline(yintercept = 0, linetype = 2) + coord_flip() There seems like no difference between the treatments, with exception to Late_plus. Let’s do this plot again, but use the proportion of yield increase compared to the no spray control as the response variable. It is also important to visualise how well the data is compared across the trial years and trials. kableExtra::kable(table(slimmer_PM_dat$spray_management, slimmer_PM_dat$year), align = rep(&#39;c&#39;, 8)) %&gt;% #commented as was redering empty, needs a look in kable_styling( &quot;striped&quot;, fixed_thead = TRUE, full_width = FALSE, position = &quot;center&quot; ) 2011 2012 2013 2015 2016 2017 2018 2019 Late_plus 0 0 0 1 7 0 12 0 Recommended_plus 2 6 6 1 5 24 0 2 Recommended 4 6 3 1 4 12 0 2 Early 0 0 1 0 0 12 0 0 control 4 2 4 1 3 18 6 2 Treatments Late_plus and early don’t have very good comparison to other treatments. slimmer_PM_dat$spray_management &lt;- factor(slimmer_PM_dat$spray_management, rev( c( &quot;control&quot;, &quot;Early&quot;, &quot;Recommended&quot;, &quot;Recommended_plus&quot;, &quot;Late_plus&quot; ) )) slimmer_PM_dat %&gt;% ggplot(aes(y = prop_yield_gain, x = spray_management)) + geom_boxplot() + #geom_point(position = &quot;jitter&quot;, alpha = 1/5)+ geom_jitter(width = 0.1, alpha = 1 / 5) + labs(x = &quot;Spray management variable&quot;, y = &quot;Grain yield (t/Ha)&quot;, title = &quot;Mean grain yield from each treatment \\n categorised by spray management scenario&quot;) + theme(plot.title = element_text(hjust = 0.5)) + geom_hline(yintercept = 0, linetype = 2) + coord_flip() ## Warning: Removed 40 rows containing non-finite values (stat_boxplot). ## Warning: Removed 40 rows containing missing values (geom_point). 5.2 Meta-analysis 5.2.1 metafor package Let’s load the metafor package we are using to analyse the data, then rearrange the factors we want to examine by placing the control treatment first. This way all treatments will be compared to the no spray controls. Next we are log transforming the grain yield and calculating the variance from the trial mean squares. Finally we will assign factor classes to the main variables in the meta-analysis. Note that variable trial is a combination of: Trial identifier Trial year Trial location Host genotype Trial row spacing library(metafor) ## Loading &#39;metafor&#39; package (version 2.1-0). For an overview ## and introduction to the package please type: help(metafor). ## ## Attaching package: &#39;metafor&#39; ## The following objects are masked from &#39;package:meta&#39;: ## ## baujat, forest, funnel, funnel.default, labbe, radial, trimfill slimmer_PM_dat$spray_management &lt;- factor( slimmer_PM_dat$spray_management, c( &quot;control&quot;, &quot;Early&quot;, &quot;Recommended&quot;, &quot;Recommended_plus&quot;, &quot;Late_plus&quot; ) ) slimmer_PM_dat$yi &lt;- log(slimmer_PM_dat$grain_yield.t.ha) slimmer_PM_dat$vi &lt;- slimmer_PM_dat$Y_Msquare / (slimmer_PM_dat$n * slimmer_PM_dat$grain_yield.t.ha ^ 2) slimmer_PM_dat$spray_management &lt;- factor(slimmer_PM_dat$spray_management) slimmer_PM_dat$trial_ref &lt;- factor(slimmer_PM_dat$trial_ref) slimmer_PM_dat$trial &lt;- factor(slimmer_PM_dat$trial) PM_mv_AI &lt;- rma.mv( yi, vi, mods = ~ spray_management, method = &quot;ML&quot;, random = list( ~ spray_management | trial), struct = &quot;UN&quot;, data = slimmer_PM_dat ) ## Warning: Some combinations of the levels of the inner factor never occurred. ## Corresponding rho value(s) fixed to 0. summary(PM_mv_AI) ## ## Multivariate Meta-Analysis Model (k = 151; method: ML) ## ## logLik Deviance AIC BIC AICc ## 32.8764 314.2898 -27.7528 29.5755 -21.9513 ## ## Variance Components: ## ## outer factor: trial (nlvls = 25) ## inner factor: spray_management (nlvls = 5) ## ## estim sqrt k.lvl fixed level ## tau^2.1 0.2378 0.4877 40 no control ## tau^2.2 0.2240 0.4732 13 no Early ## tau^2.3 0.2638 0.5136 32 no Recommended ## tau^2.4 0.2818 0.5308 46 no Recommended_plus ## tau^2.5 0.3073 0.5543 20 no Late_plus ## ## rho.cntr rho.Erly rho.Rcmm rho.Rcm_ rho.Lt_p cntr ## control 1 0.9862 0.9834 0.9653 0.9750 - ## Early 0.9862 1 0.9989 0.9952 0.0000 7 ## Recommended 0.9834 0.9989 1 0.9946 0.9958 21 ## Recommended_plus 0.9653 0.9952 0.9946 1 0.9988 19 ## Late_plus 0.9750 0.0000 0.9958 0.9988 1 7 ## Erly Rcmm Rcm_ Lt_p ## control no no no no ## Early - no no yes ## Recommended 6 - no no ## Recommended_plus 6 19 - no ## Late_plus 0 4 4 - ## ## Test for Residual Heterogeneity: ## QE(df = 146) = 6090.1847, p-val &lt; .0001 ## ## Test of Moderators (coefficients 2:5): ## QM(df = 4) = 12.3585, p-val = 0.0149 ## ## Model Results: ## ## estimate se zval pval ci.lb ## intrcpt -0.0495 0.0992 -0.4994 0.6175 -0.2439 ## spray_managementEarly 0.0592 0.0568 1.0430 0.2969 -0.0521 ## spray_managementRecommended 0.0974 0.0281 3.4694 0.0005 0.0424 ## spray_managementRecommended_plus 0.1193 0.0373 3.1981 0.0014 0.0462 ## spray_managementLate_plus 0.0903 0.0417 2.1670 0.0302 0.0086 ## ci.ub ## intrcpt 0.1448 ## spray_managementEarly 0.1705 ## spray_managementRecommended 0.1524 *** ## spray_managementRecommended_plus 0.1925 ** ## spray_managementLate_plus 0.1719 * ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Results show that yields in single early spray treatments are not significantly different to the no spray control. Commencing spray management schedules at first sign of disease (Recommended), or between 7 - 19 days after first sign (late) produced significantly higher yields compared to the no spray control. On average a spray schedule with two or more applications stating late (7-19 days after first sign of powdery mildew) produced the highest yields. When we compare these results to those of the linear mixed effect model there is little difference in the outcome. The most notable difference is the linear mixed-effect model is somewhat less certain about the Late_plus treatment, and the mean yield lower than the recommended_plus treatment. lme_PM &lt;- lmer(yi ~ spray_management + (spray_management | trial), data = slimmer_PM_dat) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : ## Model failed to converge with max|grad| = 0.0368245 (tol = 0.002, component 1) summary(lme_PM) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: yi ~ spray_management + (spray_management | trial) ## Data: slimmer_PM_dat ## ## REML criterion at convergence: -52.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.78722 -0.42816 0.07383 0.50593 2.54197 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## trial (Intercept) 0.2465882 0.49658 ## spray_managementEarly 0.0008349 0.02890 -1.00 ## spray_managementRecommended 0.0003844 0.01961 0.34 -0.34 ## spray_managementRecommended_plus 0.0062853 0.07928 0.89 -0.89 0.73 ## spray_managementLate_plus 0.0047713 0.06907 0.96 -0.96 0.59 ## Residual 0.0176660 0.13291 ## ## ## ## ## ## 0.98 ## ## Number of obs: 151, groups: trial, 25 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.07775 0.10168 -0.765 ## spray_managementEarly 0.04476 0.04488 0.997 ## spray_managementRecommended 0.10930 0.03302 3.310 ## spray_managementRecommended_plus 0.14381 0.03472 4.142 ## spray_managementLate_plus 0.13852 0.05005 2.768 ## ## Correlation of Fixed Effects: ## (Intr) spry_E spry_R spr_R_ ## spry_mngmnE -0.213 ## spry_mngmnR -0.098 0.289 ## spry_mngmR_ 0.273 0.257 0.493 ## spry_mngmL_ 0.172 0.048 0.191 0.261 ## convergence code: 0 ## Model failed to converge with max|grad| = 0.0368245 (tol = 0.002, component 1) *****s To make it easier to compare each of the treatments we can compute the meta-analysis contrasts. anova(PM_mv_AI, L = rbind( c(0, 1, -1, 0, 0), # early vs Recomended c(0, 1, 0, -1, 0), # early vs recommended plus c(0, 1, 0, 0, -1), # early vs Late plus c(0, 0, -1, 1, 0), # Recommended vs recommended_plus c(0, 0, -1, 0, 1), # Recommended vs Late_Plus c(0, 0, 0, -1, 1) )) # recommended_plus vs Late_plus ## ## Hypotheses: ## 1: spray_managementEarly - spray_managementRecommended = 0 ## 2: spray_managementEarly - spray_managementRecommended_plus = 0 ## 3: spray_managementEarly - spray_managementLate_plus = 0 ## 4: -spray_managementRecommended + spray_managementRecommended_plus = 0 ## 5: -spray_managementRecommended + spray_managementLate_plus = 0 ## 6: -spray_managementRecommended_plus + spray_managementLate_plus = 0 ## ## Results: ## estimate se zval pval ## 1: -0.0382 0.0561 -0.6803 0.4963 ## 2: -0.0601 0.0582 -1.0327 0.3017 ## 3: -0.0310 0.0637 -0.4873 0.6261 ## 4: 0.0219 0.0203 1.0829 0.2788 ## 5: -0.0071 0.0325 -0.2190 0.8266 ## 6: -0.0291 0.0298 -0.9745 0.3298 Results show with the exclusion of the no spray control, none of the treatments are significantly different, however, early applications treatments on average produced lower yields. Let’s view this on a plot. results_AI &lt;- data.frame(cbind(exp(PM_mv_AI$b), exp((PM_mv_AI$ci.lb)), exp(PM_mv_AI$ci.ub))) # results_AI &lt;- data.frame(cbind(PM_mv_AI$b, # (PM_mv_AI$ci.lb), # PM_mv_AI$ci.ub)) treat &lt;- c(&quot;control&quot;, &quot;Early&quot;, &quot;Recommended&quot;, &quot;Recommended_plus&quot;, &quot;Late_plus&quot;) efficacy &lt;- tbl_df(results_AI) efficacy$treat &lt;- treat efficacy$se &lt;- PM_mv_AI$se colnames(efficacy) &lt;- c(&quot;Mean&quot;, &quot;CIs_lower&quot;, &quot;CI_upper&quot;, &quot;Treatment&quot;, &quot;SE&quot;) efficacy ## # A tibble: 5 x 5 ## Mean CIs_lower CI_upper Treatment SE ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 0.952 0.784 1.16 control 0.0992 ## 2 1.06 0.949 1.19 Early 0.0568 ## 3 1.10 1.04 1.16 Recommended 0.0281 ## 4 1.13 1.05 1.21 Recommended_plus 0.0373 ## 5 1.09 1.01 1.19 Late_plus 0.0417 efficacy$Treatment &lt;- factor( efficacy$Treatment, c( &quot;control&quot;, &quot;Early&quot;, &quot;Recommended&quot;, &quot;Recommended_plus&quot;, &quot;Late_plus&quot; ) ) efficacy %&gt;% ggplot(aes(Treatment, Mean)) + geom_hline( yintercept = c(0.8, 1, 1.2, 1.4), color = &quot;grey80&quot;, linetype = 3 ) + geom_point(aes(size = 1 / SE), shape = 15) + geom_linerange(aes(ymin = CIs_lower, ymax = CI_upper)) + coord_flip() What is interesting here is that the variance in the control has increased while the treatments have decreased. This is despite the control being the best represented across all experiments. However it could also be because it also has a low number of pooled reps per trial. Let’s look at how well each of the treatments compare to each other. We can use the netmeta package to give a graphical representation of this. 5.2.2 netmeta package Let’s analyse the data again using a different statistical approach to see if our outcome with the metafor package was robust. The netmeta package uses a frequentist approach to the analysis and focuses on the pairwise comparisons between treatments. datPM3 &lt;- slimmer_PM_dat %&gt;% group_by(trial, spray_management, n) %&gt;% summarize(yi_mean = mean(yi), vi_mean = mean(vi)) %&gt;% ungroup() PM_con &lt;- pairwise( treat = spray_management, n = n, mean = yi_mean, sd = sqrt(vi_mean), studlab = trial, data = datPM3, sm = &quot;MD&quot; ) net_con &lt;- netmeta(TE, seTE, treat1, treat2, studlab, data = PM_con, sm = &quot;MD&quot;) ## Warning: Note, treatments within a comparison have been re-sorted in increasing ## order. summary(net_con) ## Number of studies: k = 25 ## Number of treatments: n = 5 ## Number of pairwise comparisons: m = 93 ## Number of designs: d = 6 ## ## Fixed effects model ## ## Treatment estimate (sm = &#39;MD&#39;): ## control Early Late_plus Recommended Recommended_plus ## control . -0.0980 -0.0459 -0.0543 -0.0835 ## Early 0.0980 . 0.0522 0.0437 0.0145 ## Late_plus 0.0459 -0.0522 . -0.0084 -0.0377 ## Recommended 0.0543 -0.0437 0.0084 . -0.0293 ## Recommended_plus 0.0835 -0.0145 0.0377 0.0293 . ## ## Lower 95%-confidence limit: ## control Early Late_plus Recommended Recommended_plus ## control . -0.1692 -0.0739 -0.0709 -0.1001 ## Early 0.0269 . -0.0237 -0.0284 -0.0577 ## Late_plus 0.0178 -0.1280 . -0.0363 -0.0655 ## Recommended 0.0377 -0.1158 -0.0195 . -0.0453 ## Recommended_plus 0.0669 -0.0866 0.0098 0.0132 . ## ## Upper 95%-confidence limit: ## control Early Late_plus Recommended Recommended_plus ## control . -0.0269 -0.0178 -0.0377 -0.0669 ## Early 0.1692 . 0.1280 0.1158 0.0866 ## Late_plus 0.0739 0.0237 . 0.0195 -0.0098 ## Recommended 0.0709 0.0284 0.0363 . -0.0132 ## Recommended_plus 0.1001 0.0577 0.0655 0.0453 . ## ## Random effects model ## ## Treatment estimate (sm = &#39;MD&#39;): ## control Early Late_plus Recommended Recommended_plus ## control . -0.0711 -0.1149 -0.0875 -0.1082 ## Early 0.0711 . -0.0438 -0.0164 -0.0371 ## Late_plus 0.1149 0.0438 . 0.0274 0.0067 ## Recommended 0.0875 0.0164 -0.0274 . -0.0207 ## Recommended_plus 0.1082 0.0371 -0.0067 0.0207 . ## ## Lower 95%-confidence limit: ## control Early Late_plus Recommended Recommended_plus ## control . -0.2008 -0.2195 -0.1518 -0.1749 ## Early -0.0586 . -0.2045 -0.1488 -0.1702 ## Late_plus 0.0102 -0.1169 . -0.0806 -0.1019 ## Recommended 0.0231 -0.1160 -0.1354 . -0.0878 ## Recommended_plus 0.0414 -0.0960 -0.1153 -0.0463 . ## ## Upper 95%-confidence limit: ## control Early Late_plus Recommended Recommended_plus ## control . 0.0586 -0.0102 -0.0231 -0.0414 ## Early 0.2008 . 0.1169 0.1160 0.0960 ## Late_plus 0.2195 0.2045 . 0.1354 0.1153 ## Recommended 0.1518 0.1488 0.0806 . 0.0463 ## Recommended_plus 0.1749 0.1702 0.1019 0.0878 . ## ## Quantifying heterogeneity / inconsistency: ## tau^2 = 0.0169; tau = 0.1298; I^2 = 90.4% [88.2%; 92.2%] ## ## Tests of heterogeneity (within designs) and inconsistency (between designs): ## Q d.f. p-value ## Total 518.84 50 &lt; 0.0001 ## Within designs 503.44 43 &lt; 0.0001 ## Between designs 15.40 7 0.0313 Now let’s visualise this as a forest plot forest( net_con, reference.group = 4, rightcols = c(&quot;effect&quot;, &quot;ci&quot;, &quot;Pscore&quot;), rightlabs = &quot;P-Score&quot;, small.values = &quot;bad&quot; ) The netmeta analysis suggests the spray schedule commencing early are no different to any other treatment including the no spray control. It estimates the mean is very similar to the recommended treatments. The recommended plus and late_plus treatments show higher mean estimates, however not significantly different from the early estimate. netgraph( net_con, plastic = FALSE, col = &quot;orange&quot;, thickness = &quot;number.of.studies&quot;, points = FALSE, col.points = &quot;black&quot;, cex.points = 1, number.of.studies = TRUE, cex.number.of.studies = 1, col.number.of.studies = &quot;black&quot;, bg.number.of.studies = &quot;orange&quot;, multiarm = FALSE, col.multiarm = &quot;lightblue&quot;, pos.number.of.studies = 0.5 ) netleague(net_con) ## League table (fixed effect model): ## ## control -0.1195 [-0.1977; -0.0412] ## -0.0980 [-0.1692; -0.0269] Early ## -0.0459 [-0.0739; -0.0178] 0.0522 [-0.0237; 0.1280] ## -0.0543 [-0.0709; -0.0377] 0.0437 [-0.0284; 0.1158] ## -0.0835 [-0.1001; -0.0669] 0.0145 [-0.0577; 0.0866] ## ## -0.0426 [-0.0753; -0.0099] -0.0614 [-0.0781; -0.0447] ## . -0.0587 [-0.1842; 0.0669] ## Late_plus -0.0290 [-0.0612; 0.0032] ## -0.0084 [-0.0363; 0.0195] Recommended ## -0.0377 [-0.0655; -0.0098] -0.0293 [-0.0453; -0.0132] ## ## -0.0839 [-0.1007; -0.0671] ## -0.0116 [-0.1421; 0.1190] ## -0.0208 [-0.0530; 0.0114] ## -0.0272 [-0.0433; -0.0110] ## Recommended_plus ## ## League table (random effects model): ## ## control -0.0911 [-0.2405; 0.0583] ## -0.0711 [-0.2008; 0.0586] Early ## -0.1149 [-0.2195; -0.0102] -0.0438 [-0.2045; 0.1169] ## -0.0875 [-0.1518; -0.0231] -0.0164 [-0.1488; 0.1160] ## -0.1082 [-0.1749; -0.0414] -0.0371 [-0.1702; 0.0960] ## ## -0.1221 [-0.2401; -0.0042] -0.0831 [-0.1483; -0.0178] ## . -0.0682 [-0.2388; 0.1024] ## Late_plus 0.0150 [-0.1200; 0.1501] ## 0.0274 [-0.0806; 0.1354] Recommended ## 0.0067 [-0.1019; 0.1153] -0.0207 [-0.0878; 0.0463] ## ## -0.1032 [-0.1718; -0.0346] ## -0.0377 [-0.2103; 0.1350] ## -0.0116 [-0.1463; 0.1230] ## -0.0200 [-0.0879; 0.0478] ## Recommended_plus decomp.design(net_con) ## Q statistics to assess homogeneity / consistency ## ## Q df p-value ## Total 518.84 50 &lt; 0.0001 ## Within designs 503.44 43 &lt; 0.0001 ## Between designs 15.40 7 0.0313 ## ## Design-specific decomposition of within-designs Q statistic ## ## Design Q df p-value ## control:Late_plus 0.82 2 0.6643 ## control:Recommended 0.15 1 0.7012 ## control:Early:Recommended:Recommended_plus 10.99 15 0.7536 ## control:Late_plus:Recommended:Recommended_plus 55.15 9 &lt; 0.0001 ## control:Recommended:Recommended_plus 436.34 16 &lt; 0.0001 ## ## Between-designs Q statistic after detaching of single designs ## ## Detached design Q df p-value ## control:Early 13.27 6 0.0390 ## control:Late_plus 13.18 6 0.0402 ## control:Recommended 15.16 6 0.0190 ## control:Early:Recommended:Recommended_plus 11.63 4 0.0203 ## control:Late_plus:Recommended:Recommended_plus 4.72 4 0.3169 ## control:Recommended:Recommended_plus 4.93 5 0.4250 ## ## Q statistic to assess consistency under the assumption of ## a full design-by-treatment interaction random effects model ## ## Q df p-value tau.within tau2.within ## Between designs 1.22 7 0.9906 0.1384 0.0191 netsplit(net_con) ## Back-calculation method to split direct and indirect evidence ## ## Fixed effect model: ## ## comparison k prop nma direct indir. Diff z p-value ## control:Early 7 0.83 -0.0980 -0.1195 0.0046 -0.1240 -1.29 0.1964 ## control:Late_plus 7 0.74 -0.0459 -0.0426 -0.0549 0.0123 0.38 0.7045 ## control:Recommended 21 0.98 -0.0543 -0.0614 0.4052 -0.4666 -6.75 &lt; 0.0001 ## control:Recommended_plus 19 0.98 -0.0835 -0.0839 -0.0700 -0.0139 -0.25 0.8014 ## Early:Late_plus 0 0 0.0522 . 0.0522 . . . ## Early:Recommended 6 0.33 0.0437 -0.0587 0.0941 -0.1528 -1.95 0.0508 ## Early:Recommended_plus 6 0.31 0.0145 -0.0116 0.0259 -0.0375 -0.47 0.6389 ## Late_plus:Recommended 4 0.75 -0.0084 -0.0290 0.0529 -0.0819 -2.50 0.0125 ## Late_plus:Recommended_plus 4 0.75 -0.0377 -0.0208 -0.0883 0.0675 2.05 0.0399 ## Recommended:Recommended_plus 19 0.99 -0.0293 -0.0272 -0.3158 0.2886 2.98 0.0029 ## ## Random effects model: ## ## comparison k prop nma direct indir. Diff z p-value ## control:Early 7 0.75 -0.0711 -0.0911 -0.0096 -0.0815 -0.53 0.5959 ## control:Late_plus 7 0.79 -0.1149 -0.1221 -0.0880 -0.0341 -0.26 0.7939 ## control:Recommended 21 0.97 -0.0875 -0.0831 -0.2362 0.1532 0.78 0.4358 ## control:Recommended_plus 19 0.95 -0.1082 -0.1032 -0.1960 0.0927 0.61 0.5402 ## Early:Late_plus 0 0 -0.0438 . -0.0438 . . . ## Early:Recommended 6 0.60 -0.0164 -0.0682 0.0620 -0.1302 -0.94 0.3455 ## Early:Recommended_plus 6 0.59 -0.0371 -0.0377 -0.0363 -0.0013 -0.01 0.9923 ## Late_plus:Recommended 4 0.64 0.0274 0.0150 0.0494 -0.0344 -0.30 0.7644 ## Late_plus:Recommended_plus 4 0.65 0.0067 -0.0116 0.0407 -0.0523 -0.45 0.6524 ## Recommended:Recommended_plus 19 0.98 -0.0207 -0.0200 -0.0485 0.0285 0.13 0.8991 ## ## Legend: ## comparison - Treatment comparison ## k - Number of studies providing direct evidence ## prop - Direct evidence proportion ## nma - Estimated treatment effect (MD) in network meta-analysis ## direct - Estimated treatment effect (MD) derived from direct evidence ## indir. - Estimated treatment effect (MD) derived from indirect evidence ## Diff - Difference between direct and indirect treatment estimates ## z - z-value of test for disagreement (direct versus indirect) ## p-value - p-value of test for disagreement (direct versus indirect) nm1 &lt;- netmeasures(net_con) plot( nm1$meanpath, nm1$minpar, pch = &quot;&quot;, xlab = &quot;Mean path length&quot;, ylab = &quot;Minimal parallelism&quot; ) text(nm1$meanpath, nm1$minpar, names(nm1$meanpath), cex = 0.8) write.csv(slimmer_PM_dat, file = &quot;data/GYmeta_data.csv&quot;) "]
]
