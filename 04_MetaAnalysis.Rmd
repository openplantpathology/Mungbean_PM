
```{r MEsummary_Libraries2, message=FALSE, include=FALSE}
if (!require("pacman"))
   install.packages("pacman")
pacman::p_load(tidyverse,
               kableExtra,
               bomrang,
               lme4,
               RColorBrewer,
               metafor,
               netmeta)

if (!require("theme.usq"))
   devtools::install_github("adamhsparks/theme.usq")
library(theme.usq)
theme_set(theme_usq())

# Data
slimmer_PM_dat <- read.csv("cache/slimmer_PM_clusterdat.csv"
)
```

# Grain yield meta-analysis

Let's get started with the analysis by first finding the best model fit that answers our research question.

> Which spray management scenario provides the greatest yield protection from powdery mildew.

To do this, in our model:

   - Grain yield is our response variable and will be converted to kg / ha

   - Trial, which resolves combinations of categorical variables: year, location, row spacing, fungicide dose and cultivar; is set as a random intercept

   - We will test spray management (our treatment) as a fixed effect and random slope to trial

First, how well does the data compare across the trial years and trials?

```{r table_of_nTreatments}
# class spray_management as a factor and reorder them for the plot
slimmer_PM_dat$spray_management <-
   factor(slimmer_PM_dat$spray_management, rev(
      c(
         "control",
         "Early",
         "Recommended",
         "Recommended_plus",
         "Late",
         "Late_plus"
      )
   ))

ggplot(slimmer_PM_dat, aes(x = as.factor(year), fill = spray_management)) +
   geom_bar(position = "dodge2") +
   scale_fill_usq(name = "Spray Management") +
   xlab("Year")

kable(
   table(slimmer_PM_dat$spray_management, slimmer_PM_dat$year),
   align = rep('c', 8),
   caption = "Which treatments and how many treatments are represented in each year"
) %>%
   kable_styling(
      "striped",
      fixed_thead = TRUE,
      full_width = FALSE,
      position = "center"
   )
```

Treatments `Late_plus` and `Early` don't have very good comparison to other treatments.

Let's visualise the spread of data in each treatments with box-plots.

```{r treatment_means_plot}
slimmer_PM_dat %>%
   ggplot(
      aes(
         y = grain_yield.t.ha,
         x = spray_management,
         fill = spray_management,
         colour = spray_management
      )
   ) +
   geom_boxplot(alpha = 0.25) +
   geom_jitter(width = 0.1, alpha = 0.5) +
   labs(x = "Spray management variable",
        y = "Grain yield (t/Ha)",
        title = "Mean grain yield from each treatment \n categorised by spray management scenario") +
   theme(plot.title = element_text(hjust = 0.5)) +
   geom_hline(yintercept = 0, linetype = 2) +
   scale_fill_usq() +
   scale_colour_usq() +
   coord_flip() +
   guides(fill = FALSE, color = FALSE)
```

There seems like little difference between the treatments, with exception of `Late_plus`.
Let's do this plot again, but let's look at the proportional mean difference between the treatments and the no spray control for each study, this should reduce variation in yield due between trials.

```{r plot_yieldProportion}
slimmer_PM_dat %>%
   filter(spray_management != "control") %>% 
   ggplot(
      aes(
         y = prop_yield_gain,
         x = spray_management,
         fill = spray_management,
         colour = spray_management
      )
   ) +
   geom_boxplot(alpha = 0.25) +
   geom_jitter(width = 0.1, alpha = 0.5) +
   labs(x = "Spray management variable",
        y = "Grain yield (t/Ha)",
        title = "Mean grain yield from each treatment \n categorised by spray management scenario") +
   theme(plot.title = element_text(hjust = 0.5)) +
   geom_hline(yintercept = 0, linetype = 2) +
   scale_fill_usq() +
   scale_colour_usq() +
   coord_flip() +
   guides(fill = FALSE, color = FALSE)
```

Using the mean difference in the treatment effect seems to show the effect of each treatment better than just raw yield and reduces the variability in the treatments.
We know there is a good deal of variability in our studies and between them.
Mungbean produces variable yields between seasons so we should use a response that highlights the difference in the treatment effects that we are interested in and reduce the variability.
Let's calculate the standardised mean difference for each treatment to reduce the variability in the meta-analysis.

### Formatting Variance 

First let's remove any entries missing variance.

```{r remove_studies}
any(is.na(slimmer_PM_dat$yield_error))

slimmer_PM_dat <-
   slimmer_PM_dat[!is.na(slimmer_PM_dat$yield_error), ]

slimmer_PM_dat$vi <- slimmer_PM_dat$yield_error
```

#### Calculate sample variance from mean square errors

Currently our data frame has the sample variance calculated earlier, however we can approximate it using the mean squared error.
Let's show the rational for our calculation and then add a secondary variance column (`vi2`).

$MSE = Var + bias$

However if our MSE was calculated from an unbiased sample we can assume $bias = 0$ and therefore:

$MSE = Var$

To calculate the sample variance (for each treatment in the trial) from the mean square error (Trial variance) all we need to do is divide by the number of samples in each treatment.
We can show this because:
$MSE = \frac{\sum_{y_1}^{y_n}(y_i - \overline{y})^2}{n - 1}$
Where the sum of squares for the fungicide treatment estimator ($y$) is divided by the number of fungicide treatments ($n$).

The sample variance is a similar formula except we use $x$ instead of $y$.
$S_{Var} = \frac{\sum_{x_1}^{x_n}(x_i - \overline{x})^2}{n - 1}$  
$x$ being each observation within the experiment and $n$ being the number of samples in the whole trial.
Therefore: 
$S_{Var}\approx\frac{1}{n_{x}}\frac{\sum_{y_1}^{y_n}(y_i - \overline{y})^2}{n_y - 1}$  
Where $n_x$ is the number of samples within each treatment.

```{r MSE_2_SVar}
#calculation when using log of response
# slimmer_PM_dat$vi <-
#    slimmer_PM_dat$Y_Msquare / (slimmer_PM_dat$n * slimmer_PM_dat$grain_yield.t.ha ^
#                                   2)

slimmer_PM_dat$vi2 <- 
   slimmer_PM_dat$Y_Msquare / 
   slimmer_PM_dat$n
```

We have removed the studies that don't report any variance from the analysis.

### Calculate standardised mean differences

Let's calculate standardised mean differences and add them to the data frame.

```{r StandardisedMeanDifference}
slimmer_PM_dat$pooledSD <- NA
slimmer_PM_dat$vi_C <- NA
for (i in slimmer_PM_dat$trial_ref) {
   # First we need to Calculate the pooled standard deviation
   slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "pooledSD"] <-
      sqrt(sum((slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "n"] - 1) * slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "yield_error"]) /
              (sum(slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "n"]) - nrow(slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, ])))
   
   # Create a column with the value of the mean grain yield of the no spray
   #  control for comparisons to the treatments means
   slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "yi_C"] <-
      mean(slimmer_PM_dat[slimmer_PM_dat$trial_ref == i &
                             slimmer_PM_dat$fungicide_ai == "control",
                          "grain_yield.t.ha"], na.rm = TRUE)
   
}

# Calculate standardised mean difference
slimmer_PM_dat$grain_SMD <-
   (slimmer_PM_dat$grain_yield.t.ha - slimmer_PM_dat$yi_C) / slimmer_PM_dat$pooledSD
```

$SMD = \frac{Y_i-\overline{Y_c}}{\sigma_p}$

We can use the same sample variance with the standardised mean difference.
This is because if you add or subtract from a random variable, the variance does not change.

Let's simplify our data by removing the control data, converting disease pressure (`D_pres`) to a factor and selecting only the columns of data necessary for analysis.

```{r metafor_organisation}
dat1 <-
   slimmer_PM_dat %>%
   filter(fungicide_ai != "control") %>% #remove controls from the data
   mutate(spray_management =
             factor(
                spray_management,
                c(
                   "Early",
                   "Recommended",
                   "Recommended_plus",
                   "Late",
                   "Late_plus"
                )
             ),
          D_pres = 
             factor(D_pres,
                    c("lowD",
                      "highD"))) %>%
   select(
      trial,
      trial_ref,
      location,
      year,
      row_spacing,
      host_genotype ,
      spray_management,
      fungicide_ai,
      D_pres,
      grain_yield.t.ha,
      grain_SMD,
      dose,
      vi,
      vi2
      )
```

## metafor analysis

For the first grain yield meta-analysis, we'll use the `metafor` package [@Viechtbauer2010].

Let's inspect the data to determine if we need to transform the response variable.

```{r}
hist_usq(dat1$grain_yield.t.ha)
hist_usq(log(dat1$grain_yield.t.ha))
hist_usq(sqrt(dat1$grain_yield.t.ha))
hist_usq(dat1$grain_SMD)
```

Standardised mean differences have a bit of a long tail however this is not bad and transformations with log or square root will not work on negative values.
So it looks like no transformation is necessary before we start the meta-analysis.

Let's undertake the meta-analysis using the package `metafor`.
We are using the `spray_management` variable as a moderator and an interactive term to the `trial` random variable.
Because we want to know the difference between all treatments and we have no reference treatment, we will remove the intercept.

```{r Metafor-analysis}
PM_mv <- rma.mv(
   yi = grain_SMD,
   vi,
   mods = ~ spray_management - 1,
   method = "ML",
   random = ~ spray_management | trial,
   struct = "UN",
   data = dat1
)
summary(PM_mv)
```

In this result we can see that the `Early` treatment is not significantly different from zero, which in this case is the mean of the no spray `control`.
However the other treatments are significantly different from zero.
The $Q_M$ [omnibus test](http://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept?s[]=anova) of moderators, shows the moderators significantly influence the model ($Q_M = 24.4769, df = 5, p = 0.0002$) and we can reject the null hypothesis ($H_0 : \beta_1 = \beta_2 = \beta_3 =\beta_4 = 0$) that there is no difference between the moderators [@Viechtbauer2010].
The analysis shows there is still a significant amount of residual heterogeneity ($Q_E = 47501.76, df = 111, p < 0.0001$) not captured by the spray management moderator indicating other possible moderators which might influence grain yield.

Let's see if we can improve this model by including some other random effects and improving the random effect structure in the model.

```{r rma_noRandomInteractiveTerm}
PM_mv_St <- rma.mv(
   yi = grain_SMD,
   vi,
   mods = ~ spray_management,
   method = "ML",
   random = list( ~ 1 | trial),
   data = dat1
)

PM_mv_St1 <- rma.mv(
   yi = grain_SMD,
   vi,
   mods = ~ spray_management,
   method = "ML",
   random = list(
      ~ 1 |
         location / year / trial_ref / dose / host_genotype / factor(row_spacing) /
         spray_management
   ),
   data = dat1
)

AIC(PM_mv) # Printing the AIC of the model helps differentiate the models in the anova output
anova(PM_mv, PM_mv_St1) # PM_mv is the better model
```

The simpler `PM_mv_St` model explains significantly less variation than the more complicated model `PM_mv`.
So we will keep the original model `PM_mv`.

The first table in this output shows the tau^2 (variance) of each random effects and the number of occurrences for each treatment in the analysis.
The second table is in two parts (left and right). 
The left part, rho, is the correlation of variation between the specified treatments.
All comparisons were acceptable except for a comparison between `Early` and `Late_plus`, `0.000` rho.
`Early` and `Late_plus` treatments never occurred within the same trial, which is indicated by the right side of the table (hence the warning).

The fixed effects, in the last table, show that yields in single early spray treatments are not significantly different from zero, or the no spray control.

### Profile plots

Let's inspect the profile plots to ensure the model is not over-fitted.
We expect to see the estimate align with the peak of the curve.
Also that the shape of the line is a curve.
Caution! this will take some time to run.

```{r profile_plots, message=FALSE, results="hide"}
profile(PM_mv, tau2 = 1)
profile(PM_mv, tau2 = 2)
profile(PM_mv, tau2 = 3)
profile(PM_mv, tau2 = 4)
profile(PM_mv, tau2 = 5)
```

*****

### Metafor comparisons

To make it easier to compare each of the treatments we can compute the meta-analysis contrasts.

```{r metafor_contrasts}
meta_cont <- anova(PM_mv, L = rbind(
   c(-1, 1, 0, 0, 0),
   c(-1, 0, 1, 0, 0),
   c(-1, 0, 0, 1, 0),
   c(-1, 0, 0, 0, 1),
   c(0, -1, 1, 0, 0),
   c(0, -1, 0, 1, 0),
   c(0, -1, 0, 0, 1),
   c(0, 0, -1, 1, 0),
   c(0, 0, -1, 0, 1),
   c(0, 0, 0, -1, 1)
))

change_labels <- function(x1) {
   x1 <- gsub(pattern = "spray_management",
              replacement = "",
              x = x1)
   x1
}

source("R/p_star.R")

data.frame(
   contrasts = change_labels(meta_cont$hyp[, 1]),
   estimates = meta_cont$Lb,
   se = meta_cont$se,
   z_val = meta_cont$zval,
   pval = meta_cont$pval,
   VisP = p_star(meta_cont$pval)
)
```

Results show with the exclusion of the no spray `control`, `Early` applications are significantly worse than all other treatments leading to lower yield estimates.
`Late_plus` is estimated to save the most yield compared and is significantly higher than all other treatments except `Recommended_plus`.
Let's look at how well each of the number treatments compare to each other.

First we will format the results into a data frame.

```{r metafor_results}
results_AI <- data.frame(cbind(PM_mv$b,
                               PM_mv$ci.lb,
                               PM_mv$ci.ub))

efficacy <- as_tibble(results_AI)
efficacy$Treatment <-
   factor(c(
      "Early",
      "Recommended",
      "Recommended_plus",
      "Late",
      "Late_plus"
   ))

efficacy$se <- PM_mv$se
colnames(efficacy) <-
   c("Mean", "CIs_lower", "CI_upper", "Treatment", "SE")
efficacy
```

Let's view these comparisons in a plot.

```{r metafor_plot}
efficacy %>%
   mutate(Treatment = factor(Treatment, levels = rev(
      c(
         "Early",
         "Recommended",
         "Recommended_plus",
         "Late",
         "Late_plus"
      )
   ))) %>%
   ggplot(aes(Treatment, Mean)) +
   geom_hline(
      yintercept = seq(-0.4, 1.8, by = 0.2),
      color = usq_cols("usq charcoal"),
      linetype = 3
   ) +
   geom_hline(yintercept = 0) +
   geom_point(aes(size = 1 / SE), shape = 15) +
   geom_linerange(aes(ymin = CIs_lower, ymax = CI_upper)) +
   coord_flip()
```

### Disease pressure effect

We also want to know if disease pressure exerts an effect on the decision for spray control.
Above we can see spraying at the first sign of powdery mildew or with in `r min(as.numeric(slimmer_PM_dat[slimmer_PM_dat$spray_management == "Late"| slimmer_PM_dat$spray_management == "Late_plus","fungicide_timing_1"]))` - `r max(as.numeric(slimmer_PM_dat[slimmer_PM_dat$spray_management == "Late"|                   slimmer_PM_dat$spray_management == "Late_plus","fungicide_timing_1"]))` days after first sign is effective at mitigating yield loss.
Does this change between years of low and high disease pressure.

We will add the intercept back into this model for ease of interpretation. 
```{r D_pres-Meta}
PM_mv_Dp <- rma.mv(
   yi = grain_SMD,
   vi,
   mods = ~ spray_management *D_pres,
   method = "ML",
   random = ~ spray_management | trial,
   struct = "UN",
   data = dat1
)

summary(PM_mv_Dp)
```

These results show that the spray management variable we tested are not significantly better or worse between the two levels of disease pressure.
It also shows that in trials with high disease pressure, all treatments produced lower standardised mean differences. 
Indicating that fungicide treatments were less effective at mitigating yield loss in seasons, which developed more severe infection levels.
Finally let's compare the disease pressure model to the original model to see which one fits better.

```{r compareDvNDP}
anova(PM_mv, PM_mv_Dp)
```

No significant difference which informs us to use the original model `PM_mv`, which is the simplest.

****

## netmeta analysis

We can use the `netmeta` package to give a graphical representation of the pairwise comparisons.

Let's analyse the data again using a different statistical approach to see if our outcome with the `metafor` package was robust.
The `netmeta` package uses a frequentist approach to the analysis and focuses on the pairwise comparisons between treatments.

```{r netmeta-analysis}
datPM3 <- slimmer_PM_dat %>%
   group_by(trial, spray_management, n) %>%
   summarize(yi_mean = mean(grain_SMD),
             vi_mean = mean(yield_error)) %>%
   ungroup()

PM_con <- pairwise(
   treat = spray_management,
   n = n,
   mean = yi_mean,
   sd = sqrt(vi_mean),
   studlab = trial,
   data = datPM3,
   sm = "MD"
)

net_con <- netmeta(TE,
                   seTE,
                   treat1,
                   treat2,
                   studlab,
                   data = PM_con,
                   sm = "MD")

summary(net_con)
```

Now let's visualise this as a forest plot.

```{r netmeta-forest}
forest(
   net_con,
   reference.group = 5,
   rightcols = c("effect", "ci", "Pscore"),
   rightlabs = "P-Score",
   small.values = "bad"
)
```

The `netmeta` analysis suggests the spray schedule commencing early are no different to any other treatment including the no spray `control`.
It estimates the mean is very similar to the recommended treatments.
The `Recommended_plus` and `Late_plus` treatments show higher mean estimates, however are not significantly different from the `Early` estimate.

```{r netgraphGW}
netgraph(
   net_con,
   plastic = FALSE,
   col = usq_cols("support orange"),
   thickness =  "number.of.studies",
   points = FALSE,
   col.points = usq_cols("usq charcoal"),
   cex.points = 1,
   number.of.studies = TRUE,
   cex.number.of.studies = 1,
   col.number.of.studies = "black",
   bg.number.of.studies = usq_cols("support orange"),
   multiarm = FALSE,
   col.multiarm = usq_cols("support turquiose"),
   pos.number.of.studies = 0.5
)
```

```{r}
netleague(net_con)

decomp.design(net_con)

netsplit(net_con)

nm1 <- netmeasures(net_con)

plot(
   nm1$meanpath,
   nm1$minpar,
   pch = "",
   xlab = "Mean path length",
   ylab = "Minimal parallelism"
)
text(nm1$meanpath, nm1$minpar, names(nm1$meanpath), cex = 0.8)
```

```{r Save_meta_data, eval=FALSE}
write.csv(slimmer_PM_dat, file = "data/GYmeta_data.csv")
```
