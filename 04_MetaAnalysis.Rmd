---
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r MEsummary_Libraries2, message=FALSE, include=FALSE}
if (!require("pacman"))
   install.packages("pacman")
pacman::p_load(tidyverse,
               kableExtra,
               bomrang,
               lme4,
               RColorBrewer,
               metafor,
               here,
               netmeta,
               multcomp)

if (!require("theme.usq"))
   devtools::install_github("adamhsparks/theme.usq")
library(theme.usq)
theme_set(theme_usq())
source(here("R/reportP.R"))

# Data
slimmer_PM_dat <- read.csv("cache/slimmer_PM_clusterdat.csv"
)
```

# Grain yield meta-analysis

Let's get started with the analysis by first finding the best model fit that answers our research question.

> Which spray management scenario provides the greatest yield protection from powdery mildew.

To do this, in our model:

   - Grain yield is our response variable (t / ha)

   - Trial, which resolves combinations of categorical variables: year, location, row spacing, fungicide dose and cultivar; is set as a random intercept

   - We will test spray management (our treatment) as a fixed effect and random interactive term to trial

First, how well does the data compare across the trial years and trials?

```{r table_of_nTreatments}
# class spray_management as a factor and reorder them for the plot
slimmer_PM_dat$spray_management <-
   factor(slimmer_PM_dat$spray_management, rev(
      c(
         "control",
         "Early",
         "Recommended",
         "Recommended_plus",
         "Late",
         "Late_plus"
      )
   ))

ggplot(slimmer_PM_dat, aes(x = as.factor(year), fill = spray_management)) +
   geom_bar(position = "dodge2") +
   scale_fill_usq(name = "Spray Management") +
   xlab("Year")

kable(
   table(slimmer_PM_dat$spray_management, slimmer_PM_dat$year),
   align = rep('c', 8),
   caption = "Which treatments and how many treatments are represented in each year"
) %>%
   kable_styling(
      "striped",
      fixed_thead = TRUE,
      full_width = FALSE,
      position = "center"
   )

```
<!-- I don't like this graph, it is hard to read given that different widths don't translate to anything meaningful -->


Treatments `Late_plus` and `Early` don't have very good comparison to other treatments.

Let's visualise the spread of data in each treatments with box-plots.

```{r treatment_means_plot}
slimmer_PM_dat %>%
   ggplot(
      aes(
         y = grain_yield.t.ha,
         x = spray_management,
         fill = spray_management,
         colour = spray_management
      )
   ) +
   geom_boxplot(alpha = 0.25) +
   geom_jitter(width = 0.1, alpha = 0.5) +
   labs(x = "Spray management variable",
        y = "Grain yield (t/Ha)",
        title = "Mean grain yield from each treatment \n categorised by spray management scenario") +
   theme(plot.title = element_text(hjust = 0.5)) +
   geom_hline(yintercept = 0, linetype = 2) +
   scale_fill_usq() +
   scale_colour_usq() +
   coord_flip() +
   guides(fill = FALSE, color = FALSE)
```

There seems like little difference between the treatments, with exception of `Late_plus`.
Let's do this plot again, but let's look at the proportional mean difference between each treatment and the no spray control for each study, this should reduce variation in yield due between trials.

```{r plot_yieldProportion}
slimmer_PM_dat %>%
   filter(spray_management != "control") %>% 
   ggplot(
      aes(
         y = prop_yield_gain,
         x = spray_management,
         fill = spray_management,
         colour = spray_management
      )
   ) +
   geom_boxplot(alpha = 0.25) +
   geom_jitter(width = 0.1, alpha = 0.5) +
   labs(x = "Spray management variable",
        y = "Grain yield (t/Ha)",
        title = "Mean grain yield from each treatment \n categorised by spray management scenario") +
   theme(plot.title = element_text(hjust = 0.5)) +
   geom_hline(yintercept = 0, linetype = 2) +
   scale_fill_usq() +
   scale_colour_usq() +
   coord_flip() +
   guides(fill = FALSE, color = FALSE)
```

Using the mean difference in the treatment effect seems to show the effect of each treatment better than just raw yield and reduces the variability in the treatments.
We know there is a good deal of variability in our studies and between them.
Mungbean produces variable yields between seasons so ordinarilly we should use a response that highlights the difference in the treatment effects that we are interested in and reduce the variability.
However for an arm-based analysis we calculate the differences between control and treatment after the meta-analysis.  

### Formating the response variable

Let's inspect the response variance `grain_yield.t.ha` to see if it is normally distributed. 
In many cases a log transformation of the response variable improves the fit, due to the prevalence of log distributed data in nature. 

```{r}
hist_usq(slimmer_PM_dat$grain_yield.t.ha, main = "Grain yield (t / ha)")
hist_usq(log(slimmer_PM_dat$grain_yield.t.ha), main = "log(Grain yield (t / ha))")
hist_usq(sqrt(slimmer_PM_dat$grain_yield.t.ha), main = "sqrt(Grain yield (t / ha))")
hist_usq(slimmer_PM_dat$yield_gain, main = "Mean difference to control (t / ha)")
```
The distribution of data does not seem to be improved by transformation of the data.
We will retain the continuous variable grain_yield.t.ha as the response.
Mean differences won't be used as we are following the methodology of a ARM-based model, where mean differences are calculated following the meta-analysis.


### Formatting Variance 

First let's remove any entries missing variance.

```{r remove_studies}
any(is.na(slimmer_PM_dat$yield_error))

slimmer_PM_dat <-
   slimmer_PM_dat[!is.na(slimmer_PM_dat$yield_error), ]

slimmer_PM_dat$vi <- slimmer_PM_dat$yield_error
```

#### Calculate sample variance from mean square errors

Currently our data frame has the sample variance calculated earlier, however we can approximate it using the mean squared error.
Let's show the rational for our calculation and then add a secondary variance column (`vi2`).

$MSE = Var + bias$

However if our MSE was calculated from an unbiased sample we can assume $bias = 0$ and therefore:

$MSE = Var$

To calculate the sample variance (for each treatment in the trial) from the mean square error (Trial variance) all we need to do is divide by the number of samples in each treatment.
We can show this because:
$MSE = \frac{\sum_{y_1}^{y_n}(y_i - \overline{y})^2}{n - 1}$
Where the sum of squares for the fungicide treatment estimator ($y$) is divided by the number of fungicide treatments ($n$).

The sample variance is a similar formula except we use $x$ instead of $y$.
$S_{Var} = \frac{\sum_{x_1}^{x_n}(x_i - \overline{x})^2}{n - 1}$  
$x$ being each observation within the experiment and $n$ being the number of samples in the whole trial.
Therefore: 
$S_{Var}\approx\frac{1}{n_{x}}\frac{\sum_{y_1}^{y_n}(y_i - \overline{y})^2}{n_y - 1}$  
Where $n_x$ is the number of samples within each treatment.

```{r MSE_2_SVar}
#calculation when using log of response
# slimmer_PM_dat$vi <-
#    slimmer_PM_dat$Y_Msquare / (slimmer_PM_dat$n * slimmer_PM_dat$grain_yield.t.ha ^
#                                   2)

slimmer_PM_dat$vi2 <- 
   slimmer_PM_dat$Y_Msquare / 
   slimmer_PM_dat$n
```


Now Let's simplify our data by removing the control data, converting disease pressure (`D_pres`) to a factor and selecting only the columns of data necessary for analysis.
We will also include the mean difference or response ratio `grain_MD`, between the treatment and control as a comparison of responses.

```{r metafor_organisation}
dat1 <-
   slimmer_PM_dat %>%
   mutate(vi = vi/n) %>% 
   mutate(spray_management =
             factor(
                spray_management,
                c(
                   "control",
                   "Early",
                   "Recommended",
                   "Recommended_plus",
                   "Late",
                   "Late_plus"
                )
             ),
          D_pres = 
             factor(D_pres,
                    c("lowD",
                      "highD")),
          id = row_number()) %>%
   dplyr::select(
      trial,
      trial_ref,
      location,
      year,
      row_spacing,
      host_genotype,
      spray_management,
      fungicide_ai,
      D_pres,
      grain_yield.t.ha,
      yield_gain,
      dose,
      vi,
      yield_error,
      vi2,
      n,
      id)
```

## metafor analysis

For the first grain yield meta-analysis, we'll use the `metafor` package [@Viechtbauer2010].

To do a ARM based model we will use the package `metafor`.
We are using the `spray_management` variable as a moderator and an interactive term to the `trial` random variable.

```{r Metafor-analysis}
PM_mv <- rma.mv(
   yi = grain_yield.t.ha,
   vi,
   mods = ~ spray_management,
   method = "ML",
   random = list(~ spray_management | trial, ~1 | id), 
   struct = "UN",
   control=list(optimizer="optim"),
   data = dat1
)

summary(PM_mv)
```

The first table in this output shows the tau^2 (variance) of each random effects and the number of occurrences for each treatment in the analysis.
This effectively shows the heterogeneity between experiments for these partivular treatments.


The tau^2 also gives us the heterogeneity between trials and indicates `Recommended_plus` showed the highest heterogeneity between experiments followed by `Late_plus`, `Late` then `Recommended`, with `Early` and the no-spray `control` showing the least heterogeneity.

The second table is in two parts (left and right). 
The left part, rho, is the correlation of variation between the specified treatments.
All comparisons were acceptable except for a comparison between `Early` and `Late_plus`, `0.000` rho.
`Early` and `Late_plus` treatments never occurred within the same trial, which is indicated by the right side of the table (hence the warning).  

In this result we can see that the `Early` treatment is not significantly different to the intercept, which in this case is the mean of the no spray `control`.
However the other treatments are significantly different from the no-spray control (intercept).
The $Q_M$ [omnibus test](http://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept?s[]=anova) of moderators, shows the moderators significantly influence the model ($Q_M =$ `r PM_mv$QM` $,df =$ `r PM_mv$m`, `r reportP(PM_mv$QMp)`) and we can reject the null hypothesis ($H_0 : \beta_1 = \beta_2 = \beta_3 =\beta_4 = 0$) that there is no difference between the moderators [@Viechtbauer2010].
The analysis shows there is still a significant amount of residual heterogeneity ($Q_E =$ `r PM_mv$QM` $,df=$ `r PM_mv$k - PM_mv$m`, `r reportP(PM_mv$QEp)` ) not captured by the spray management moderator indicating other possible moderators which might influence grain yield.  


```{r PM_Mv_Contrast}
source("R/simple_summary.R")
summary(glht(PM_mv, linfct=cbind(contrMat(rep(1,6), type="Tukey"))), test=adjusted("none"))
contrast_Ssum <- simple_summary(summary(glht(PM_mv, linfct=cbind(contrMat(rep(1,6), type="Tukey"))), test=adjusted("none")))
contrast_Ssum
```

These contrasts can be viewed in a plot
```{r plotContrasts}
par(mar = c(5, 13, 4, 2) + 0.1)
plot(glht(PM_mv, linfct=cbind(contrMat(rep(1,6), type="Tukey"))), yaxt='n')
axis(2, at = seq_along(contrast_Ssum$contrast), labels = rev(contrast_Ssum$contrast), las=2, cex.axis = 0.8)
```

Does disease pressure on the crop affect the optimum spray scenario? 
Above we can see spraying at the first sign of powdery mildew or with in `r min(as.numeric(slimmer_PM_dat[slimmer_PM_dat$spray_management == "Late"| slimmer_PM_dat$spray_management == "Late_plus","fungicide_timing_1"]))` - `r max(as.numeric(slimmer_PM_dat[slimmer_PM_dat$spray_management == "Late"|                   slimmer_PM_dat$spray_management == "Late_plus","fungicide_timing_1"]))` days after first sign is effective at mitigating yield loss.
Lets test this hypothesis by adding it as a moderator and comparing the new model with the original model above.

```{r DisPressComparison}
PM_mv2 <- rma.mv(
   yi = grain_yield.t.ha,
   vi,
   mods = ~ spray_management*D_pres,
   method = "ML",
   random = list(~ spray_management | trial, ~1 | id), 
   struct = "UN",
   control=list(optimizer="optim"),
   data = dat1
)

anova(PM_mv, PM_mv2)
```
We can see that the lower $QE$ indicates that disease pressure moderator helped explain some of the residual heterogeneity in differences in grain yield between treatments. 
However according to the Wald-test the models were not significantly different and we should use the original "Reduced" model. 

The P value was close to the 0.05 cut-off so we will present the model output for the interest of the readers.
```{r DissPressMetMod}
summary(PM_mv2)
summary(glht(PM_mv2, linfct=cbind(contrMat(rep(7,12), type="Tukey"))), test=adjusted("none"))
# plot(glht(PM_mv2, linfct=cbind(contrMat(rep(7,12), type="Tukey")))) # I think this plot is too busy to be incorporated
```



### Profile plots

Let's inspect the profile plots to ensure the model is not over-fitted.
We expect to see the estimate align with the peak of the curve.
Also that the shape of the line is a curve.
Caution! this will take some time to run.

```{r profile_plots, eval=FALSE, message=FALSE, include=FALSE, results="hide"}
profile(PM_mv, tau2 = 1)
profile(PM_mv, tau2 = 2)
profile(PM_mv, tau2 = 3)
profile(PM_mv, tau2 = 4)
profile(PM_mv, tau2 = 5)
```

Lets present the meta-analysis results for the moderator variables in a forest style plot.
First lets create a table of the results.

```{r metafor_results}
results_AI <- data.frame(cbind(PM_mv$b,
                               PM_mv$ci.lb,
                               PM_mv$ci.ub))

efficacy <- as_tibble(results_AI)
efficacy$Treatment <-
   factor(c(
      
       "control",
      "Early",
      "Recommended",
      "Recommended_plus",
      "Late",
      "Late_plus"
   ))

efficacy$se <- PM_mv$se
colnames(efficacy) <-
   c("Mean", "CIs_lower", "CI_upper", "Treatment", "SE")
efficacy
```

Let's view these comparisons in a plot.

```{r metafor_plot}
YieldContrasts <- efficacy %>%
   filter(Treatment != "control") %>% 
   mutate(Treatment = factor(Treatment, levels = rev(
      c(
         
         "Early",
         "Recommended",
         "Recommended_plus",
         "Late",
         "Late_plus"
      )
   ))) %>%
   ggplot(aes(Treatment, Mean)) +
   geom_hline(
      yintercept = seq(-0.05, 0.3, by = 0.05),
      color = usq_cols("usq charcoal"),
      linetype = 3
   ) +
   geom_hline(yintercept = 0) +
   geom_point(aes(size = 1 / SE), shape = 15) +
   geom_linerange(aes(ymin = CIs_lower, ymax = CI_upper)) +
   coord_flip()

YieldContrasts
```

### Forest plot of trial treatment effect per trial
Lets look at the trial variability in this model with a forest plot
```{r forestP, fig.height= 40, fig.width=17}
# THIS NEEDS TO BE FIXED
source(here("R/change_labels.R"))
source(here("R/forest_rows.R"))

### Sort and arrange data-frame accordingly and produce a index vector to inform the order of each "Trial" on the plot
index1 <- dat1 %>%
   mutate(ID = seq_along(trial_ref)) %>%
   mutate(spray_management = 
             factor(spray_management, 
                    levels = c("Early","Late","Recommended",
                    "Recommended_plus","Late_plus"))) %>%
   arrange(desc(spray_management), location, desc(grain_yield.t.ha)) %>%
   mutate(ID2 = order(ID))%>%
   pull(ID2)

### Use forest rows function to return a list of where to place on the plot: sub-titles, each trial row, and summary prediction for each treatment.
### this list can be used below to reference where to plot each variable
rows1 <- forest_rows(head_row = 186, 
                     ord_var = dat1$spray_management, 
                     index = index1, 
                     gap = 5, 
                     row_offset = -2)

### A data-frame of meta-model coefficients used to produce the summary polygons for each treatment
polys <- data.frame(ref = change_labels(names(coef(PM_mv))),
                    x = c(coef(PM_mv)[1],coef(PM_mv)[1] + coef(PM_mv)[2:6]),
                    ci.lb = c(PM_mv$ci.lb[1],PM_mv$ci.lb[1] +PM_mv$ci.lb[2:6]),
                    ci.ub = c(PM_mv$ci.ub[1],PM_mv$ci.ub[1] +PM_mv$ci.ub[2:6]))[c(2,5,3,4,6,1),]
polys$rows <- rows1$pred_row - 1.5

forest1  <- metafor::forest(PM_mv, cex = 1.15 , width = 5,
                #order = "fit",
                rows = rows1$trows-1.5,
                ilab = cbind(dat1$year, 
                             dat1$row_spacing, dat1$host_genotype, dat1$dose),
                ilab.xpos = c(-2.35,-2.1,-1.8,-1.4)+1,
                slab = NA, 
                xlim = c(-2, 4),
                ylim = c(5,190),
                xlab = "Grain yield mean difference",
                addfit = FALSE,
                efac = c(0.2,0.15,0.2),
                at = seq(-0.5,3, 0.5))

### code which puts lines and annotations on the plot, its a bit long...
source(here("R/add_annotations.R"))

```



****

## netmeta analysis

We can use the `netmeta` package to give a graphical representation of the pairwise comparisons.

Let's analyse the data again using a different statistical approach to see if our outcome with the `metafor` package was robust.
The `netmeta` package uses a frequentist approach to the analysis and focuses on the pairwise comparisons between treatments.

```{r netmeta-analysis}
datPM3 <- slimmer_PM_dat %>%
   group_by(trial, spray_management, n) %>%
   summarize(yi_mean = mean(grain_yield.t.ha),
             vi_mean = mean(yield_error)) %>%
   ungroup()

PM_con <- pairwise(
   treat = spray_management,
   n = n,
   mean = yi_mean,
   sd = sqrt(vi_mean),
   studlab = trial,
   data = datPM3,
   sm = "MD"
)

net_con <- netmeta(TE,
                   seTE,
                   treat1,
                   treat2,
                   studlab,
                   data = PM_con,
                   sm = "MD")

summary(net_con)
```

Now let's visualise this as a forest plot.

```{r netmeta-forest}
forest(
   net_con,
   reference.group = 1,
   rightcols = c("effect", "ci", "Pscore"),
   rightlabs = "P-Score",
   small.values = "bad"
)
```

The `netmeta` analysis suggests the spray schedule commencing early are no different to any other treatment including the no spray `control`.
It estimates the mean is very similar to the recommended treatments.
The `Recommended_plus` and `Late_plus` treatments show higher mean estimates, however are not significantly different from the `Early` estimate.

```{r netgraphGW}
netgraph(
   net_con,
   plastic = FALSE,
   col = usq_cols("support orange"),
   thickness =  "number.of.studies",
   points = FALSE,
   col.points = usq_cols("usq charcoal"),
   cex.points = 1,
   number.of.studies = TRUE,
   cex.number.of.studies = 1,
   col.number.of.studies = "black",
   bg.number.of.studies = usq_cols("support orange"),
   multiarm = FALSE,
   col.multiarm = usq_cols("support turquiose"),
   pos.number.of.studies = 0.5
)
```

```{r}
netleague(net_con)

decomp.design(net_con)

netsplit(net_con)

nm1 <- netmeasures(net_con)

plot(
   nm1$meanpath,
   nm1$minpar,
   pch = "",
   xlab = "Mean path length",
   ylab = "Minimal parallelism"
)
text(nm1$meanpath, nm1$minpar, names(nm1$meanpath), cex = 0.8)
```

```{r Save_meta_data, eval=FALSE}
write.csv(slimmer_PM_dat, file = "data/GYmeta_data.csv")
save(dat1, efficacy, PM_mv, YieldContrasts, file = here("cache/Meta-analysisData.Rdata"))
```



#### Powdery mildewMBM comparison -- Delete
One aspect we would like to consider is how the results of this meta-analysis compares to how the PowderyMildewMBM estimates the effect of fungicide applications on grain yields.
Below we create a data frame of the mitigation factors for each spray scenario so we can compare them to the outcomes of the meta-analysis.
```{r compare2PowderyMildewMDM}

PMBM <- 
   data.frame(Sprays = c(rep(1,20), rep(2,20)),
              Disease = rep(c(rep("NotPresent", 5),
                          rep("LowerCanopy", 5),
                          rep("MidCanopy", 5),
                          rep("UpperCanopy", 5)),2),
              CropMaturity = rep(c("Vegetative", "Budding", "Flowering",
                                   "EarlyPod", "LatePod"), 8),
              mitigation = c(0.57, 0.855, 0.95,0.95,0.95,
                             0.45995, 0.52919,0.5530,0.390,0.1642,
                             0.291258,0.351051, 0.2454,0.1409,0.4717,
                             0,0.059597,0.093034,0.0682476,0.0215584,
                             0.95,0.95,0.95,0.95,0.95,
                             0.766588,0.6991,0.55042,0.390056,0.1642,
                             0.485429,0.390,0.2454,0.140904,0.0471684,
                             0.0791,0.086068,0.093034,0.0682476,0.0215584))

# what is the mean age of the plant in our data when disease first occurs and we apply the first spray?
source("R/import_data.R")
PM_MB_dat <- import_data()
mean(PM_MB_dat$first_sign_disease - PM_MB_dat$planting_date, na.rm =TRUE) # 46.3 days (which is when the plant is flowering)

#What proportion of the yield was saved?
1 - (coef(PM_mv)[1] /(coef(PM_mv)[1] + coef(PM_mv)[3]))
1- (coef(PM_mv)[1] /(coef(PM_mv)[1] + coef(PM_mv)[4]))

PMBM %>%
   filter(CropMaturity == "Flowering")

```
To to a better comparison I need to know how the mitigation factor is calculated with the estimated yields.


