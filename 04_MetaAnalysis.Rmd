---
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r MEsummary_Libraries2, message=FALSE, include=FALSE}
if (!require("pacman"))
   install.packages("pacman")
pacman::p_load(tidyverse,
               kableExtra,
               bomrang,
               lme4,
               RColorBrewer,
               metafor,
               here,
               netmeta,
               multcomp)

if (!require("theme.usq"))
   devtools::install_github("adamhsparks/theme.usq")
library(theme.usq)
theme_set(theme_usq())
source(here("R/reportP.R"))

# Data
load("cache/PrepData.Rdata")
```

# Grain yield meta-analysis

Let's get started with the analysis by first finding the best model fit that answers our research question.

> Which spray management scenario provides the greatest yield protection from powdery mildew.

To do this, in our model:

   - Grain yield is our response variable (t / ha)

   - Trial, which resolves combinations of categorical variables: year, location, row spacing, fungicide dose and cultivar; is set as a random intercept

   - We will test spray management (our treatment) as a fixed effect and random interactive term to trial


```{r metafor_organisation}
dat1 <-
   PM_MB_dat %>%
   mutate(vi = vi/n) %>% 
   mutate(spray_management =
             factor(
                spray_management,
                c(
                   "control",
                   "Early",
                   "Recommended",
                   "Recommended_plus",
                   "Late",
                   "Late_plus"
                )
             ),
          D_pres = 
             factor(D_pres,
                    c("lowD",
                      "highD")),
          id = row_number()) %>%
   dplyr::select(
      trial,
      trial_ref,
      location,
      year,
      row_spacing,
      host_genotype,
      spray_management,
      fungicide_ai,
      D_pres,
      grain_yield.t.ha,
      yield_gain,
      dose,
      vi,
      yield_error,
      vi2,
      n,
      id)
```

## metafor analysis

For the first grain yield meta-analysis, we'll use the `metafor` package [@Viechtbauer2010].

To do a ARM based model we will use the package `metafor`.
We are using the `spray_management` variable as a moderator and an interactive term to the `trial` random variable.

```{r Metafor-analysis}
PM_mv <- rma.mv(
   yi = grain_yield.t.ha,
   vi,
   mods = ~ spray_management,
   method = "ML",
   random = list(~ spray_management | trial, ~1 | id), 
   struct = "UN",
   control=list(optimizer="optim"),
   data = dat1
)

summary(PM_mv)
```

The first table in this output shows the tau^2 (variance) of each random effects and the number of occurrences for each treatment in the analysis.
This effectively shows the heterogeneity between experiments for these particular treatments.


The tau^2 also gives us the heterogeneity between trials and indicates `Recommended_plus` showed the highest heterogeneity between experiments followed by `Late_plus`, `Late` then `Recommended`, with `Early` and the no-spray `control` showing the least heterogeneity.

The second table is in two parts (left and right). 
The left part, rho, is the correlation of variation between the specified treatments.
All comparisons were acceptable except for a comparison between `Early` and `Late_plus`, `0.000` rho.
`Early` and `Late_plus` treatments never occurred within the same trial, which is indicated by the right side of the table (hence the warning).  

In this result we can see that the `Early` treatment is not significantly different to the intercept, which in this case is the mean of the no spray `control`.
However the other treatments are significantly different from the no-spray control (intercept).
The $Q_M$ [omnibus test](http://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept?s[]=anova) of moderators, shows the moderators significantly influence the model ($Q_M =$ `r PM_mv$QM` $,df =$ `r PM_mv$m`, `r reportP(PM_mv$QMp)`) and we can reject the null hypothesis ($H_0 : \beta_1 = \beta_2 = \beta_3 =\beta_4 = 0$) that there is no difference between the moderators [@Viechtbauer2010].
The analysis shows there is still a significant amount of residual heterogeneity ($Q_E =$ `r PM_mv$QE` $,df=$ `r PM_mv$k - PM_mv$m`, `r reportP(PM_mv$QEp)` ) not captured by the spray management moderator indicating other possible moderators which might influence grain yield.  


```{r PM_Mv_Contrast}
source("R/simple_summary.R")
summary(glht(PM_mv, linfct=cbind(contrMat(rep(1,6), type="Tukey"))), test=adjusted("none"))
contrast_Ssum <- simple_summary(summary(glht(PM_mv, linfct=cbind(contrMat(rep(1,6), type="Tukey"))), test=adjusted("none")))
contrast_Ssum
```

These contrasts can be viewed in a plot
```{r plotContrasts}
par(mar = c(5, 13, 4, 2) + 0.1)
plot(glht(PM_mv, linfct=cbind(contrMat(rep(1,6), type="Tukey"))), yaxt='n')
axis(2, at = seq_along(contrast_Ssum$contrast), labels = rev(contrast_Ssum$contrast), las=2, cex.axis = 0.8)
```

Does disease pressure on the crop affect the optimum spray scenario? 
Above we can see spraying at the first sign of powdery mildew or with in `r min(as.numeric(PM_MB_dat[PM_MB_dat$spray_management == "Late"| PM_MB_dat$spray_management == "Late_plus","fungicide_timing_1"]))` - `r max(as.numeric(PM_MB_dat[PM_MB_dat$spray_management == "Late"|                   PM_MB_dat$spray_management == "Late_plus","fungicide_timing_1"]))` days after first sign is effective at mitigating yield loss.
Lets test this hypothesis by adding it as a moderator and comparing the new model with the original model above.

```{r DisPressComparison}
PM_mv2 <- rma.mv(
   yi = grain_yield.t.ha,
   vi,
   mods = ~ spray_management*D_pres,
   method = "ML",
   random = list(~ spray_management | trial, ~1 | id), 
   struct = "UN",
   control=list(optimizer="optim"),
   data = dat1
)

anova(PM_mv, PM_mv2)
```
We can see that the lower $QE$ indicates that disease pressure moderator helped explain some of the residual heterogeneity in differences in grain yield between treatments. 
However according to the Wald-test the models were not significantly different and we should use the original "Reduced" model. 

The P value was close to the 0.05 cut-off so we will present the model output for the interest of the readers.
```{r DissPressMetMod}
summary(PM_mv2)
summary(glht(PM_mv2, linfct=cbind(contrMat(rep(7,12), type="Tukey"))), test=adjusted("none"))
# plot(glht(PM_mv2, linfct=cbind(contrMat(rep(7,12), type="Tukey")))) # I think this plot is too busy to be incorporated
```



### Profile plots

Let's inspect the profile plots to ensure the model is not over-fitted.
We expect to see the estimate align with the peak of the curve.
Also that the shape of the line is a curve.
Caution! this will take some time to run.

```{r profile_plots, eval=FALSE, message=FALSE, include=FALSE, results="hide"}
profile(PM_mv, tau2 = 1)
profile(PM_mv, tau2 = 2)
profile(PM_mv, tau2 = 3)
profile(PM_mv, tau2 = 4)
profile(PM_mv, tau2 = 5)
```

Lets present the meta-analysis results for the moderator variables in a forest style plot.
First lets create a table of the results.

```{r metafor_results}
results_AI <- data.frame(cbind(PM_mv$b,
                               PM_mv$ci.lb,
                               PM_mv$ci.ub))

efficacy <- as_tibble(results_AI)
efficacy$Treatment <-
   factor(c(
      
       "control",
      "Early",
      "Recommended",
      "Recommended_plus",
      "Late",
      "Late_plus"
   ))

efficacy$se <- PM_mv$se
colnames(efficacy) <-
   c("Mean", "CIs_lower", "CI_upper", "Treatment", "SE")
efficacy
```

Let's view these comparisons in a plot.

```{r metafor_plot}
YieldContrasts <- efficacy %>%
   filter(Treatment != "control") %>% 
   mutate(Treatment = factor(Treatment, levels = rev(
      c(
         
         "Early",
         "Recommended",
         "Recommended_plus",
         "Late",
         "Late_plus"
      )
   ))) %>%
   ggplot(aes(Treatment, Mean)) +
   geom_hline(
      yintercept = seq(-0.05, 0.3, by = 0.05),
      color = usq_cols("usq charcoal"),
      linetype = 3
   ) +
   geom_hline(yintercept = 0) +
   geom_point(aes(size = 1 / SE), shape = 15) +
   geom_linerange(aes(ymin = CIs_lower, ymax = CI_upper)) +
   coord_flip()

YieldContrasts
```

### Forest plot of trial treatment effect per trial
Lets look at the trial variability in this model with a forest plot
```{r forestP, fig.height= 40, fig.width=17}
# THIS NEEDS TO BE FIXED
source(here("R/change_labels.R"))
source(here("R/forest_rows.R"))

### Sort and arrange data-frame accordingly and produce a index vector to inform the order of each "Trial" on the plot
index1 <- dat1 %>%
   mutate(ID = seq_along(trial_ref)) %>%
   mutate(spray_management = 
             factor(spray_management, 
                    levels = c("Early","Late","Recommended",
                    "Recommended_plus","Late_plus"))) %>%
   arrange(desc(spray_management), location, desc(grain_yield.t.ha)) %>%
   mutate(ID2 = order(ID))%>%
   pull(ID2)

### Use forest rows function to return a list of where to place on the plot: sub-titles, each trial row, and summary prediction for each treatment.
### this list can be used below to reference where to plot each variable
rows1 <- forest_rows(head_row = 186, 
                     ord_var = dat1$spray_management, 
                     index = index1, 
                     gap = 5, 
                     row_offset = -2)

### A data-frame of meta-model coefficients used to produce the summary polygons for each treatment
polys <- data.frame(ref = change_labels(names(coef(PM_mv))),
                    x = c(coef(PM_mv)[1],coef(PM_mv)[1] + coef(PM_mv)[2:6]),
                    ci.lb = c(PM_mv$ci.lb[1],PM_mv$ci.lb[1] +PM_mv$ci.lb[2:6]),
                    ci.ub = c(PM_mv$ci.ub[1],PM_mv$ci.ub[1] +PM_mv$ci.ub[2:6]))[c(2,5,3,4,6,1),]
polys$rows <- rows1$pred_row - 1.5

forest1  <- metafor::forest(PM_mv, cex = 1.15 , width = 5,
                #order = "fit",
                rows = rows1$trows-1.5,
                ilab = cbind(dat1$year, 
                             dat1$row_spacing, dat1$host_genotype, dat1$dose),
                ilab.xpos = c(-2.35,-2.1,-1.8,-1.4)+1,
                slab = NA, 
                xlim = c(-2, 4),
                ylim = c(5,190),
                xlab = "Grain yield mean difference",
                addfit = FALSE,
                efac = c(0.2,0.15,0.2),
                at = seq(-0.5,3, 0.5))

### code which puts lines and annotations on the plot, its a bit long...
source(here("R/add_annotations.R"))

```



****

## netmeta analysis

We can use the `netmeta` package to give a graphical representation of the pairwise comparisons.

Let's analyse the data again using a different statistical approach to see if our outcome with the `metafor` package was robust.
The `netmeta` package uses a frequentist approach to the analysis and focuses on the pairwise comparisons between treatments.

```{r netmeta-analysis}
datPM3 <- PM_MB_dat %>%
   group_by(trial, spray_management, n) %>%
   summarize(yi_mean = mean(grain_yield.t.ha),
             vi_mean = mean(yield_error)) %>%
   ungroup()

PM_con <- pairwise(
   treat = spray_management,
   n = n,
   mean = yi_mean,
   sd = sqrt(vi_mean),
   studlab = trial,
   data = datPM3,
   sm = "MD"
)

net_con <- netmeta(TE,
                   seTE,
                   treat1,
                   treat2,
                   studlab,
                   data = PM_con,
                   sm = "MD")

summary(net_con)
```

Now let's visualise this as a forest plot.

```{r netmeta-forest}
forest(
   net_con,
   reference.group = 1,
   rightcols = c("effect", "ci", "Pscore"),
   rightlabs = "P-Score",
   small.values = "bad"
)
```

The `netmeta` analysis suggests the spray schedule commencing early are no different to any other treatment including the no spray `control`.
It estimates the mean is very similar to the recommended treatments.
The `Recommended_plus` and `Late_plus` treatments show higher mean estimates, however are not significantly different from the `Early` estimate.

```{r netgraphGW}
netgraph(
   net_con,
   plastic = FALSE,
   col = usq_cols("support orange"),
   thickness =  "number.of.studies",
   points = FALSE,
   col.points = usq_cols("usq charcoal"),
   cex.points = 1,
   number.of.studies = TRUE,
   cex.number.of.studies = 1,
   col.number.of.studies = "black",
   bg.number.of.studies = usq_cols("support orange"),
   multiarm = FALSE,
   col.multiarm = usq_cols("support turquiose"),
   pos.number.of.studies = 0.4
)
```

```{r}
netleague(net_con)

decomp.design(net_con)

netsplit(net_con)

nm1 <- netmeasures(net_con)

plot(
   nm1$meanpath,
   nm1$minpar,
   pch = "",
   xlab = "Mean path length",
   ylab = "Minimal parallelism"
)
text(nm1$meanpath, nm1$minpar, names(nm1$meanpath), cex = 0.8)
```

```{r Save_meta_data, eval=FALSE}
save(dat1, efficacy, PM_MB_dat, PM_mv, YieldContrasts, contrast_Ssum, 
     file = here("cache/Meta-analysisData.Rdata"))
```


