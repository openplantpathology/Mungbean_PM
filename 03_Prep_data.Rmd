# Prepare data for meta-analysis

## Set environment and import data

```{r load_libraries, include=FALSE}
if (!require("pacman"))
   install.packages("pacman")
pacman::p_load(tidyverse, kableExtra, agricolae, lme4, here)
if (!require("theme.usq"))
   devtools::install_github("adamhsparks/theme.usq")
library(theme.usq)
theme_set(theme_usq())
```

```{r import_data}
PM_MB_means <- read.csv("cache/1911_PM_MB_means&Ygains.csv")

source("R/same.R") # matches each element of a vector and does not return NAs
```

## Standardising sample variance  
Meta-analyses use variance from the data to calculate the effect sizes.
The type of variance needs to be the same across all the data incorporated in the meta-analysis.

We are narrowing the meta-analysis to only include treatments using demethylation inhibitors, tebuconazole and propiconazole.
Let's look at what type of statistical error was reported for the trials that used these fungicides.

```{r variance_types}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole" |
             fungicide_ai == "propiconazole") %>%
   group_by(trial_ref, location, year , Y_error_type, fungicide_ai) %>%
   summarise(DMI_treatments = length(Y_error_type)) %>%
   arrange(Y_error_type) %>%
   select(!fungicide_ai) %>%
   kable(caption = "Number of treatments for each trial and the error type reported", align = "c") %>%
   footnote(general = "DMI - demethylation inhibitors (tebuconazole and propiconazole).")
```

The experiment summaries report either standard deviation, least square differences or no error term (`NA`). 
First we will convert LSD and standard deviation to sample variance.
Then we will impute variances for the trials, which did not report any form of variance (`NA`).

### Converting least-squares to sample variance

First let's get a list the of trials that reported LSD.

```{r all_LSD_trials}
Trials <- PM_MB_means %>%
   filter(Y_error_type == "lsd (P=0.05)") %>%
   select(trial_ref) %>%
   distinct()
Trials
```

Let's use this list of trials to subset the data and calculate sampling variances.

We will follow the method of converting 'least square differences' (LSD) to sampling variance reported by [Nugugi et.al (2011)](https://apsjournals.apsnet.org/doi/10.1094/PHYTO-08-10-0221).
A [table of T-critical values](https://www.statisticshowto.datasciencecentral.com/tables/t-distribution-table/) was consulted to select the T-crit value in the equation. 
Our data contained 30 degrees of freedom which equates to a 'T-crit' value of 1.697.

![Calculating sampling variance from mean squared error Paul et al. (2008)](Paul_etal_2008.PNG)

`Tcrit` is the T critical value for which there is significant difference between two groups.
This value is the same for both trials "mung1112/01" and "mung1112/02".

```{r LSD_2_Sampling_Variance}
Tcrit <- 1.697 # 0.05 and DFw = 30

for (i in Trials$trial_ref) {
   DFw <-
      sum(PM_MB_means[PM_MB_means$trial_ref == i, ]$replicates) -
      length(PM_MB_means[PM_MB_means$trial_ref == i, ]$replicates) # degrees of freedom within groups
   
   LSD <-
      PM_MB_means[PM_MB_means$trial_ref == i, ]$yield_error[1]
   
   
   V_yield <-
      (PM_MB_means[PM_MB_means$trial_ref == i, ]$replicates[1] * 
          (LSD / Tcrit) ^ 2) / 2 
   # method - Nugugi et.al (2011) DOI: 10.1094/phyto-08-10-0221
   
   
   for (j in seq_along(PM_MB_means[PM_MB_means$trial_ref == i,]$replicates)) {
      if (j == 1) {
         Sv <-
            vector(length = length(PM_MB_means[PM_MB_means$trial_ref == i,]$replicates))
      } # reset Sv vector if this is the first loop
      
      
      Sv[j] = V_yield /
         PM_MB_means[PM_MB_means$trial_ref == i,]$replicates[j]
      
   }
   
   # Replace the values in the dataset
   PM_MB_means[PM_MB_means$trial_ref == i,]$yield_error <-
      Sv
   PM_MB_means[PM_MB_means$trial_ref == i,]$Y_error_type <-
      "SamplingVariance"
}
```

### Converting standard deviation to sample variance

Now to estimate the variance from the standard deviation.

```{r stdev2SampVariance}
# subset data by those which describe the Yield error with standard deviation
Trials <- PM_MB_means %>%
   filter(Y_error_type == "stdev") %>%
   select(trial_ref) %>%
   distinct()


# calculate the Sampling variance from the standard deviation
# standard error of the mean equals the standard deviation divided by the square
#  root of the number of samples
# Sv <- sem^2 <- stdev/sqrt(n)
# Sampling variance equals the square of the standard error.
# Sv <- (stdev/sqrt(n))^2

# Therefore

for (j in seq_along(PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error)) {
   if (j == 1) {
      Sv <-
         vector(length = length(PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error))
   }# create empty vector at first iteration with length of j
   
   Sv[j] = (PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error[j]) ^ 2
}


# and replacing the values in the dataset
PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error <-
   Sv
PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$Y_error_type <-
   "SamplingVariance"
```


### Check variance of data-set
Our data currently uses sample variance to define the yield error.
We should expect that when yield increases so does the variance.
Let's quickly plot this to check.

```{r Var_mean_sqaures}
# redefine sample variance calculated from mean square
PM_MB_means$vi <-
   PM_MB_means$Y_Msquare /
   (PM_MB_means$n)

PM_MB_means %>%
   ggplot(aes(x = grain_yield.t.ha., y = vi)) +
   geom_point()
```

We see here that the sample variance generally decreases or has no association with the grain yield.
This might be due to the unpredictable nature of mungbeans, however going forward we will use mean squares, which defines between trial variation and is the more generic error term.

```{r Var_MeanSquarePlot}
PM_MB_means %>%
   ggplot(aes(x = grain_yield.t.ha., y = Y_Msquare)) +
   geom_point()
```


## Reduce data set to required variables

Let's tidy up the data set into a data frame of only the variables, which are required for the analysis.

First remove the irrelevant columns/variables.
Then calculate fungicide application timing variables relative to the first sign of disease.
Entries with `NA` in the grain yield or powdery mildew severity are also removed from the data.

```{r clustered_fungicide_applications}
source("R/slimming_PM_dat.R") # see R script for the code, which reduces the data.

slim_PM_dat %<>%
   mutate(fungicide_timing_1 = fungicide_application_1 - first_sign_disease) %>%
   mutate(fungicide_timing_2 = fungicide_application_2 - fungicide_application_1) %>%
   mutate(fungicide_timing_3 = fungicide_application_3 - fungicide_application_2) %>%
   filter(!is.na(grain_yield.t.ha)) %>%
   filter(!is.na(PM_final_severity))
```

### Cluster fungicide applications

We are going to define 'fungicide application timing' as a categorical variable, relative to the first sign of powdery mildew.

These categorical variables are named:

   - **Early**: First fungicide application was prior to first sign of disease.  

   - **Recommended**: First fungicide application was applied on the day powdery mildew was observed, or within three days of first sign.  

   - **Late**: First fungicide application was four or more days after first sign of disease being observed. 
Follow up fungicide applications (cluster_2 and cluster_3) were also categorised as either early, recommended or late.

```{r cluster}
slim_PM_dat %<>%
   mutate(
      cluster_1 = case_when(
         fungicide_timing_1 < 0 ~ "Early",
         fungicide_timing_1 >= 0 &
            fungicide_timing_1 < 4 ~ "Recommended",
         TRUE ~ "Late"
      )
   ) %>%
   mutate(
      cluster_2 = case_when(
         is.na(fungicide_timing_2) ~ NA_character_,
         fungicide_timing_2 < 13 ~ "Early",
         fungicide_timing_2 >= 13 &
            fungicide_timing_2 < 17 ~ "Recommended",
         TRUE ~ "Late"
      )
   ) %>%
   mutate(
      cluster_3 = case_when(
         fungicide_timing_3 < 14 ~ "Early",
         is.na(fungicide_timing_3) ~ NA_character_,
         TRUE ~ "Recommended"
      )
   )
```

Let's look at these clusters to see where we have the most degrees of freedom.

```{r cluster_clusters}
clusters <-
   unique(slim_PM_dat[c("cluster_1", "cluster_2", "cluster_3")])

for (i in 1:nrow(clusters)) {
   if (i == 1) {
      clusters$n <- NA
      clusters$n_x_trial <- NA
   }
   
   clusters[i, "n"] <-
      nrow(slim_PM_dat[same(slim_PM_dat$cluster_1, clusters[i, "cluster_1"]) &
                          same(slim_PM_dat$cluster_2, clusters[i, "cluster_2"]) &
                          same(slim_PM_dat$cluster_3, clusters[i, "cluster_3"]),])
   
   clusters[i, "n_x_trial"] <-
      length(unique(slim_PM_dat[same(slim_PM_dat$cluster_1, clusters[i, "cluster_1"]) &
                                   same(slim_PM_dat$cluster_2, clusters[i, "cluster_2"]) &
                                   same(slim_PM_dat$cluster_3, clusters[i, "cluster_3"]),
                                "trial_ref"]))
   
}

knitr::kable(clusters)
```

From this we can see that there are 16 different cluster combinations, which would make the analysis too difficult. We will reduce this to 6 levels within one variable.

Single sprays of either:

   a) early,

   b) recommended timing,

   c) late.

Two or more sprays where the first spray was either:

   d) early,

   e) recommended timing,
   
   f) late.

```{r simple_clusters}
slim_PM_dat <- slim_PM_dat %>%
   mutate(
      spray_management = case_when(
         fungicide_timing_1 < 0 &
            is.na(fungicide_application_2) &
            is.na(fungicide_application_3) ~ "Early",
         fungicide_timing_1 >= 0 &
            fungicide_timing_1 < 4 &
            is.na(fungicide_application_2) &
            is.na(fungicide_application_3) ~ "Recommended",
         fungicide_timing_1 >= 4 &
            is.na(fungicide_application_2) &
            is.na(fungicide_application_3) ~ "Late",
         fungicide_timing_1 < 0 &
            !is.na(fungicide_application_2) ~ "Early_plus",
         fungicide_timing_1 >= 0 &
            fungicide_timing_1 < 4 &
            !is.na(fungicide_application_2) ~ "Recommended_plus",
         fungicide_timing_1 >= 4 &
            !is.na(fungicide_application_2) ~ "Late_plus",
         TRUE ~ "Other"
      )
   )

slim_PM_dat[slim_PM_dat$fungicide_ai == "control",
            c(
               "fungicide_timing_1",
               "fungicide_timing_2",
               "fungicide_timing_3",
               "spray_management"
            )] <- "control"
```

Now to view the number break-down of the `spray_management` treatments

```{r tableSprayManagement}
table(slim_PM_dat$spray_management)
```

There are few 'Early_plus' treatments, these treatments therefore will have too few comparisons with other treatments in the meta-analysis to provide accurate results. Therefore we will remove 'Early_plus' from the analysis.

```{r simpler_clusters_remove}
slimmer_PM_dat <-
   slim_PM_dat[slim_PM_dat$spray_management != "Early_plus", ]
```

****

## Test dose effect

Earlier we noted there were different doses of propiconazole, which might influence our analysis.
Let's check this by comparing a linear mixed effect model including and excluding dose.
We already have a factor breaking down the dose in the `trial` variable.
Let's make a new one without dose.

```{r dose_test}
slimmer_PM_dat$trial_noDose <- paste(slimmer_PM_dat$trial_ref, slimmer_PM_dat$year,
                 slimmer_PM_dat$location,slimmer_PM_dat$host_genotype,
                 slimmer_PM_dat$row_spacing,sep = "_")

cbind(Dose = head(slimmer_PM_dat$trial),
      NoDose = head(slimmer_PM_dat$trial_noDose)) %>%
   kable()
```

Let's test the dose effect in a basic linear mixed effect model.

```{r dose_lmer}
m1 <-
   lmer(log(grain_yield.t.ha * 1000) ~ factor(spray_management) +
           (1 | trial),
        data = slimmer_PM_dat)

m2 <-
   lmer(log(grain_yield.t.ha * 1000) ~ factor(spray_management) +
           (1 | trial_noDose),
        data = slimmer_PM_dat)

anova(m1, m2)
```

Using the model without dose produces a lower AIC, however we should accept the data with dose as there is a significant difference between the models and we should accept the more complicated model `m1`.
We will retain dose as a variable inside the `trial` factor.  

```{r saveDat}
slimmer_PM_dat <-
   slimmer_PM_dat[, colnames(slimmer_PM_dat) != "trial_noDose"] #remove second trial column
```


## Disease pressure factor

We may wish to investigate the impact of spray management in mitigating the yield loss through the effect on the disease pressure.
We will set a categorical variable to indicate the amount of disease pressure in the trial, which will be evaluated on the control plot.
We will create two categories, `lowD` and `highD`.
We will use the median `AUDPC` to separate the trials into these two groups.

```{r DiseasePressure}
slimmer_PM_dat$D_pres <- NA_character_

Trial_Dpress <- slimmer_PM_dat %>%
   group_by(trial_ref) %>%
   filter(fungicide_ai == "control") %>%
   summarise(AUDPC_C = mean(AUDPC_m, na.rm = TRUE))

median_AUDPC <-
   median(as.vector(Trial_Dpress$AUDPC_C), na.rm = TRUE)
median_AUDPC

write.csv(median_AUDPC, here("cache/median_AUDPC_C.csv"), row.names = FALSE)

sort(Trial_Dpress$AUDPC_C)

for (i in unique(slimmer_PM_dat$trial_ref)) {
   if (is.na(Trial_Dpress[Trial_Dpress$trial_ref == i, "AUDPC_C"])) {
      next()
   }
   
   if (Trial_Dpress[Trial_Dpress$trial_ref == i, "AUDPC_C"] < median_AUDPC)
   {
      slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "D_pres"] <- "lowD"
   } else{
      if (Trial_Dpress[Trial_Dpress$trial_ref == i, "AUDPC_C"] >= median_AUDPC) {
         slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "D_pres"] <- "highD"
      } else{
         slimmer_PM_dat[slimmer_PM_dat$trial_ref == i, "D_pres"] <-
            NA_character_
      }
   }
}
```


Let's have a quick look to examine whether trials with high disease pressure sustain a greater yield loss.

```{r plot_disease_pressure}
slimmer_PM_dat %>%
   ggplot(aes(x = D_pres, y = grain_yield.t.ha))+
   geom_boxplot() +
   xlab("Disease pressure") +
   ylab("Grain yield (t/ha)")
```

From this plot we see that in the trials with high disease pressure tended to produce lower yields. 
There are `r length(unique(slimmer_PM_dat[is.na(slimmer_PM_dat$D_pres),"trial_ref"]))` trials that contained no data for AUDPC and thus produced `NA` values.

## Row spacing

We may want to consider row spacing in the trials.
However one of the locations has `NA` as the row spacing.
For now let's assign the most used row spacing of 0.33 m as an approximation so the model can analyse this as a continuous variable. 
If we decide to use the row_spacing column as a factor in the final model we will need to remove this approximation.  

```{r assign_row_spacing_missing}
slimmer_PM_dat[is.na(slimmer_PM_dat$row_spacing),]
slimmer_PM_dat[is.na(slimmer_PM_dat$row_spacing),"row_spacing"] <- 0.33

write.csv(slimmer_PM_dat, file = here("cache/slimmer_PM_clusterdat.csv"), row.names = FALSE)
```
