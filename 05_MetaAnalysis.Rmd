---
title: "Meta-analysis"
author: "P. Melloy"
date: "04/07/2019"
output: html_document
---

```{r MEsummary_Libraries}
library(dplyr)
library(openxlsx)
library(kableExtra)
library(ggplot2)
library(leaflet)
#source("./getPPD2.R")

```

# Meta-analysis

## Data-wrangling

```{r Meta_dataImport}
PM_MB_means <- read.csv("data/1902 powdery mildew-Mungbean - Collated means.csv", stringsAsFactors = FALSE)
PM_MB_means$grain_yield.t.ha. <- as.numeric(PM_MB_means$grain_yield.t.ha.) # NAs produced due to some cells having text description to why there is no specific data

#str(PM_MB_means)
```


When investigating previous studies into Powdery Mildew Fungicide efficacy on Mungbean `r length(unique(PM_MB_means$Trial_ref))` trials were found, however only eleven Tebeconazol were used for the following meta-analysis, followed by the next common Fungicide Propiconazole. Sulphur was disregarded due to it's inconsistancy in efficacy.

```{r Fungicides}
unique(PM_MB_means$Fungicide)
PM_MB_means %>%
   group_by(Fungicide,Trial_ref) %>%
   summarise() %>%
   count(sort = T) %>%
   rename(Trials = n) %>%
   kable()

# How many trials do we have if Tebe and Propi are pooled?

```
Tebeconazole and propiconazole might be able to be pooled as a 'Triazole' fungicide treatment. Amistar is a combination of Azoxistrobin and Cyproconazole. Perhaps Amistar and 200 g/l Tebuconazole + 120 g/l Azoxystrobin might be able to be pooled given they both contain strobins and triazole, however they contain differening dose ratio (inverted).  

Perhaps best way forward is to do an analysis of only the Triazoles. Then do another including Amistar as a comparison.


### Fungicide Doses
All trials that used Tebeconazole used approimately the same dose. dose of the active ingredient ranged from 62.35 grams per hectare to 60 grams per hectare. 
```{r Tebe_dose}
PM_MB_means %>%
   filter(Fungicide == "Tebeconazole") %>%
   select(Trial_ref, Year, Location, first_sign_disease, Dose.ai.ha., total_Fungicide) %>%
   kable()
# why are there zeros
```

### Row spacing

Some experiments were designed to investigate the effect of row spacing and plant density on Powdery Mildew disease and crop yield. The results showed that shorter distances between rows increase crop yields and mitigated the yield impact of the disease.  
Seven trials used a row spacing of 0.75 meters.

```{r row_spacing}
PM_MB_means %>%
   filter(Fungicide == "Tebeconazole") %>%
   group_by(row_spacing,Trial_ref) %>%
   summarise() %>%
   count() %>%
   rename(Trials = n) %>%
   kable()


PM_MB_means %>%
   filter(Fungicide == "Tebeconazole",
          row_spacing == 0.75) 

```
Were there any statistical diference between all row spacing or only some?  
Can we pool certain row spacings that have no significant difference?


### Host genotypes
Host genotype may need to be analysed to determine the effect.  
```{r Host_genotype}
PM_MB_means %>%
   filter(Fungicide == "Tebeconazole",
          row_spacing == 0.75) %>% 
   group_by(host_genotype, Trial_ref) %>%
   summarise() %>%
   count() %>%
   rename(Treatments = n) %>%
   kable()

```
In general the mungbean varieties have the following resistance to powdery mildew.  
   - Berken: Highly susceptible  
   - Crystal: Susceptible  
   - Jade: Moderatley susceptible  
   


### standardising the type of variance  

The type of variance needs to be standardised between trials and treatments for the meta-analysis. 

```{r variance}
   PM_MB_means %>%
   filter(Fungicide == "Tebeconazole",
          row_spacing == 0.75) %>%
   group_by(Trial_ref, Y_error.type) %>%
   summarise(Tebe_Treatments = length(Y_error.type))
```


```{r LSD_trials}
Trials <- PM_MB_means %>%
   filter(Fungicide == "Tebeconazole",
          row_spacing == 0.75,
          Y_error.type == "lsd (P=0.05)")%>%
   select(Trial_ref)%>%
   distinct()

```


The trial, `mung1112/02` uses Least squre differences to describe the variation within the experiment. The following code attempts to convert this to sampling variance as per the method in [Nugugi et.al (2011)](https://apsjournals.apsnet.org/doi/10.1094/PHYTO-08-10-0221). Ideas for using a T-critical value of 1.697 came from reading a [statisics-how-to website](https://www.statisticshowto.datasciencecentral.com/how-to-calculate-the-least-significant-difference-lsd/). A [table of T-critical values](https://www.statisticshowto.datasciencecentral.com/tables/t-distribution-table/) was consulted where 30 degrees of freedom within expeiment was used to find the 'T-crit' value of 1.697.


![Calculating sampling variance from mean squared error Paul et. al. (2008)](Paul_etal_2008.PNG)

```{r LSD_2_Sampling Variance}
# Formula and modifications based off information found at https://www.statisticshowto.datasciencecentral.com/how-to-calculate-the-least-significant-difference-lsd/

for(Trial2012 in Trials$Trial_ref){


Tcrit <- 1.697  # 0.05 and DFw = 30 # T critical value for which there is significant difference between two groups; This value is the same for both trials "mung1112/01" and "mung1112/02"
DFw <- sum(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates) - 
   length(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates) # degrees of freedom within groups
# n.A <- PM_MB_means[PM_MB_means$Trial_ref == "Trial2012,]$Replicates[1]
# n.B <- PM_MB_means[PM_MB_means$Trial_ref == "Trial2012,]$Replicates[2]
LSD <- PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Yield_error[1]


# SSwithin <- #unknown
# MSW <- SSwithin / DFw # mean square within (SS within / DF within)


#  LSD = (Tcrit) * sqrt(MSW * (1/n.A + 1/n.B))
#  (LSD/Tcrit) = sqrt(MSW * (1/n.A + 1/n.B))
#  (LSD/Tcrit)^2 = MSW * (1/n.A + 1/n.B)
#  (LSD/Tcrit)^2/(1/n.A + 1/n.B) = MSW
#  MSE <- (LSD/Tcrit)^2/(1/n.A + 1/n.B) # This formula was abandon in favor for the formula in Nugugi et. at (2011)
MSE <- PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates[1]*(LSD/Tcrit)^2/2 # method for finding variance in Nugugi et.al (2011) DOI: 10.1094/phyto-08-10-0221


for(j in seq_along(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates)){
   if(j == 1){Sv <- vector(length = length(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates))}
#  Sv[j]^2 = MSE/(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates[j] *
#                   PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$grain_yield.t.ha.[j])
# Balance equation 
   Sv[j] = sqrt(MSE/(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Replicates[j] *
                  as.numeric(PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$grain_yield.t.ha.[j])))

   }

# and replacing the values in the dataset

PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Yield_error <- Sv
PM_MB_means[PM_MB_means$Trial_ref == Trial2012,]$Y_error.type <- "SamplingVariance"

}
```


Now to estimate the variance from the standard deviation

```{r stdev2SampVariance}
# subset data by those which describe the Yield error with standard deviation
Trials <- PM_MB_means %>%
   filter(Fungicide == "Tebeconazole",
          row_spacing == 0.75,
          Y_error.type == "stdev")%>%
   select(Trial_ref)%>%
   distinct()


# calculate the Sampling variance from the standard deviation
# standard error of the mean equals the standard deviation divided by the square root of the number of samples
# Sv <- sem^2 <- stdev/sqrt(n)
# Sampling variance eqauls the square of the standard error.
# Sv <- (stdev/sqrt(n))^2

# Therefore 

for(j in seq_along(PM_MB_means[PM_MB_means$Trial_ref %in% Trials$Trial_ref,]$Yield_error)){
# create empty vector at first iteration with length of j
   if(j == 1){Sv <- vector(length = length(PM_MB_means[PM_MB_means$Trial_ref %in% Trials$Trial_ref,]$Yield_error))}

# Equation to convert standard deviation to Sampling Variance 
   Sv[j] = (PM_MB_means[PM_MB_means$Trial_ref %in% Trials$Trial_ref,]$Yield_error[j])^2
   }



   # and replacing the values in the dataset
PM_MB_means[PM_MB_means$Trial_ref %in% Trials$Trial_ref,]$Yield_error <- Sv
PM_MB_means[PM_MB_means$Trial_ref %in% Trials$Trial_ref,]$Y_error.type <- "SamplingVariance"

```


Now for the trickier part creating 'Sampling Variance' for treatments where only mean yeild is recorded.  
The trial which does not report any type of variance also reports that there is no significant difference between the means.
```{r}
NATrials <- PM_MB_means %>%
   filter(Fungicide == "Tebeconazole",
          row_spacing == 0.75,
          is.na(Y_error.type)) %>%
   select(Trial_ref)%>%
   distinct()
```

A single trial `mung1516/03` within the current scope od the meta-analysis fails to report a varience statistic. According to [Machado F. et. al (2017)](http://apsjournals.apsnet.org/doi/10.1094/PDIS-03-17-0340-RE) [Paul et. al. (2007)](https://apsjournals.apsnet.org/doi/pdfplus/10.1094/PHYTO-97-2-0211) uses linear regression model to estimate sampling variance.  

```{r na2Sampling_variance}

# for(i in PM_MB_means$Trial_ref){
# 
# log(V)[i] = a + b * log(
#    mean(subset(PM_MB_means$grain_yield.t.ha.[i], Fungicide == "control"),
#         subset(PM_MB_means$grain_yield.t.ha.[i], Fungicide == "Tebeconazole")))
# # need to know what parameters a and b are here
# # I am guessing they represent prediction parameters for each "study" for each of the treatments, "control" and Tebeconazole"
# }


# method as described by Emerson
levels(factor(PM_MB_means$Y_error.type))

PM_MB_train <- PM_MB_means %>%
   filter(Y_error.type == "SamplingVariance")

PM_MB_train$Trial_ref <- as.factor(PM_MB_train$Trial_ref)

plot(PM_MB_train$Yield_error, log(PM_MB_train$`grain_yield.t.ha.`))


library(lme4)
library(scales)
# Run a linear model with Grain_yield as a fixed effect predictor and Trial as a random intercept
PM_MB_trianLMER <- lmer(Yield_error ~ `grain_yield.t.ha.`+ 
         (1|Trial_ref), data = PM_MB_train)
summary(PM_MB_trianLMER)

# grain yeild is a significant predictor for yeild error (t value = -2.757)
# does log transformation improve the model

PM_MB_trianLMER.1 <- lmer(log(Yield_error) ~ `grain_yield.t.ha.`+ 
         (1|Trial_ref), data = PM_MB_train)
summary(PM_MB_trianLMER.1) # grain yeild is not a significant predictor of log(yeild error)
anova(PM_MB_trianLMER, PM_MB_trianLMER.1) # no significant difference between the models


PM_MB_trianLMER.2 <- lmer(Yield_error ~ log(`grain_yield.t.ha.`)+ 
         (1|Trial_ref), data = PM_MB_train)
summary(PM_MB_trianLMER.2) # log(grain yeild) is a significant predictor of yeild error
anova(PM_MB_trianLMER, PM_MB_trianLMER.2) # no significant difference between the models


#log transforming the response or predictor variables did not improve the model therefore I will leave it untransformed
# I will be using the first model PM_MB_trianLMER for further analyses beyond this point

paramA <- (summary(PM_MB_trianLMER)$coef)[2,1] # Extract the overall mean Slope to predict Yield error
InterC <- (summary(PM_MB_trianLMER)$coef)[1,1] # Extract the overall mean intercept to predict Yield error

lmer.coef <- coef(PM_MB_trianLMER) # extracting the mean random intercept for each of trial variables

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train)+
   geom_point(aes(y = Yield_error, x = `grain_yield.t.ha.`, colour = Trial_ref))+
   geom_abline(intercept = c(InterC,lmer.coef$Trial_ref[,1]), 
               slope = c(paramA,lmer.coef$Trial_ref[,2]),
               size = 1.5,
               colour = c("Black",hue_pal()(5)))
   coord_cartesian(xlim = c(0.8, 1.2))




for(i in NATrials$Trial_ref){
#Sv <- (log(PM_MB_means[PM_MB_means$Trial_ref == i,]$`grain_yield.t.ha.`) - InterC)/ paramA  # parameter from when I had the predictor and response variable flipped

Sv <- (PM_MB_means[PM_MB_means$Trial_ref == i,]$`grain_yield.t.ha.` * paramA) + InterC

PM_MB_means[PM_MB_means$Trial_ref == i,]$Yield_error <- Sv
PM_MB_means[PM_MB_means$Trial_ref == i,]$Y_error.type <- "SamplingVariance"


}
```

Just for kicks lets look at the linear regression model as a Random effects model where `grain_yield.t.ha.` is set as a random slope to the random intercept `Trial_ref`.  
The model fits better as shown by an anova comparison. But now to determine how to impute from this model ....
```{r random_slope_model}

# Run a linear model with Yield error as a fixed effect predictor and Trial as a random intercept
PM_MB_trianLMERx <- lmer(Yield_error ~ 1 + 
         (`grain_yield.t.ha.`|Trial_ref), data = PM_MB_train)

anova(PM_MB_trianLMER,PM_MB_trianLMERx) # random slope model significantly better # P = 0.00378

summary(PM_MB_trianLMERx)

InterC <- (summary(PM_MB_trianLMER)$coef)[1,1] # Extract the overall mean intercept 

lmer.coefx <- coef(PM_MB_trianLMERx)

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train)+
   geom_point(aes(y = Yield_error, x = `grain_yield.t.ha.`, colour = Trial_ref))+
   geom_abline(intercept = lmer.coefx$Trial_ref[,2], 
               slope = lmer.coefx$Trial_ref[,1],
               size = 1.5,
               colour = hue_pal()(5))+
   coord_cartesian(xlim = c(0, 3))
   


```

What is interesting about this model is the slopes all converge and pass through a specific point.
Perhaps can use this to predict the slope of the trials we don't know the specific slope for and get a better prediction of the errors.

```{r imputing_from_randomModel}
ggplot(PM_MB_train)+
   geom_point(aes(y = Yield_error, x = `grain_yield.t.ha.`, colour = Trial_ref))+
   geom_abline(intercept = lmer.coefx$Trial_ref[,2], 
               slope = lmer.coefx$Trial_ref[,1],
               size = 1.5,
               colour = hue_pal()(6))+
   coord_cartesian(xlim = c(2.85, 2.875), ylim = c(0.0048,0.0049))

# let us find the value of this point
# what are the slopes and intercepts for each random grouping factor (Trial_ref)
randomS_coefs <- lmer.coefx$Trial_ref



# lets write a funcion to generate a sequence of predicted Y (yield error) values
slope_generator <- function(slope,intercept, x_minimum = 0.8, x_maximum = 1.2, increment = 0.00000001){
   Xi <- seq(from = x_minimum, to = x_maximum, by = increment)
   (Xi * slope) + intercept
}




# generate a vector of predicted values for each of the trial slopes, returned as a matrix
tmp2 <- apply(randomS_coefs,1,FUN = function(x) {
   slope_generator(slope = x[1], intercept = x[2],x_minimum = 2.86135, x_maximum = 2.8614)
                      })
head(tmp2)




# find which X predictor gives the lowest variation between trials and therefore the closest to the point at which the slopes converge
tmp3 <- apply(tmp2,1,sd)
plot(tmp3)
min(tmp3)
x_3252 <- which(tmp3 == min(tmp3))



# zooming in on the X predictor by increasing resolution
seq(from = 2.85,to = 2.875, by =0.0001)[115]
seq(from = 2.85,to = 2.875, by =0.00001)[1139]
x_point <- seq(from = 2.86135,to = 2.8614, by =0.00000001)[x_3252]




# predict the y (yeild error) at the x predictor (grain.yield) for each trial group
tmp4 <- apply(randomS_coefs,1,FUN = function(x){
   (x_point * x[1]) + x[2]
})




# they are all the same value but lets take the mean to be more precise
y_point <- mean(tmp4)



# here is my 'good-enough' prediction of the convergence point
common_S_coordinate <- c(x_point, y_point)

```
After much deliberation I don't think this is possible to use the model with grain yield/ha as a random slope. Even though we know the grain yields and the mean in the grain yeilds we still can't predict the effect of the random intercept trial on the yield error.  
I also re-ran the model without including the trial which we used LSD to interprete the sampling variance and the model lost a lot of significance.  



