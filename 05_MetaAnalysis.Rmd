---
title: "Meta-analysis"
author: "P. Melloy"
date: "`r Sys.Date()`"
output: html_document
---


```{r MEsummary_Libraries, message=FALSE}
# install.packages("tidyverse")
# install.packages("devtools")
# devtools::install_github("https://github.com/PaulMelloy/bomrang")
# devtools::install_github("https://github.com/adamhsparks/theme.usq")
# install.packages("lme4")


library(RColorBrewer)
library(tidyverse)
library(theme.usq)
library(bomrang)
library(lme4)

```

# Meta-analysis

```{r data_import, message=FALSE, echo=FALSE}
source("R/import_data.R")
PM_MB_means <- import_data()

# see Yield vs in-season rain section on the influence of rain and irrigation on grain yield
PM_MB_means$irrigation <- NA
PM_MB_means[PM_MB_means$location == "Hermitage", "irrigation"] <- TRUE
PM_MB_means[PM_MB_means$location != "Hermitage", "irrigation"] <- FALSE

```



## Estimating variance for trials without reported error

Now for the trickier part creating 'Sampling Variance' for treatments where only mean yield is recorded.  
The trial which does not report any type of variance also reports that there is no significant difference between the means.

```{r}
NATrials <- PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
          row_spacing == 0.75,
          is.na(Y_error_type)) %>%
   select(trial_ref) %>%
   distinct()
```

A single trial `mung1516/03` within the current scope of the meta-analysis fails to report a variance statistic. According to [Machado F. et. al (2017)](http://apsjournals.apsnet.org/doi/10.1094/PDIS-03-17-0340-RE) [Paul et al. (2007)](https://apsjournals.apsnet.org/doi/pdfplus/10.1094/PHYTO-97-2-0211) uses linear regression model to estimate sampling variance.  

#### Mixed effect model to estimate variance

```{r na2Sampling_variance, message=FALSE}
library(lme4)
library(scales)

# for(i in PM_MB_means$trial_ref){
#
# log(V)[i] = a + b * log(
#    mean(subset(PM_MB_means$grain_yield.t.ha[i], fungicide_ai == "control"),
#         subset(PM_MB_means$grain_yield.t.ha[i], fungicide_ai == "tebuconazole")))
# # need to know what parameters a and b are here
# # I am guessing they represent prediction parameters for each "study" for each of the treatments, "control" and tebuconazole"
# }

# method as described by Emerson
PM_MB_train <- PM_MB_means %>%
   filter(Y_error_type == "SamplingVariance")

PM_MB_train$trial_ref <- as.factor(PM_MB_train$trial_ref)

plot(PM_MB_train$yield_error,
     log(PM_MB_train$grain_yield.t.ha))

length(unique(PM_MB_train$trial_ref))

# Run a linear model with grain_yield.t.ha as a fixed effect predictor and trial as a random intercept
PM_MB_trainLMER <- lmer(yield_error ~ grain_yield.t.ha. +
                           (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER)

# grain yield (in this model) IS a significant predictor for yield error
# (t value = 5.826)
# And the variance increases as the mean increases does log transformation
# improve the model?


PM_MB_trainLMER.1 <- lmer(log(yield_error) ~ `grain_yield.t.ha` +
                             (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER.1) # grain yield a significant predictor of log(yield error)
anova(PM_MB_trainLMER, PM_MB_trainLMER.1) # no significant difference between the models


PM_MB_trainLMER.2 <- lmer(yield_error ~ log(`grain_yield.t.ha`) +
                             (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER.2) # log(grain yeild) is a significant predictor of yield error
anova(PM_MB_trainLMER, PM_MB_trainLMER.2) # no significant difference between the models


PM_MB_trainLMER.3 <-
   lmer(log(yield_error) ~ log(`grain_yield.t.ha`) +
           (1 | trial_ref),
        data = PM_MB_train)
summary(PM_MB_trainLMER.3) # log(grain yeild) is a significant predictor of log(yielderror)
anova(PM_MB_trainLMER, PM_MB_trainLMER.3) # no significant difference between the models


# Lets try with Fungicide as a fixed effect
PM_MB_trainLMER.4 <-
   lmer(yield_error ~ `grain_yield.t.ha` + as.factor(fungicide_ai) +
           (1 | trial_ref),
        data = PM_MB_train)
summary(PM_MB_trainLMER.4)
anova(PM_MB_trainLMER, PM_MB_trainLMER.4) # no significant difference between the models



#log transforming the response or predictor variables did not improve the model therefore I will leave it untransformed
# I will be using the first model PM_MB_trainLMER for further analyses beyond this point

# Extract the model coefficients
paramA <-
   (summary(PM_MB_trainLMER)$coef)[2, 1] # Extract the overall mean slope to predict Yield error
InterC <-
   (summary(PM_MB_trainLMER)$coef)[1, 1] # Extract the overall mean intercept to predict Yield error
lmer.coef <-
   coef(PM_MB_trainLMER) # extracting the mean random intercept for each of trial variables






# for(i in NATrials$Trial_ref){
# #Sv <- (log(PM_MB_means[PM_MB_means$Trial_ref == i,]$`grain_yield.t.ha.`) - InterC)/ paramA  # parameter from when I had the predictor and response variable flipped
# 
# Sv <- (PM_MB_means[PM_MB_means$Trial_ref == i,]$`grain_yield.t.ha.` * paramA) + InterC
# 
# PM_MB_means[PM_MB_means$Trial_ref == i,]$Yield_error <- Sv
# PM_MB_means[PM_MB_means$Trial_ref == i,]$Y_error.type <- "SamplingVariance"
# }

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = c(InterC, lmer.coef$trial_ref[, 1]),
      slope = c(paramA, lmer.coef$trial_ref[, 2]),
      size = 1,
      colour = c("Black", hue_pal()(length(unique(PM_MB_train$trial_ref))))
   ) +
   coord_cartesian(xlim = c(0, 3)) +
   theme_usq()
```



```{r na2Sv_formula}
# commented until a reliable model can be written


# for (i in NATrials$trial_ref) {
#    #Sv <- (log(PM_MB_means[PM_MB_means$trial_ref == i,]$`grain_yield.t.ha`) - InterC)/ paramA  # parameter from when I had the predictor and response variable flipped
#    
#    Sv <-
#       (PM_MB_means[PM_MB_means$trial_ref == i,]$`grain_yield.t.ha` * paramA) + InterC
#    
#    PM_MB_means[PM_MB_means$trial_ref == i,]$yield_error <- Sv
#    PM_MB_means[PM_MB_means$trial_ref == i,]$Y_error_type <-
#       "SamplingVariance"
# }

```


Let's look at the model without the trial mung1718/01, as it looks to be adding some skew.

```{r lmer_remove_mung1718-01}
# remove from mung1718/01 from training dataset
PM_MB_train.2 <-
   PM_MB_train[PM_MB_train$trial_ref != "mung1718/01",]

# Rerun the model
PM_MB_trainLMER.5 <- lmer(yield_error ~ `grain_yield.t.ha` +
                             (1 | trial_ref), data = PM_MB_train.2)
summary(PM_MB_trainLMER.5) # no significant effect of mean grain yield on yield error


# Extract the cooeficients
paramA <-
   (summary(PM_MB_trainLMER.5)$coef)[2, 1] # Extract the overall mean Slope to predict Yield error
InterC <-
   (summary(PM_MB_trainLMER.5)$coef)[1, 1] # Extract the overall mean intercept to predict Yield error
lmer.coef <-
   coef(PM_MB_trainLMER.5) # extracting the mean random intercept for each of trial variables


# plot the data with the predicted slopes overlayed

ggplot(PM_MB_train.2) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = c(InterC, lmer.coef$trial_ref[, 1]),
      slope = c(paramA, lmer.coef$trial_ref[, 2]),
      size = 1,
      colour = c("Black", hue_pal()(length(unique(PM_MB_train.2$Trial_ref))))
   ) +
   coord_cartesian(ylim = c(0, 0.33)) +
   xlab("Grain Yield (t/ha)") +
   ylab("Yield Error") +
   scale_colour_discrete("Trial Reference") +
   theme_usq()

```


### Random effects model to predict trial variance
Just for kicks lets look at the linear regression model as a random effects model where `grain_yield.t.ha` is set as a random slope to the random intercept `trial_ref`.

The model fits better as shown by an ANOVA comparison. But how to impute from this model if mean variance for a trial is unknown...

```{r random_slope_model} 
# This code chunk broke with the addition of new data, I will re-inspect the data and remodel.

# Run a linear model with yield error as a fixed effect predictor and trial as a random intercept
PM_MB_trainLMERx <- lmer(yield_error ~ 1 +
                            (grain_yield.t.ha |
                                trial_ref), data = PM_MB_train)


anova(PM_MB_trainLMER, PM_MB_trainLMERx) # random slope model NOT significantly better # P = 0.6677

summary(PM_MB_trainLMERx)

InterC <-
   (summary(PM_MB_trainLMER)$coef)[1, 1] # Extract the overall mean intercept

lmer.coefx <- coef(PM_MB_trainLMERx)

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = lmer.coefx$trial_ref[, 2],
      slope = lmer.coefx$trial_ref[, 1],
      size = 1,
      colour = hue_pal()(length(unique(PM_MB_train$Trial_ref)))
   ) +
   coord_cartesian(xlim = c(0, 3),
                   ylim = c(0, 1)) +
   xlab("Grain Yield (t/ha)") +
   ylab("Yield Error") +
   scale_colour_discrete("Trial Reference") +
   theme_usq()
```
After much deliberation I don't think this is possible to use the model with grain yield t/ha as a random slope. Even though we know the grain yields and the mean of the grain yields, we still can't predict the effect of the random intercept trial on the yield error.


I also re-ran the model without including the trial in which we used LSD to interpret the sampling variance and the model lost a lot of significance.  



### Between trial variation

Emerson proposed I look at the between trial variation
```{r between_trial_variation}
unique(PM_MB_means$Y_error_type)

PM_MB_means.SV <- PM_MB_means[PM_MB_means$Y_error_type == "SamplingVariance",]
meta_mean.GY <- mean(PM_MB_means.SV$grain_yield.t.ha.,na.rm = TRUE)


# find the mean and variance of each trial
PM_MB_means_T <- PM_MB_means %>%
   filter(Y_error_type == "SamplingVariance") %>%
   group_by(trial_ref) %>%
   summarise(trial_mean = mean(grain_yield.t.ha., na.rm = TRUE),
             BW_trial_variance = sd(grain_yield.t.ha., na.rm = TRUE) ^ 2
             ) # I am not sure I have calculated between trial variance or trial variance// Should I be using a denominator (N-1) or (N), sd by default uses (N-1)

# by excluding the standard deviation of each treatment I have discarded much of the variance. Should I simulate a larger number of samples for each treatment to reflect the sample distribution of each treatment and then take the mean and standard deviation of the whole trial of the simulated data?



# update the main data set with Trial variance
SV_Trials <- unique(PM_MB_means_T$Trial_ref)
PM_MB_means$TrialVariance <- NA

for(i in SV_Trials){
   PM_MB_means[PM_MB_means$Trial_ref == i, "TrialVariance"] <- PM_MB_means_T[PM_MB_means_T$Trial_ref == i,"BW_trial_variance"]
}
PM_MB_means$TrialVariance
# OR ?
PM_MB_means <- left_join(PM_MB_means, PM_MB_means_T, by = "trial_ref")

SV_mod1 <- lm(Trial_variance ~ trial_mean, data = PM_MB_means_T)
summary(SV_mod1)

plot(Trial_variance ~ trial_mean, data = PM_MB_means_T)
abline(SV_mod1)


```


## Preliminary meta-analysis

```{r}
slim_PM_dat <- read.csv("data/slim_PM_clusterdat.csv")

m1 <- lmer(grain_yield.t.ha*1000 ~ factor(total_fungicide) + (factor(total_fungicide) | trial_ref), data = slim_PM_dat)

m2 <- lmer(grain_yield.t.ha*1000 ~ factor(total_fungicide) + (1 | trial_ref), data = slim_PM_dat)

anova(m1,m2)

m3 <- lmer(log(grain_yield.t.ha*1000) ~ factor(total_fungicide) + (factor(total_fungicide) | trial_ref), data = slim_PM_dat)

anova(m1, m3)
summary(m3)


```




```{r}
slim_PM_dat <- read.csv("data/slim_PM_clusterdat.csv")
slim_PM_dat$spray_management

m4 <- lmer(grain_yield.t.ha*1000 ~ factor(spray_management) + (factor(spray_management) | trial_ref), data = slim_PM_dat)

m5 <- lmer(log(grain_yield.t.ha*1000) ~ factor(spray_management) + (factor(spray_management) | trial_ref), data = slim_PM_dat)

anova(m4,m5) # m5 has a much lower AIC and significantly better model

summary(m5)

```







