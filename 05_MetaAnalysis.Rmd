---
title: "Meta-analysis"
author: "P. Melloy"
date: "`r Sys.Date()`"
output: html_document
---


```{r MEsummary_Libraries, message=FALSE}
# install.packages("tidyverse")
# install.packages("devtools")
# devtools::install_github("https://github.com/PaulMelloy/bomrang")
# devtools::install_github("https://github.com/adamhsparks/theme.usq")
# install.packages("lme4")


library(RColorBrewer)
library(tidyverse)
library(theme.usq)
library(bomrang)
library(lme4)
library(kableExtra)

```

# Meta-analysis

```{r data_import, message=FALSE, echo=FALSE}
source("R/import_data.R")
PM_MB_means <- import_data()

# see Yield vs in-season rain section on the influence of rain and irrigation on grain yield
PM_MB_means$irrigation <- NA
PM_MB_means[PM_MB_means$location == "Hermitage", "irrigation"] <- TRUE
PM_MB_means[PM_MB_means$location != "Hermitage", "irrigation"] <- FALSE

```



## Estimating variance for trials without reported error

Now for the trickier part creating 'Sampling Variance' for treatments where only mean yield is recorded.  
The trial which does not report any type of variance also reports that there is no significant difference between the means.

```{r}
NATrials <- PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
          row_spacing == 0.75,
          is.na(Y_error_type)) %>%
   select(trial_ref) %>%
   distinct()
```

A single trial `mung1516/03` within the current scope of the meta-analysis fails to report a variance statistic. According to [Machado F. et. al (2017)](http://apsjournals.apsnet.org/doi/10.1094/PDIS-03-17-0340-RE) [Paul et al. (2007)](https://apsjournals.apsnet.org/doi/pdfplus/10.1094/PHYTO-97-2-0211) uses linear regression model to estimate sampling variance.  


## Preliminary meta-analysis

```{r slim_lmer}
slim_PM_dat <- read.csv("data/slim_PM_clusterdat.csv")

m4 <- lmer(grain_yield.t.ha*1000 ~ factor(spray_management) + (factor(spray_management) | trial_ref), data = slim_PM_dat)

m5 <- lmer(log(grain_yield.t.ha*1000) ~ factor(spray_management) + (factor(spray_management) | trial_ref), data = slim_PM_dat)

m5.0 <- lmer(log(grain_yield.t.ha*1000) ~ factor(spray_management) + (1 | trial_ref), data = slim_PM_dat) 

anova(m4,m5) # m5 has a much lower AIC and significantly better model
anova(m5,m5.0) # no difference
```

Model 5 (m5) is a significantly better fit than model 4 (m4). Model 5.0 (m5.0), a simpler model with less variables, was not significantly different from m5. This analyis suggests that model 5.0 is the best fit.
`r summary(m5.0)`


```{r LME_cluster_disease_mod}
m6 <- lmer(grain_yield.t.ha*1000 ~ factor(spray_management) * PM_final_severity +
              (factor(spray_management) | trial_ref), 
           data = slim_PM_dat)

m7 <- lmer(log(grain_yield.t.ha*1000) ~ factor(spray_management) * PM_final_severity + 
              (factor(spray_management) | trial_ref), 
           data = slim_PM_dat)

anova(m5,m6) # 65 has a lower AIC but not evaluated as a significantly better model

summary(m6)

```


```{r LME_slimmer_cluster_disease_mod}
library(lme4)
slimmer_PM_dat <- read.csv("data/slimmer_PM_clusterdat.csv")
unique(slimmer_PM_dat$trial_ref, slimmer_PM_dat$location, slimmer_PM_dat$year)

m8 <- lmer(grain_yield.t.ha*1000 ~ factor(spray_management) +
              (factor(spray_management) | trial_ref), 
           data = slimmer_PM_dat)

m9 <- lmer(log(grain_yield.t.ha*1000) ~ factor(spray_management) + 
              (factor(spray_management) | trial_ref), 
           data = slimmer_PM_dat)

m10 <- lmer(log(grain_yield.t.ha*1000) ~ (factor(spray_management) | trial_ref), 
           data = slimmer_PM_dat)


anova(m8,m9) # m9 is significantly better model
anova(m9,m10) # m9 is significantly better model

summary(m9)

```



We need to impute the variances which are missing for a few of the trials. These trials `r paste(unique(slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),c("location","year", "trial_ref")])` were analysed and reported that there was no significant difference between the treatments in each trial. So therefore we need the imputed variances not to show a significant difference.  

There are `r sum(is.na(slimmer_PM_dat$yield_error))` treatments without yield error in our data, and `r sum(!is.na(slimmer_PM_dat$yield_error))` where yield error was recorded.  

Plotting a histogram of the variances show that the yield is not normally distributed. A log transformation, however, shows a normal disrtubution. We can use the mean and standard deviation of the log(V) to sample variances for the treatments where V is mission.  

We will evaluate wheather the imputed variances confer a significant difference to the recorded means. I created a distance matrix of two standard errors above the mean against two standard errors below the mean. If any errors don't overlap, infering signicifant difference, the imputed variances are discarded and resampled until all treatment variances show no significant differences.
### Imputing sample variances
```{r imputing_variances}

hist(slimmer_PM_dat$yield_error) # yield error is not normally distributed
hist(log(slimmer_PM_dat$yield_error)) # a log transformation shows it is normally distributed 

# generate yield error values
for(i in 0:500){

   # Imputing missing log variances
   log_Yerror <- rnorm(n = sum(is.na(slimmer_PM_dat$yield_error)),
               mean = mean(log(slimmer_PM_dat$yield_error), na.rm = TRUE),
               sd = sd(log(slimmer_PM_dat$yield_error), na.rm = TRUE)) 
   
   
   # First lets convert Variance to standard error for all the variables that have variance recorded
   slimmer_PM_dat$yield_SE <- 
      sqrt(slimmer_PM_dat$yield_error)/sqrt(slimmer_PM_dat$n)
   
   
   # Second; adding the imputed standard errors
   slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), "yield_SE"] <-
      sqrt(exp(log_Yerror))/sqrt(slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"n"]) 


# all errorbars should overlap so they are consistant with the meta-data describing no significant difference bettween treatments
# lets test to make sure
if(
   max(outer(X = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"grain_yield.t.ha"] -
               (2*slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"yield_SE"]),
             Y = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"grain_yield.t.ha"] +
               (2*slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"yield_SE"]),
             FUN = "-")
       ) > 0){
   
   message(paste("\nWarning!!: Imputed yield errors show significant differences when they should not, rerun chunk", "i =",i))
   next()
   }else{
      message(paste(i,"iterations: ", "imputed variances now show no significant distances :)\n Now adding variances to data "))
      
      # Plot the imputed errors for each trial
      Vplot <- slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),] %>%
         ggplot(aes(y = grain_yield.t.ha, trial))+
         #geom_point()+
         geom_pointrange(ymin = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"grain_yield.t.ha"] -
                            (2*slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"yield_SE"]),
                         ymax = slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"grain_yield.t.ha"] +
                            (2*slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error),"yield_SE"]),
                         position = "jitter"
                         )+
         ylim(0.2,1.5)
      
      slimmer_PM_dat[is.na(slimmer_PM_dat$yield_error), "yield_error"] <- exp(log_Yerror)
      print(Vplot)
      break()}
}

```

#### Imputing sample variances from Mean squares
```{r imputing_MSE}
slimmer_PM_dat <- read.csv("data/slimmer_PM_clusterdat.csv")
hist(unique(slimmer_PM_dat$Y_Msquare))
hist(log(unique(slimmer_PM_dat$Y_Msquare))) # log mean square has a more normal distribution


TrialMSQ <- slimmer_PM_dat %>%
   group_by(trial_ref)%>%
   summarise(unique(Y_Msquare))

TrialMSQ[is.na(TrialMSQ$`unique(Y_Msquare)`), "trial_ref"]

for(i in TrialMSQ[is.na(TrialMSQ$`unique(Y_Msquare)`),]$trial_ref){
   slimmer_PM_dat[slimmer_PM_dat$trial_ref == i,"Y_Msquare"] <- 
      exp(
         rnorm(n = 1,
               mean = mean(log(TrialMSQ$`unique(Y_Msquare)`), na.rm = TRUE),
               sd(log(TrialMSQ$`unique(Y_Msquare)`), na.rm = TRUE)
         )
      )
   }


```

Before plotting lets have a look at how the trimmed down, modified data looks.

```{r treatment_means_plot}
slimmer_PM_dat$spray_management <- factor(slimmer_PM_dat$spray_management, levels(slimmer_PM_dat$spray_management)[rev(c(1,2,4,5,3))])

slimmer_PM_dat %>%
   ggplot(aes(y = prop_yield_gain, x = spray_management))+
   geom_boxplot()+
   #geom_point(position = "jitter", alpha = 1/5)+
   geom_jitter(width = 0.1, alpha = 1/5)+
   theme_usq()+
   labs(x = "Spray management variable", 
        y = "Grain yield (t/Ha)",
        title = "Mean grain yield from each treatment \n categorised by spray management scenario")+
   theme(plot.title = element_text(hjust = 0.5))+
   coord_flip()
   

kableExtra::kable(table(slimmer_PM_dat$spray_management, slimmer_PM_dat$year), align=rep('c', 8))%>%  #commented as was redering empty, needs a look in
   kable_styling("striped", fixed_thead = TRUE, full_width = FALSE, position = "center")

```


## Meta-analysis
```{r meta_1}
library(metafor)
slimmer_PM_dat$spray_management <-
   factor(slimmer_PM_dat$spray_management,levels(slimmer_PM_dat$spray_management)[c(2,3,1,4,5)])


slimmer_PM_dat$yi <- log(slimmer_PM_dat$grain_yield.t.ha)
slimmer_PM_dat$vi <- slimmer_PM_dat$Y_Msquare/(slimmer_PM_dat$n * slimmer_PM_dat$grain_yield.t.ha^2)

slimmer_PM_dat$spray_management <- factor(slimmer_PM_dat$spray_management)
slimmer_PM_dat$trial_ref <- factor(slimmer_PM_dat$trial_ref)
slimmer_PM_dat$trial <- factor(slimmer_PM_dat$trial)


PM_mv_AI <- rma.mv(yi,vi,
                   mods = ~ spray_management,
                   method = "ML",
                   random = list(~ spray_management | trial),
                   struct = "UN",
                   data = slimmer_PM_dat)

summary(PM_mv_AI)

```

```{r compare_meta&lmer}
lme_PM <- lmer(yi ~ spray_management + (spray_management | trial), data = slimmer_PM_dat)

summary(lme_PM)

```


```{r meta_contrasts}
anova(PM_mv_AI, L=rbind(c(0,1,-1,0,0),  # early vs late plus
                        c(0,1,0,-1,0),  # early vs recommended
                        c(0,1,0,0,-1),  # early vs recommended plus
                        c(0,0,-1,1,0),  # late plus vs recommended 
                        c(0,0,-1,0,1),  # late plus vs recommended  Plus
                        c(0,0,0,-1,1))) # recommended vs recommended plus
```
Results show that Early applications are not significantly different to the no spray control or the one and two spray management options at the recommended time. Lets view this on a plot.

```{r meta_results}
results_AI <- data.frame(cbind(exp(PM_mv_AI$b), 
                              exp((PM_mv_AI$ci.lb)),
                              exp(PM_mv_AI$ci.ub)))

results_AI <- data.frame(cbind(PM_mv_AI$b, 
                              (PM_mv_AI$ci.lb),
                              PM_mv_AI$ci.ub))

treat <- c("control", "Early", "Recommended", "Recommended_plus","Late_plus")
efficacy <- tbl_df(results_AI)
efficacy$treat <- treat
efficacy$se <- PM_mv_AI$se
colnames(efficacy) <- c("Mean", "CIsup", "CIinf", "Treatment", "SE")
efficacy
```

```{r meta_plot}
efficacy %>% 
  ggplot(aes(Treatment, Mean))+
  geom_point(aes(size=1/SE), shape=15)+
  geom_linerange(aes(ymin = CIinf, ymax = CIsup))+
  coord_flip()+
  theme_grey()+
   geom_hline(yintercept = efficacy[efficacy$Treatment == "control",]$CIinf)

```


Check the yeild 

```{r}
boxplot(slimmer_PM_dat$grain_yield.t.ha ~ slimmer_PM_dat$spray_management)


```


