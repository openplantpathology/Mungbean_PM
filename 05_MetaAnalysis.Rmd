---
title: "Meta-analysis"
author: "P. Melloy"
date: "`r Sys.Date()`"
output: html_document
---


```{r MEsummary_Libraries, message=FALSE}
install.packages("tidyverse")
install.packages("devtools")
devtools::install_github("https://github.com/PaulMelloy/bomrang")
devtools::install_github("https://github.com/adamhsparks/theme.usq")

library(tidyverse)
library(theme.usq)
library(bomrang)
source("R/import_data.R")
```

# Meta-analysis

```{r data_import, message=FALSE, echo=FALSE}
PM_MB_means <- import_data()

```

## Visualise Data

Visualise and inspect the number of factors represented in each trial.

### Fungicides

When investigating previous studies into powdery mildew fungicide efficacy on mungbean `r length(unique(PM_MB_means$trial_ref))` trials were found.
However, only eleven tebuconazole were used for the following meta-analysis, followed by the next most common fungicide, propiconazole. Sulphur was disregarded due to its inconsistency in efficacy.

```{r Fungicides}
PM_MB_means %>%
   group_by(fungicide_ai, trial_ref) %>%
   summarise() %>%
   count(sort = TRUE) %>%
   rename(Trials = n) %>%
   ggplot(aes(x = reorder(fungicide_ai, Trials), y = Trials)) +
   xlab("Fungicide active ingredient") +
   ylab("N Trials") +
   geom_col() +
   scale_fill_usq() +
   ggtitle(label = "Number of trials in which the\nspecified fungicide was used") +
   scale_colour_usq() +
   theme_usq() +
   coord_flip()
```

Tebuconazole and propiconazole might be able to be pooled as a triazole fungicide treatment. 
Amistar Xtra is a combination of azoxystrobin and cyproconazole.
Custodia is a combination of tebuconazole and azoxystrobin.
Amistar Xtra and Custodia might be able to be pooled given they both contain strobilurin and triazole, however, they contain differing dose ratios (inverted).

Perhaps best way forward is to do an analysis of only the triazoles. Then do another including azoxystrobin as a comparison.

Preliminary analysis of fungicides show there is a difference the effect of fungicide in proportion of yield saved.

### Fungicide Doses

All trials that used tebuconazole used approximately the same dose.
Dose of the active ingredient ranged from 62.35&nbsp;g per hectare to 60&nbsp;g per hectare. 

```{r tebu_dose}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole") %>%
   select(trial_ref,
          year,
          location,
          first_sign_disease,
          dose_ai.ha,
          total_fungicide) %>%
   ggplot(aes(x = as.factor(dose_ai.ha))) +
   xlab("Dose (g ai/ha)") +
   ggtitle(label = "Total number of treatments for each respective tebuconazole dose") +
   geom_bar() +
   scale_fill_usq() +
   scale_colour_usq() +
   theme_usq()
```

### Row spacing

Some experiments were designed to investigate the effect of row spacing and plant density on powdery mildew disease.
The results showed that the row spacing had no statistically significant effect on powdery mildew, but narrower rows in most cases increased yield significantly. This finding has also been shown by Kerry McKenzie's work as well.
Eight trials used a row spacing of 0.75&nbsp;meters and tebuconazole as an active ingredient (AI).

```{r row_spacing.m}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole" | fungicide_ai == "propiconazole") %>%
   group_by(fungicide_ai, row_spacing, trial_ref) %>%
   summarise() %>%
   count() %>%
   rename(Trials = n) %>%
   ggplot(aes(x = as.factor(row_spacing), y = Trials)) +
   xlab("Row Spacing (m)") +
   ylab("N Trials") +
   ggtitle(label = "Trial row spacings using tebuconazole") +
   geom_col(aes(fill = fungicide_ai),
            position = "dodge") +
   scale_fill_usq(name = "Fungicide AI") +
   theme_usq()

PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
         row_spacing == 0.75) %>% 
   glimpse()
```

Were there any statistical difference between all row spacing or only some?
Can we pool certain row spacings that have no significant difference?
From the preliminary analysis, the graphs seem to imply that if there is a lower overall yield there is no effect of row spacing on yield.
However, if the average yield is more than approximately 0.6 - 1 t/ha then smaller row spacing has the potential to provide greater yield.

### Host genotypes

Host genotype may need to be analysed to determine the effect.

```{r Host_genotype}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
         row_spacing == 0.75) %>%
   group_by(host_genotype, trial_ref) %>%
   summarise() %>%
   count() %>%
   rename(Treatments = n) %>%
   ggplot(aes(x = host_genotype, y = Treatments)) +
   xlab("Cultivar") +
   ylab("N Trials") +
   ggtitle(label = "Cultivars used in tebuconazole trials with 0.75 m row spacing") +
   geom_col() +
   scale_fill_usq() +
   scale_colour_usq() +
   theme_usq()
```

In general the mungbean varieties have the following resistance to powdery mildew.

   - Berken: Highly susceptible
   
   - Crystal: Susceptible
   
   - Jade: Moderately susceptible

#### Genotype yield variability

Host genotype seems to contribute to the variation in yield. Berken shows higher yields compared to crystal and jade.
```{r yield_vol}
source("R/yield_volatility.r") #function to investigate the volatility in yields

yield_volatility(genotype_by_trial = FALSE, control_only = FALSE)
yield_volatility(genotype_by_trial = FALSE, control_only = TRUE)
yield_volatility(genotype_by_trial = FALSE, control_only = FALSE, location = "Hermitage")

yield_volatility("Crystal",control_only = TRUE)
yield_volatility("Crystal",control_only = FALSE)

yield_volatility("Jade",control_only = TRUE)
yield_volatility("Jade",control_only = FALSE, location = "Hermitage")

```

## Yield vs in-season rain

```{r yield_from_rain}
experiment_sites <- read.csv("data/Mungbean_experiment_sites.csv", stringsAsFactors = FALSE)

rain_dat <- PM_MB_means[!is.na(PM_MB_means$planting_date),] # Which locations don't have NA for planting date
unique(as.character(rain_dat$location)) # locations with recorded planting date

rain_dat_sum <- rain_dat %>%
   group_by(trial_ref) %>%
   summarise(location = unique(location),
             planting_date = unique(as.character(planting_date))[1],
             grain_yield = mean(grain_yield.t.ha., na.rm = TRUE))

rain_dat_sum <- rain_dat_sum[order(rain_dat_sum$location),] # order them to make adding the lat long easier

rain_dat_sum$lat <- NA
rain_dat_sum$lon <- NA

# 
rain_dat_sum[rain_dat_sum$location == "Bongeen_1", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Bongeen 1 & 2",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Hermitage", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Hermitage Research Station",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Gatton", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Gatton",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Kingaroy", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Red Vale & Kingaroy Research Station",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Missen Flats", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Missen Flats",c("lat","lon")]

# sweep_for_stations(latlon = unlist(c(rain_dat_sum[rain_dat_sum$location == "Premer", c("lat","lon")])))[2,c("lon")]
# closest weather to Premer does not have rain, recoding so it takes the next closest station
rain_dat_sum[rain_dat_sum$location == "Premer", c("lat","lon")] <- 
   sweep_for_stations(latlon = unlist(c(rain_dat_sum[rain_dat_sum$location == "Premer", c("lat","lon")])))[2,c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Emerald", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Emerald Agricultural College",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Redvale", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Red Vale & Kingaroy Research Station",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Wellcamp", c("lat","lon")] <- 
   experiment_sites[experiment_sites$location == "Wellcamp",c("lat","lon")]

rain_dat_sum[rain_dat_sum$location == "Dalby", c("lat","lon")] <- c(-27.168426, 151.264421)

rain_dat_sum$rainfall_sum <- NA

source("R/AUS_rainfall_function.r")




# loop to download and save all the rainfall sum data

for(j in -10:20){
   if(j == -10){lm_data <- data.frame()}
   
   for(i in seq_along(rain_dat_sum$trial_ref)){
      
      
      #ERROR HANDLING
     # possibleError <- tryCatch(
         rain_dat_sum$rainfall_sum[i] <- 
            AUS_rainfall(StartDate = as.Date(rain_dat_sum$planting_date)[i] + 10,
                         EndDate = as.Date(rain_dat_sum$planting_date)[i] + 90,
                         lat = rain_dat_sum$lat[i],
                         long = rain_dat_sum$lon[i])
         #error=function(e) e
         #)
      
      
      #if(inherits(possibleError, "error")) {print(possibleError)
      #   next
      }
   }
   
   lmod1 <- summary(lm(rainfall_sum ~ grain_yield, 
                       data = rain_dat_sum[rain_dat_sum$location != "Hermitage",])) # remove hermitage which is irrigated
   
   lm_data <- rbind(lm_data,
                    data.frame(days_from_plant = 10,
                               estimate = coef(lmod1)[2,1],
                               P_value = coef(lmod1)[2,4],
                               r_squared = lmod1$r.squared,
                               adj_r_squared = lmod1$adj.r.squared,
                               stringsAsFactors = FALSE)
                    )
   
}




write.csv(lm_data, "data/rainfall_x_Gyield_lmod.csv")
<- read.csv("data/rainfall_x_Gyield_lmod.csv", stringsAsFactors = FALSE)
rain_dat_sum[rain_dat_sum$location != "Hermitage",] %>%
   ggplot(aes(x = rainfall_sum, y = grain_yield )) + 
   geom_point(aes(colour = location)) +
   geom_smooth(method = "lm")              

# use Bomrang to find the quantaty of rain for the season and do a linear regression

is.vector(unlist(c(rain_dat_sum[1,5],rain_dat_sum[1,6])))

plot(P_value ~ days_from_plant, data = lm_data)
plot(r_squared ~ days_from_plant, data = lm_data)
plot(estimate ~ days_from_plant, data = lm_data)

tmp1 <- read.csv("C:/Users/U8011054/AppData/Local/Temp/RtmpkbEvfL/IDCJAC0009_041359_1800_Data.csv", stringsAsFactors = FALSE)

nchar(tmp1$Bureau.of.Meteorology.station.number[1])
strsp

head(tmp1)
message()

```



```{r first_incidence}
# Here I want to build a plot of horizontal lines indicating the season length and
# place a dot on the line to indicating the day of the year first sign was observed for that trial

FS_dates <- data.frame(first_sign = as.Date(unique(PM_MB_means$first_sign_disease)),
                       plant.date = as.Date(PM_MB_)
)

PM_MB_


dat1 <- data.frame(First_sign = sort(format(FS_dates, "%b-%d"))[c(5:25,1:4)])

dat1$First_sign <- as.Date(dat1$First_sign)

ggplot(dat1, aes(x = First_sign))+
   geom_dotplot()+
   scale_x_date()+
   coord_flip()

as.character(format(FS_dates, "%b-%d"))

as.Date()



```



## Standardising the type of variance  

The type of variance needs to be standardised between trials and treatments for the meta-analysis. 

```{r variance}
# PM_MB_means$Y_error_type <- forcats::fct_explicit_na(PM_MB_means$Y_error_type, na_level = NA)
# Trials using tebuconazole
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
         row_spacing == 0.75) %>%
   group_by(trial_ref, location, Y_error_type) %>%
   summarise(tebuconazole_trts = length(Y_error_type))


# Trials using propiconazole
PM_MB_means %>%
   filter(fungicide_ai == "propiconazole",
          row_spacing == 0.75) %>%
   group_by(trial_ref, location, Y_error_type) %>%
   summarise(propiconazole_trts = length(Y_error_type))
```


```{r LSD_trials}
Trials <- PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
          row_spacing == 0.75,
          Y_error_type == "lsd (P=0.05)") %>%
   select(trial_ref) %>%
   distinct()
Trials
```


The trial, `mung1112/02` uses Least Square Differences (LSD) to describe the variation within the experiment.
The following code attempts to convert this to sampling variance as per the method in [Nugugi et.al (2011)](https://apsjournals.apsnet.org/doi/10.1094/PHYTO-08-10-0221).
Ideas for using a T-critical value of 1.697 came from reading a [statisics-how-to website](https://www.statisticshowto.datasciencecentral.com/how-to-calculate-the-least-significant-difference-lsd/).
A [table of T-critical values](https://www.statisticshowto.datasciencecentral.com/tables/t-distribution-table/) was consulted where 30 degrees of freedom within experiment was used to find the 'T-crit' value of 1.697.

![Calculating sampling variance from mean squared error Paul et al. (2008)](Paul_etal_2008.PNG)

```{r LSD_2_Sampling Variance}
# Formula and modifications based off information found at https://www.statisticshowto.datasciencecentral.com/how-to-calculate-the-least-significant-difference-lsd/

for (Trial2012 in Trials$trial_ref) {
   Tcrit <-
      1.697  # 0.05 and DFw = 30 # T critical value for which there is significant difference between two groups; This value is the same for both trials "mung1112/01" and "mung1112/02"
   DFw <-
      sum(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates) -
      length(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates) # degrees of freedom within groups
   # n.A <- PM_MB_means[PM_MB_means$trial_ref == "Trial2012,]$replicates[1]
   # n.B <- PM_MB_means[PM_MB_means$trial_ref == "Trial2012,]$replicates[2]
   LSD <-
      PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$yield_error[1]
   
   
   # SSwithin <- #unknown
   # MSW <- SSwithin / DFw # mean square within (SS within / DF within)
   
   
   #  LSD = (Tcrit) * sqrt(MSW * (1/n.A + 1/n.B))
   #  (LSD/Tcrit) = sqrt(MSW * (1/n.A + 1/n.B))
   #  (LSD/Tcrit)^2 = MSW * (1/n.A + 1/n.B)
   #  (LSD/Tcrit)^2/(1/n.A + 1/n.B) = MSW
   #  MSE <- (LSD/Tcrit)^2/(1/n.A + 1/n.B) # This formula was abandon in favor for the formula in Nugugi et. at (2011)
   MSE <-
      PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates[1] * (LSD /
                                                                            Tcrit) ^ 2 / 2 # method for finding variance in Nugugi et.al (2011) DOI: 10.1094/phyto-08-10-0221
   
   
   for (j in seq_along(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates)) {
      if (j == 1) {
         Sv <-
            vector(length = length(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates))
      }
      #  Sv[j]^2 = MSE/(PM_MB_means[PM_MB_means$trial_ref == Trial2012,]$replicates[j] *
      #                   PM_MB_means[PM_MB_means$trial_ref == Trial2012,]$grain_yield.t.ha[j])
      # Balance equation
      Sv[j] = sqrt(MSE / (
         PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates[j] *
            as.numeric(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$grain_yield.t.ha[j])
      ))
      
   }
   
   # and replacing the values in the dataset
   
   PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$yield_error <-
      Sv
   PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$Y_error_type <-
      "SamplingVariance"
   
}
```


Now to estimate the variance from the standard deviation

```{r stdev2SampVariance}
# subset data by those which describe the Yield error with standard deviation
Trials <- PM_MB_means %>%
   filter(#fungicide_ai == "tebuconazole",
      #row_spacing.m == 0.75,
      Y_error_type == "stdev") %>%
   select(trial_ref) %>%
   distinct()


# calculate the Sampling variance from the standard deviation
# standard error of the mean equals the standard deviation divided by the square root of the number of samples
# Sv <- sem^2 <- stdev/sqrt(n)
# Sampling variance equals the square of the standard error.
# Sv <- (stdev/sqrt(n))^2

# Therefore

for (j in seq_along(PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error)) {
   # create empty vector at first iteration with length of j
   if (j == 1) {
      Sv <-
         vector(length = length(PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error))
   }
   
   # Equation to convert standard deviation to Sampling Variance
   Sv[j] = (PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error[j]) ^
      2
}

# and replacing the values in the dataset
PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error <-
   Sv
PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$Y_error_type <-
   "SamplingVariance"
```


Now for the trickier part creating 'Sampling Variance' for treatments where only mean yield is recorded.  
The trial which does not report any type of variance also reports that there is no significant difference between the means.

```{r}
NATrials <- PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
          row_spacing.m == 0.75,
          is.na(Y_error_type)) %>%
   select(trial_ref) %>%
   distinct()
```

A single trial `mung1516/03` within the current scope of the meta-analysis fails to report a variance statistic. According to [Machado F. et. al (2017)](http://apsjournals.apsnet.org/doi/10.1094/PDIS-03-17-0340-RE) [Paul et al. (2007)](https://apsjournals.apsnet.org/doi/pdfplus/10.1094/PHYTO-97-2-0211) uses linear regression model to estimate sampling variance.  

```{r na2Sampling_variance, message=FALSE}
library(lme4)
library(scales)

# for(i in PM_MB_means$trial_ref){
#
# log(V)[i] = a + b * log(
#    mean(subset(PM_MB_means$grain_yield.t.ha[i], fungicide_ai == "control"),
#         subset(PM_MB_means$grain_yield.t.ha[i], fungicide_ai == "tebuconazole")))
# # need to know what parameters a and b are here
# # I am guessing they represent prediction parameters for each "study" for each of the treatments, "control" and tebuconazole"
# }

# method as described by Emerson
PM_MB_train <- PM_MB_means %>%
   filter(Y_error_type == "SamplingVariance")

PM_MB_train$trial_ref <- as.factor(PM_MB_train$trial_ref)

plot(PM_MB_train$yield_error,
     log(PM_MB_train$grain_yield.t.ha))

length(unique(PM_MB_train$Trial_ref))

# Run a linear model with grain_yield.t.ha as a fixed effect predictor and trial as a random intercept
PM_MB_trainLMER <- lmer(yield_error ~ grain_yield.t.ha +
                           (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER)

# grain yield (in this model) IS a significant predictor for yield error
# (t value = 5.826)
# And the variance increases as the mean increases does log transformation
# improve the model?


PM_MB_trainLMER.1 <- lmer(log(yield_error) ~ `grain_yield.t.ha` +
                             (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER.1) # grain yield a significant predictor of log(yield error)
anova(PM_MB_trainLMER, PM_MB_trainLMER.1) # no significant difference between the models


PM_MB_trainLMER.2 <- lmer(yield_error ~ log(`grain_yield.t.ha`) +
                             (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER.2) # log(grain yeild) is a significant predictor of yield error
anova(PM_MB_trainLMER, PM_MB_trainLMER.2) # no significant difference between the models


PM_MB_trainLMER.3 <-
   lmer(log(yield_error) ~ log(`grain_yield.t.ha`) +
           (1 | trial_ref),
        data = PM_MB_train)
summary(PM_MB_trainLMER.3) # log(grain yeild) is a significant predictor of log(yielderror)
anova(PM_MB_trainLMER, PM_MB_trainLMER.3) # no significant difference between the models


# Lets try with Fungicide as a fixed effect
PM_MB_trainLMER.4 <-
   lmer(yield_error ~ `grain_yield.t.ha` + as.factor(fungicide_ai) +
           (1 | trial_ref),
        data = PM_MB_train)
summary(PM_MB_trainLMER.4)
anova(PM_MB_trainLMER, PM_MB_trainLMER.4) # no significant difference between the models



#log transforming the response or predictor variables did not improve the model therefore I will leave it untransformed
# I will be using the first model PM_MB_trainLMER for further analyses beyond this point

# Extract the model coefficients
paramA <-
   (summary(PM_MB_trainLMER)$coef)[2, 1] # Extract the overall mean slope to predict Yield error
InterC <-
   (summary(PM_MB_trainLMER)$coef)[1, 1] # Extract the overall mean intercept to predict Yield error
lmer.coef <-
   coef(PM_MB_trainLMER) # extracting the mean random intercept for each of trial variables






# for(i in NATrials$Trial_ref){
# #Sv <- (log(PM_MB_means[PM_MB_means$Trial_ref == i,]$`grain_yield.t.ha.`) - InterC)/ paramA  # parameter from when I had the predictor and response variable flipped
# 
# Sv <- (PM_MB_means[PM_MB_means$Trial_ref == i,]$`grain_yield.t.ha.` * paramA) + InterC
# 
# PM_MB_means[PM_MB_means$Trial_ref == i,]$Yield_error <- Sv
# PM_MB_means[PM_MB_means$Trial_ref == i,]$Y_error.type <- "SamplingVariance"
# }

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = c(InterC, lmer.coef$trial_ref[, 1]),
      slope = c(paramA, lmer.coef$trial_ref[, 2]),
      size = 1,
      colour = c("Black", hue_pal()(length(unique(PM_MB_train$trial_ref))))
   ) +
   coord_cartesian(xlim = c(0, 3)) +
   theme_usq()
```



```{r na2Sv_formula}
# commented until a reliable model can be written


# for (i in NATrials$trial_ref) {
#    #Sv <- (log(PM_MB_means[PM_MB_means$trial_ref == i,]$`grain_yield.t.ha`) - InterC)/ paramA  # parameter from when I had the predictor and response variable flipped
#    
#    Sv <-
#       (PM_MB_means[PM_MB_means$trial_ref == i,]$`grain_yield.t.ha` * paramA) + InterC
#    
#    PM_MB_means[PM_MB_means$trial_ref == i,]$yield_error <- Sv
#    PM_MB_means[PM_MB_means$trial_ref == i,]$Y_error_type <-
#       "SamplingVariance"
# }

```


Let's look at the model without the trial mung1718/01, as it looks to be adding some skew.

```{r lmer_remove_mung1718-01}
# remove from mung1718/01 from training dataset
PM_MB_train.2 <-
   PM_MB_train[PM_MB_train$trial_ref != "mung1718/01",]

# Rerun the model
PM_MB_trainLMER.5 <- lmer(yield_error ~ `grain_yield.t.ha` +
                             (1 | trial_ref), data = PM_MB_train.2)
summary(PM_MB_trainLMER.5) # no significant effect of mean grain yield on yield error


# Extract the cooeficients
paramA <-
   (summary(PM_MB_trainLMER.5)$coef)[2, 1] # Extract the overall mean Slope to predict Yield error
InterC <-
   (summary(PM_MB_trainLMER.5)$coef)[1, 1] # Extract the overall mean intercept to predict Yield error
lmer.coef <-
   coef(PM_MB_trainLMER.5) # extracting the mean random intercept for each of trial variables


# plot the data with the predicted slopes overlayed

ggplot(PM_MB_train.2) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = c(InterC, lmer.coef$trial_ref[, 1]),
      slope = c(paramA, lmer.coef$trial_ref[, 2]),
      size = 1,
      colour = c("Black", hue_pal()(length(unique(PM_MB_train.2$Trial_ref))))
   ) +
   coord_cartesian(ylim = c(0, 0.33)) +
   xlab("Grain Yield (t/ha)") +
   ylab("Yield Error") +
   scale_colour_discrete("Trial Reference") +
   theme_usq()

```



Just for kicks lets look at the linear regression model as a random effects model where `grain_yield.t.ha` is set as a random slope to the random intercept `trial_ref`.

The model fits better as shown by an ANOVA comparison. But how to impute from this model if mean variance for a trial is unknown...

```{r random_slope_model} 
# This code chunk broke with the addition of new data, I will re-inspect the data and remodel.

# Run a linear model with yield error as a fixed effect predictor and trial as a random intercept
PM_MB_trainLMERx <- lmer(yield_error ~ 1 +
                            (grain_yield.t.ha |
                                trial_ref), data = PM_MB_train)


anova(PM_MB_trainLMER, PM_MB_trainLMERx) # random slope model NOT significantly better # P = 0.6677

summary(PM_MB_trainLMERx)

InterC <-
   (summary(PM_MB_trainLMER)$coef)[1, 1] # Extract the overall mean intercept

lmer.coefx <- coef(PM_MB_trainLMERx)

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = lmer.coefx$trial_ref[, 2],
      slope = lmer.coefx$trial_ref[, 1],
      size = 1,
      colour = hue_pal()(length(unique(PM_MB_train$Trial_ref)))
   ) +
   coord_cartesian(xlim = c(0, 3),
                   ylim = c(0, 1)) +
   xlab("Grain Yield (t/ha)") +
   ylab("Yield Error") +
   scale_colour_discrete("Trial Reference") +
   theme_usq()
```
After much deliberation I don't think this is possible to use the model with grain yield t/ha as a random slope. Even though we know the grain yields and the mean of the grain yields, we still can't predict the effect of the random intercept trial on the yield error.


I also re-ran the model without including the trial in which we used LSD to interpret the sampling variance and the model lost a lot of significance.  



## Between trial variation

Emerson proposed I look at the between trial variation
```{r between_trial_variation}
unique(PM_MB_means$Y_error_type)

PM_MB_means.SV <- PM_MB_means[PM_MB_means$Y_error_type == "SamplingVariance",]
meta_mean.GY <- mean(PM_MB_means.SV$grain_yield.t.ha.,na.rm = TRUE)


# find the mean and variance of each trial
PM_MB_means_T <- PM_MB_means %>%
   filter(Y_error_type == "SamplingVariance") %>%
   group_by(trial_ref) %>%
   summarise(trial_mean = mean(grain_yield.t.ha., na.rm = TRUE),
             BW_trial_variance = sd(grain_yield.t.ha., na.rm = TRUE) ^ 2
             ) # I am not sure I have calculated between trial variance or trial variance// Should I be using a denominator (N-1) or (N), sd by default uses (N-1)

# by excluding the standard deviation of each treatment I have discarded much of the variance. Should I simulate a larger number of samples for each treatment to reflect the sample distribution of each treatment and then take the mean and standard deviation of the whole trial of the simulated data?



# update the main data set with Trial variance
SV_Trials <- unique(PM_MB_means_T$Trial_ref)
PM_MB_means$TrialVariance <- NA

for(i in SV_Trials){
   PM_MB_means[PM_MB_means$Trial_ref == i, "TrialVariance"] <- PM_MB_means_T[PM_MB_means_T$Trial_ref == i,"BW_trial_variance"]
}
PM_MB_means$TrialVariance
# OR ?
PM_MB_means <- left_join(PM_MB_means, PM_MB_means_T, by = "trial_ref")

SV_mod1 <- lm(Trial_variance ~ trial_mean, data = PM_MB_means_T)
summary(SV_mod1)

plot(Trial_variance ~ trial_mean, data = PM_MB_means_T)
abline(SV_mod1)


```
