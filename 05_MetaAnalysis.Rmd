---
title: "Meta-analysis"
author: "P. Melloy"
date: "`r Sys.Date()`"
output: html_document
---

```{r MEsummary_Libraries, message=FALSE}
library(tidyverse)
library(theme.usq)
```

# Meta-analysis

```{r data_import, message=FALSE, echo=FALSE}
PM_MB_means <-
   read_csv(
      "data/1902 powdery mildew-Mungbean - Collated means.csv"
   )

# convert coltypes
PM_MB_means <-
   PM_MB_means %>%
   mutate(year = as.integer(year)) %>%
   mutate(replicates = as.integer(replicates)) %>%
   mutate(planting_date = as.Date(planting_date, format = "%d/%m/%Y")) %>%
   mutate(emergence_date = as.Date(emergence_date, format = "%d/%m/%Y")) %>%
   mutate(flowering_date = as.Date(flowering_date, format = "%d/%m/%Y")) %>%
   mutate(pod_final_date = as.Date(pod_final_date, format = "%d/%m/%Y")) %>%
   mutate(mid_late_pod_final = as.Date(mid_late_pod_final, format = "%d/%m/%Y")) %>%
   mutate(first_sign_disease = as.Date(first_sign_disease, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_1 = as.Date(fungicide_application_1, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_2 = as.Date(fungicide_application_2, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_3 = as.Date(fungicide_application_3, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_4 = as.Date(fungicide_application_4, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_5 = as.Date(fungicide_application_5, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_6 = as.Date(fungicide_application_6, format = "%d/%m/%Y")) %>%
   mutate(fungicide_application_7 = as.Date(fungicide_application_7, format = "%d/%m/%Y")) %>%
   mutate(harvest_date = as.Date(harvest_date, format = "%d/%m/%Y")) %>%
   mutate(final_assessment = as.Date(final_assessment, format = "%d/%m/%Y"))
```

## Visualise Data

Visualise and inspect the number of factors represented in each trial.

### Fungicides

When investigating previous studies into powdery mildew fungicide efficacy on mungbean `r length(unique(PM_MB_means$trial_ref))` trials were found.
However, only eleven tebuconazole were used for the following meta-analysis, followed by the next most common fungicide, propiconazole. Sulphur was disregarded due to its inconsistency in efficacy.

```{r Fungicides}
PM_MB_means %>%
   group_by(fungicide_ai, trial_ref) %>%
   summarise() %>%
   count(sort = TRUE) %>%
   rename(Trials = n) %>%
   ggplot(aes(x = reorder(fungicide_ai, Trials), y = Trials)) +
   xlab("Fungicide active ingredient") +
   ylab("N Trials") +
   geom_col() +
   scale_fill_usq() +
   scale_colour_usq() +
   theme_usq() +
   coord_flip()
```

Tebuconazole and propiconazole might be able to be pooled as a triazole fungicide treatment. 
Amistar Xtra is a combination of azoxystrobin and cyproconazole.
Custodia is a combination of tebuconazole and azoxystrobin.
Amistar Xtra and Custodia might be able to be pooled given they both contain strobilurin and triazole, however, they contain differing dose ratios (inverted).

Perhaps best way forward is to do an analysis of only the triazoles. Then do another including azoxystrobin as a comparison.

Preliminary analysis of fungicides show there is a difference the effect of fungicide in proportion of yield saved.

### Fungicide Doses

All trials that used tebuconazole used approximately the same dose.
Dose of the active ingredient ranged from 62.35&nbsp;g per hectare to 60&nbsp;g per hectare. 

```{r tebu_dose}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole") %>%
   select(trial_ref,
          year,
          location,
          first_sign_disease,
          dose_ai_f1_g.ha,
          total_fungicide) %>%
   ggplot(aes(x = as.factor(dose_ai_f1_g.ha))) +
   xlab("Dose (g ai/ha)") +
   geom_bar() +
   scale_fill_usq() +
   scale_colour_usq() +
   theme_usq()
```

### Row spacing

Some experiments were designed to investigate the effect of row spacing and plant density on powdery mildew disease.
The results showed that the row spacing had no statistically significant effect on powdery mildew, but narrower rows did increase yield significantly, which has been shown by Kerry McKenzie's work as well.
Eight trials used a row spacing of 0.75&nbsp;meters and tebuconazole as an active ingredient (AI).

```{r row_spacing.m}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole" | fungicide_ai == "propiconazole") %>%
   group_by(fungicide_ai, row_spacing.m, trial_ref) %>%
   summarise() %>%
   count() %>%
   rename(Trials = n) %>%
   ggplot(aes(x = as.factor(row_spacing.m), y = Trials)) +
   xlab("Row Spacing (m)") +
   ylab("N Trials") +
   ggtitle(label = "Trial row spacings using tebuconazole") +
   geom_col(aes(fill = fungicide_ai),
            position = "dodge") +
   scale_fill_usq(name = "Fungicide AI") +
   theme_usq()

PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
         row_spacing.m == 0.75) %>% 
   glimpse()
```

Were there any statistical difference between all row spacing or only some?
Can we pool certain row spacings that have no significant difference?
From the preliminary analysis, the graphs seem to imply that if there is a lower overall yield there is no effect of row spacing on yield.
However, if the average yield is more than approximately 0.6 - 1 t/ha then smaller row spacing has the potential to provide greater yield.

### Host genotypes

Host genotype may need to be analysed to determine the effect.

```{r Host_genotype}
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
         row_spacing.m == 0.75) %>%
   group_by(host_genotype, trial_ref) %>%
   summarise() %>%
   count() %>%
   rename(Treatments = n) %>%
   ggplot(aes(x = host_genotype, y = Treatments)) +
   xlab("Cultivar") +
   ylab("N Trials") +
   ggtitle(label = "Cultivars used in tebuconazole trials with 0.75 m row spacing") +
   geom_col() +
   scale_fill_usq() +
   scale_colour_usq() +
   theme_usq()
```

In general the mungbean varieties have the following resistance to powdery mildew.

   - Berken: Highly susceptible
   
   - Crystal: Susceptible
   
   - Jade: Moderately susceptible

## Standardising the type of variance  

The type of variance needs to be standardised between trials and treatments for the meta-analysis. 

```{r variance}
# Trials using tebuconazole
PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
         row_spacing.m == 0.75) %>%
   group_by(trial_ref, location, y_error.type) %>%
   summarise(tebuconazole_trts = length(y_error.type))

# Trials using propiconazole
PM_MB_means %>%
   filter(fungicide_ai == "propiconazole",
          row_spacing.m == 0.75) %>%
   group_by(trial_ref, location, y_error.type) %>%
   summarise(propiconazole_trts = length(y_error.type))
```


```{r LSD_trials}
Trials <- PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
          row_spacing.m == 0.75,
          y_error.type == "lsd (P=0.05)") %>%
   select(trial_ref) %>%
   distinct()
Trials
```


The trial, `mung1112/02` uses Least Square Differences (LSD) to describe the variation within the experiment.
The following code attempts to convert this to sampling variance as per the method in [Nugugi et.al (2011)](https://apsjournals.apsnet.org/doi/10.1094/PHYTO-08-10-0221).
Ideas for using a T-critical value of 1.697 came from reading a [statisics-how-to website](https://www.statisticshowto.datasciencecentral.com/how-to-calculate-the-least-significant-difference-lsd/).
A [table of T-critical values](https://www.statisticshowto.datasciencecentral.com/tables/t-distribution-table/) was consulted where 30 degrees of freedom within experiment was used to find the 'T-crit' value of 1.697.

![Calculating sampling variance from mean squared error Paul et al. (2008)](Paul_etal_2008.PNG)

```{r LSD_2_Sampling Variance}
# Formula and modifications based off information found at https://www.statisticshowto.datasciencecentral.com/how-to-calculate-the-least-significant-difference-lsd/

for (Trial2012 in Trials$trial_ref) {
   Tcrit <-
      1.697  # 0.05 and DFw = 30 # T critical value for which there is significant difference between two groups; This value is the same for both trials "mung1112/01" and "mung1112/02"
   DFw <-
      sum(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates) -
      length(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates) # degrees of freedom within groups
   # n.A <- PM_MB_means[PM_MB_means$trial_ref == "Trial2012,]$replicates[1]
   # n.B <- PM_MB_means[PM_MB_means$trial_ref == "Trial2012,]$replicates[2]
   LSD <-
      PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$yield_error[1]
   
   
   # SSwithin <- #unknown
   # MSW <- SSwithin / DFw # mean square within (SS within / DF within)
   
   
   #  LSD = (Tcrit) * sqrt(MSW * (1/n.A + 1/n.B))
   #  (LSD/Tcrit) = sqrt(MSW * (1/n.A + 1/n.B))
   #  (LSD/Tcrit)^2 = MSW * (1/n.A + 1/n.B)
   #  (LSD/Tcrit)^2/(1/n.A + 1/n.B) = MSW
   #  MSE <- (LSD/Tcrit)^2/(1/n.A + 1/n.B) # This formula was abandon in favor for the formula in Nugugi et. at (2011)
   MSE <-
      PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates[1] * (LSD /
                                                                            Tcrit) ^ 2 / 2 # method for finding variance in Nugugi et.al (2011) DOI: 10.1094/phyto-08-10-0221
   
   
   for (j in seq_along(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates)) {
      if (j == 1) {
         Sv <-
            vector(length = length(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates))
      }
      #  Sv[j]^2 = MSE/(PM_MB_means[PM_MB_means$trial_ref == Trial2012,]$replicates[j] *
      #                   PM_MB_means[PM_MB_means$trial_ref == Trial2012,]$grain_yield.t.ha[j])
      # Balance equation
      Sv[j] = sqrt(MSE / (
         PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$replicates[j] *
            as.numeric(PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$grain_yield.t.ha[j])
      ))
      
   }
   
   # and replacing the values in the dataset
   
   PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$yield_error <-
      Sv
   PM_MB_means[PM_MB_means$trial_ref == Trial2012, ]$y_error.type <-
      "SamplingVariance"
   
}
```


Now to estimate the variance from the standard deviation

```{r stdev2SampVariance}
# subset data by those which describe the Yield error with standard deviation
Trials <- PM_MB_means %>%
   filter(#fungicide_ai == "tebuconazole",
      #row_spacing.m == 0.75,
      y_error.type == "stdev") %>%
   select(trial_ref) %>%
   distinct()


# calculate the Sampling variance from the standard deviation
# standard error of the mean equals the standard deviation divided by the square root of the number of samples
# Sv <- sem^2 <- stdev/sqrt(n)
# Sampling variance equals the square of the standard error.
# Sv <- (stdev/sqrt(n))^2

# Therefore

for (j in seq_along(PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error)) {
   # create empty vector at first iteration with length of j
   if (j == 1) {
      Sv <-
         vector(length = length(PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error))
   }
   
   # Equation to convert standard deviation to Sampling Variance
   Sv[j] = (PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error[j]) ^
      2
}



# and replacing the values in the dataset
PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$yield_error <-
   Sv
PM_MB_means[PM_MB_means$trial_ref %in% Trials$trial_ref,]$y_error.type <-
   "SamplingVariance"

```


Now for the trickier part creating 'Sampling Variance' for treatments where only mean yield is recorded.  
The trial which does not report any type of variance also reports that there is no significant difference between the means.

```{r}
NATrials <- PM_MB_means %>%
   filter(fungicide_ai == "tebuconazole",
          row_spacing.m == 0.75,
          is.na(y_error.type)) %>%
   select(trial_ref) %>%
   distinct()
```

A single trial `mung1516/03` within the current scope of the meta-analysis fails to report a variance statistic. According to [Machado F. et. al (2017)](http://apsjournals.apsnet.org/doi/10.1094/PDIS-03-17-0340-RE) [Paul et al. (2007)](https://apsjournals.apsnet.org/doi/pdfplus/10.1094/PHYTO-97-2-0211) uses linear regression model to estimate sampling variance.  

```{r na2Sampling_variance, message=FALSE}
library(lme4)
library(scales)

# for(i in PM_MB_means$trial_ref){
#
# log(V)[i] = a + b * log(
#    mean(subset(PM_MB_means$grain_yield.t.ha[i], fungicide_ai == "control"),
#         subset(PM_MB_means$grain_yield.t.ha[i], fungicide_ai == "tebuconazole")))
# # need to know what parameters a and b are here
# # I am guessing they represent prediction parameters for each "study" for each of the treatments, "control" and tebuconazole"
# }


# method as described by Emerson
PM_MB_train <- PM_MB_means %>%
   filter(y_error.type == "SamplingVariance")

PM_MB_train$trial_ref <- as.factor(PM_MB_train$trial_ref)

plot(PM_MB_train$yield_error,
     log(PM_MB_train$grain_yield.t.ha))



# Run a linear model with grain_yield.t.ha as a fixed effect predictor and trial as a random intercept
PM_MB_trainLMER <- lmer(yield_error ~ grain_yield.t.ha +
                           (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER)

# grain yield (in this model) IS a significant predictor for yield error
# (t value = 5.826)
# And the variance increases as the mean increases does log transformation
# improve the model?


PM_MB_trainLMER.1 <- lmer(log(yield_error) ~ `grain_yield.t.ha` +
                             (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER.1) # grain yield a significant predictor of log(yield error)
anova(PM_MB_trainLMER, PM_MB_trainLMER.1) # no significant difference between the models


PM_MB_trainLMER.2 <- lmer(yield_error ~ log(`grain_yield.t.ha`) +
                             (1 | trial_ref), data = PM_MB_train)
summary(PM_MB_trainLMER.2) # log(grain yeild) is a significant predictor of yield error
anova(PM_MB_trainLMER, PM_MB_trainLMER.2) # no significant difference between the models


PM_MB_trainLMER.3 <-
   lmer(log(yield_error) ~ log(`grain_yield.t.ha`) +
           (1 | trial_ref),
        data = PM_MB_train)
summary(PM_MB_trainLMER.3) # log(grain yeild) is a significant predictor of log(yielderror)
anova(PM_MB_trainLMER, PM_MB_trainLMER.3) # no significant difference between the models


# Lets try with Fungicide as a fixed effect
PM_MB_trainLMER.4 <-
   lmer(yield_error ~ `grain_yield.t.ha` + as.factor(fungicide_ai) +
           (1 | trial_ref),
        data = PM_MB_train)
summary(PM_MB_trainLMER.4)
anova(PM_MB_trainLMER, PM_MB_trainLMER.4) # no significant difference between the models



#log transforming the response or predictor variables did not improve the model therefore I will leave it untransformed
# I will be using the first model PM_MB_trainLMER for further analyses beyond this point

# Extract the model coefficients
paramA <-
   (summary(PM_MB_trainLMER)$coef)[2, 1] # Extract the overall mean slope to predict Yield error
InterC <-
   (summary(PM_MB_trainLMER)$coef)[1, 1] # Extract the overall mean intercept to predict Yield error
lmer.coef <-
   coef(PM_MB_trainLMER) # extracting the mean random intercept for each of trial variables


# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = c(InterC, lmer.coef$trial_ref[, 1]),
      slope = c(paramA, lmer.coef$trial_ref[, 2]),
      size = 1,
      colour = c("Black", hue_pal()(16))
   ) +
   coord_cartesian(xlim = c(0, 3)) +
   theme_usq()
```

```{r na2Sv_formula}
for (i in NATrials$trial_ref) {
   #Sv <- (log(PM_MB_means[PM_MB_means$trial_ref == i,]$`grain_yield.t.ha`) - InterC)/ paramA  # parameter from when I had the predictor and response variable flipped
   
   Sv <-
      (PM_MB_means[PM_MB_means$trial_ref == i,]$`grain_yield.t.ha` * paramA) + InterC
   
   PM_MB_means[PM_MB_means$trial_ref == i,]$yield_error <- Sv
   PM_MB_means[PM_MB_means$trial_ref == i,]$y_error.type <-
      "SamplingVariance"
}
```


Let's look at the model without the trial mung1718/01, as it looks to be adding some skew.

```{r lmer_remove_mung1718-01}
# remove from mung1718/01 from training dataset
PM_MB_train.2 <-
   PM_MB_train[PM_MB_train$trial_ref != "mung1718/01",]

# Rerun the model
PM_MB_trainLMER.5 <- lmer(yield_error ~ `grain_yield.t.ha` +
                             (1 | trial_ref), data = PM_MB_train.2)
summary(PM_MB_trainLMER.5) # no significant effect of mean grain yield on yield error


# Extract the cooeficients
paramA <-
   (summary(PM_MB_trainLMER.5)$coef)[2, 1] # Extract the overall mean Slope to predict Yield error
InterC <-
   (summary(PM_MB_trainLMER.5)$coef)[1, 1] # Extract the overall mean intercept to predict Yield error
lmer.coef <-
   coef(PM_MB_trainLMER.5) # extracting the mean random intercept for each of trial variables


# plot the data with the predicted slopes overlayed
ggplot(PM_MB_train.2) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = c(InterC, lmer.coef$trial_ref[, 1]),
      slope = c(paramA, lmer.coef$trial_ref[, 2]),
      size = 1,
      colour = c("Black", hue_pal()(15))
   ) +
   coord_cartesian(ylim = c(0, 0.33)) +
   xlab("Grain Yield (t/ha)") +
   ylab("Yield Error") +
   scale_colour_discrete("Trial Reference") +
   theme_usq()
```


Just for kicks lets look at the linear regression model as a random effects model where `grain_yield.t.ha` is set as a random slope to the random intercept `trial_ref`.

The model fits better as shown by an ANOVA comparison. But how to impute from this model if mean variance for a trial is unknown...

```{r random_slope_model}
# Run a linear model with yield error as a fixed effect predictor and trial as a random intercept
PM_MB_trainLMERx <- lmer(yield_error ~ 1 +
                            (grain_yield.t.ha |
                                trial_ref), data = PM_MB_train)

anova(PM_MB_trainLMER, PM_MB_trainLMERx) # random slope model NOT significantly better # P = 0.6677

summary(PM_MB_trainLMERx)

InterC <-
   (summary(PM_MB_trainLMER)$coef)[1, 1] # Extract the overall mean intercept

lmer.coefx <- coef(PM_MB_trainLMERx)

# plot of the mixed effect model, Black line shows the mean lmer regression line
ggplot(PM_MB_train) +
   geom_point(aes(y = yield_error, x = grain_yield.t.ha, colour = trial_ref)) +
   geom_abline(
      intercept = lmer.coefx$trial_ref[, 2],
      slope = lmer.coefx$trial_ref[, 1],
      size = 1,
      colour = hue_pal()(16)
   ) +
   coord_cartesian(xlim = c(0, 3),
                   ylim = c(0, 1)) +
   xlab("Grain Yield (t/ha)") +
   ylab("Yield Error") +
   scale_colour_discrete("Trial Reference") +
   theme_usq()
```


After much deliberation I don't think this is possible to use the model with grain yield t/ha as a random slope. Even though we know the grain yields and the mean of the grain yields, we still can't predict the effect of the random intercept trial on the yield error.

I also re-ran the model without including the trial in which we used LSD to interpret the sampling variance and the model lost a lot of significance.  

## Between trial variation

Emerson proposed I look at the between trial variation.

```{r between_trial_variation}
levels(factor(PM_MB_means$y_error.type))

PM_MB_means.SV <-
   filter(PM_MB_means, y_error.type == "SamplingVariance")

meta_mean.GY <- mean(PM_MB_means.SV$grain_yield.t.ha, na.rm = TRUE)

PM_MB_means_T <- PM_MB_means %>%
   group_by(trial_ref) %>%
   summarise(
      trial_mean = mean(grain_yield.t.ha, na.rm = TRUE),
      BW_trial_variance = sd(grain_yield.t.ha, na.rm = TRUE) ^ 2
   )

PM_MB_means <- left_join(PM_MB_means, PM_MB_means_T, by = "trial_ref")

summary(lm(BW_trial_variance ~ trial_mean, data = PM_MB_means))
summary(lm(
   BW_trial_variance ~ trial_mean,
   data = subset(PM_MB_means, fungicide_ai == "tebuconazole")
))
summary(lm(
   BW_trial_variance ~ trial_mean,
   data = subset(PM_MB_means, fungicide_ai == "propiconazole")
))


plot(BW_trial_variance ~ trial_mean, data = PM_MB_means)
abline(-0.01356, 0.03076)

```
